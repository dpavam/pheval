{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Introduction PhEval - Phenotypic Inference Evaluation Framework PhEval: Tool-specific processing (VP pipeline) flowchart LR PC-->DP PC[(Phenopackets Corpus)] SSSOM[Semantic Similarity Profiles Mapping Commons]-->|OAK-SEMSIM|DP[Data Prepare] KG[Source data KG - Monarch KG]-->|KGX-BIOLINK|DP[Data Prepare] ONT[Ontologies - Phenio]-->|OAK-ONTO|DP[Data Prepare] DP-->RP[Run Prepare] RP-->PR[PhEval Runner] PR-->DP2[Data Process] ER[Exomiser Runner]-->PR EDP[Exomiser Data Prepare]-->DP ERP[Exomiser Run Prepare]-->RP PPP[Disease-profile similarity prediction Post-process]-->DP2 PV[Phenotype/Variant]-->DP2 GVP[Gene VP Post-process]-->DP2 EPP[Exomiser Post Process]-->GVP GVP-->VPR[VP Report] Quick links: GitHub page","title":"Home"},{"location":"#home","text":"","title":"Home"},{"location":"#introduction","text":"PhEval - Phenotypic Inference Evaluation Framework","title":"Introduction"},{"location":"#pheval-tool-specific-processing-vp-pipeline","text":"flowchart LR PC-->DP PC[(Phenopackets Corpus)] SSSOM[Semantic Similarity Profiles Mapping Commons]-->|OAK-SEMSIM|DP[Data Prepare] KG[Source data KG - Monarch KG]-->|KGX-BIOLINK|DP[Data Prepare] ONT[Ontologies - Phenio]-->|OAK-ONTO|DP[Data Prepare] DP-->RP[Run Prepare] RP-->PR[PhEval Runner] PR-->DP2[Data Process] ER[Exomiser Runner]-->PR EDP[Exomiser Data Prepare]-->DP ERP[Exomiser Run Prepare]-->RP PPP[Disease-profile similarity prediction Post-process]-->DP2 PV[Phenotype/Variant]-->DP2 GVP[Gene VP Post-process]-->DP2 EPP[Exomiser Post Process]-->GVP GVP-->VPR[VP Report] Quick links: GitHub page","title":"PhEval: Tool-specific processing (VP pipeline)"},{"location":"CODE_OF_CONDUCT/","text":"Contributor Covenant Code of Conduct Our Pledge In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to make participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Our Responsibilities Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution This code of conduct has been derived from the excellent code of conduct of the ATOM project which in turn is adapted from the Contributor Covenant , version 1.4, available at https://contributor-covenant.org/version/1/4","title":"Contributor Covenant Code of Conduct"},{"location":"CODE_OF_CONDUCT/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"CODE_OF_CONDUCT/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to make participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"CODE_OF_CONDUCT/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"CODE_OF_CONDUCT/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our Responsibilities"},{"location":"CODE_OF_CONDUCT/#scope","text":"This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"CODE_OF_CONDUCT/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"CODE_OF_CONDUCT/#attribution","text":"This code of conduct has been derived from the excellent code of conduct of the ATOM project which in turn is adapted from the Contributor Covenant , version 1.4, available at https://contributor-covenant.org/version/1/4","title":"Attribution"},{"location":"about/","text":"PhEval - Phenotypic Inference Evaluation Framework Many variant prioritization tools (such as Exomiser and other computational approaches rely on ontologies and phenotype matching, sometimes involving complex processes such as cross-species inference. The performance of such tools is exceedingly hard to evaluate, because of the many factors involved: changes to the structure of the ontology, cross-species mappings and semantic similarity algorithms can have significant consequences. Furthermore, the lack of suitable real-world problems/corpora lead to the situation that many algorithms are evaluated using simulations, which may fail to capture real-world scenarios. The lack of an evaluation framework that enables the study of effects on data and knowledge inputs on real world problems makes it difficult to optimize algorithms. To this end we are developing a modular Phenotypic Inference Evaluation Framework (PhEval) which is delivered it as a community resource.","title":"About"},{"location":"about/#pheval-phenotypic-inference-evaluation-framework","text":"Many variant prioritization tools (such as Exomiser and other computational approaches rely on ontologies and phenotype matching, sometimes involving complex processes such as cross-species inference. The performance of such tools is exceedingly hard to evaluate, because of the many factors involved: changes to the structure of the ontology, cross-species mappings and semantic similarity algorithms can have significant consequences. Furthermore, the lack of suitable real-world problems/corpora lead to the situation that many algorithms are evaluated using simulations, which may fail to capture real-world scenarios. The lack of an evaluation framework that enables the study of effects on data and knowledge inputs on real world problems makes it difficult to optimize algorithms. To this end we are developing a modular Phenotypic Inference Evaluation Framework (PhEval) which is delivered it as a community resource.","title":"PhEval - Phenotypic Inference Evaluation Framework"},{"location":"contact/","text":"Contact The preferred way to contact the PhEval team is through the issue tracker (for problems with PhEval) or the GitHub discussions (for general questions). You can find any of the members of the PhEval core team on GitHub: https://github.com/orgs/monarch-initiative/teams/pheval-team Their GitHub profiles usually also provide email addresses.","title":"Contact Us"},{"location":"contact/#contact","text":"The preferred way to contact the PhEval team is through the issue tracker (for problems with PhEval) or the GitHub discussions (for general questions). You can find any of the members of the PhEval core team on GitHub: https://github.com/orgs/monarch-initiative/teams/pheval-team Their GitHub profiles usually also provide email addresses.","title":"Contact"},{"location":"contributing/","text":"Contributions First of all: Thank you for taking the time to contribute! The following is a set of guidelines for contributing to the PhEval framework. These guidelines are not strict rules. Use your best judgment, and feel free to propose changes to this document in a pull request. Table Of Contents Contributions Table Of Contents Code of Conduct Guidelines for Contributions and Requests Reporting problems with the data model Code of Conduct The monarch-technical-documentation team strives to create a welcoming environment for editors, users and other contributors. Please carefully read our Code of Conduct . Guidelines for Contributions and Requests Reporting problems with the data model Please use our Issue Tracker for reporting problems with the ontology.","title":"Contributions"},{"location":"contributing/#contributions","text":"First of all: Thank you for taking the time to contribute! The following is a set of guidelines for contributing to the PhEval framework. These guidelines are not strict rules. Use your best judgment, and feel free to propose changes to this document in a pull request.","title":"Contributions"},{"location":"contributing/#table-of-contents","text":"Contributions Table Of Contents Code of Conduct Guidelines for Contributions and Requests Reporting problems with the data model","title":"Table Of Contents"},{"location":"contributing/#code-of-conduct","text":"The monarch-technical-documentation team strives to create a welcoming environment for editors, users and other contributors. Please carefully read our Code of Conduct .","title":"Code of Conduct"},{"location":"contributing/#guidelines-for-contributions-and-requests","text":"","title":"Guidelines for Contributions and Requests"},{"location":"contributing/#reporting-problems-with-the-data-model","text":"Please use our Issue Tracker for reporting problems with the ontology.","title":"Reporting problems with the data model"},{"location":"developing_a_pheval_plugin/","text":"Developing a PhEval Plugin Description Plugin development allows PhEval to be extensible, as we have designed it. The plugin goal is to be flexible through custom runner implementations. This plugin development enhances the PhEval functionality. You can build one quickly using this step-by-step process. All custom Runners implementations must implement all PhevalRunner methods Bases: ABC PhEvalRunner Class Source code in src/pheval/runners/runner.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @dataclass class PhEvalRunner ( ABC ): \"\"\"PhEvalRunner Class\"\"\" input_dir : Path testdata_dir : Path tmp_dir : Path output_dir : Path config_file : Path version : str @abstractmethod def prepare ( self ) -> str : \"\"\"prepare\"\"\" @abstractmethod def run ( self ): \"\"\"run\"\"\" @abstractmethod def post_process ( self ): \"\"\"post_process\"\"\" Step-by-Step Plugin Development Process The plugin structure is derived from a cookiecutter template, Sphintoxetry-cookiecutter , and it uses Sphinx , tox and poetry as core dependencies. This allows PhEval extensibility to be standardized in terms of documentation and dependency management. 1. Sphintoxetry-cookiecutter scaffold First, install the cruft package. Cruft enables keeping projects up-to-date with future updates made to this original template. Install cruft from pip pip install cruft Next, create a project using the sphintoxetry-cookiecutter template. cruft create https://github.com/hrshdhgd/sphintoxetry-cookiecutter 2. Further setup Install poetry if you haven't already. pip install poetry Install dependencies poetry install Add PhEval dependency poetry add pheval Run tox to see if the setup works poetry run tox 3. Implement PhEval Custom Runner The runner name is arbitrary and custom Runner name was chose by demonstrative purposes Create a runner file inside the plugin project, e.g: \"\"\"Custom Pheval Runner.\"\"\" from dataclasses import dataclass import click from pheval.runners.runner import PhEvalRunner @dataclass class CustomPhevalRunner ( PhEvalRunner ): \"\"\"CustomPhevalRunner Class.\"\"\" inputdir : click . Path testdatadir : click . Path tmpdir : click . Path outputdir : click . Path config : click . Path def prepare ( self ): \"\"\"prepare method.\"\"\" print ( \"preparing\" ) def run ( self ): \"\"\"run method.\"\"\" print ( \"running with custom pheval Runner\" ) def post_process ( self ): \"\"\"post_process method.\"\"\" print ( \"post processing\" ) 4. Add PhEval Plugins section into the pyproject.toml file [tool.poetry.plugins.\"pheval.plugins\"] customrunner = \"pheval_plugin_example.runner:CustomPhevalRunner\" Replace the value above with the path to your custom runner plugin 5. Test it. To update your custom pheval runner implementation, you must first install the package poetry install Now you have to be able to run PhEval passing your custom runner as parameter. e.g pheval run -i input.txt -t './test' -r 'customphevalrunner' -o out.txt The -r parameter stands for your plugin runner class name and it must be entirely lowercase. Output: preparing running with custom pheval Runner post processing Pay attention to \" running with custom pheval Runner \" line, this is exactly what we had implemented in the CustomPhevalRunner Example","title":"Developing a PhEval Plugin"},{"location":"developing_a_pheval_plugin/#developing-a-pheval-plugin","text":"","title":"Developing a PhEval Plugin"},{"location":"developing_a_pheval_plugin/#description","text":"Plugin development allows PhEval to be extensible, as we have designed it. The plugin goal is to be flexible through custom runner implementations. This plugin development enhances the PhEval functionality. You can build one quickly using this step-by-step process. All custom Runners implementations must implement all PhevalRunner methods Bases: ABC PhEvalRunner Class Source code in src/pheval/runners/runner.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @dataclass class PhEvalRunner ( ABC ): \"\"\"PhEvalRunner Class\"\"\" input_dir : Path testdata_dir : Path tmp_dir : Path output_dir : Path config_file : Path version : str @abstractmethod def prepare ( self ) -> str : \"\"\"prepare\"\"\" @abstractmethod def run ( self ): \"\"\"run\"\"\" @abstractmethod def post_process ( self ): \"\"\"post_process\"\"\"","title":"Description"},{"location":"developing_a_pheval_plugin/#step-by-step-plugin-development-process","text":"The plugin structure is derived from a cookiecutter template, Sphintoxetry-cookiecutter , and it uses Sphinx , tox and poetry as core dependencies. This allows PhEval extensibility to be standardized in terms of documentation and dependency management.","title":"Step-by-Step Plugin Development Process"},{"location":"developing_a_pheval_plugin/#1-sphintoxetry-cookiecutter-scaffold","text":"First, install the cruft package. Cruft enables keeping projects up-to-date with future updates made to this original template. Install cruft from pip pip install cruft Next, create a project using the sphintoxetry-cookiecutter template. cruft create https://github.com/hrshdhgd/sphintoxetry-cookiecutter","title":"1. Sphintoxetry-cookiecutter scaffold"},{"location":"developing_a_pheval_plugin/#2-further-setup","text":"","title":"2. Further setup"},{"location":"developing_a_pheval_plugin/#install-poetry-if-you-havent-already","text":"pip install poetry","title":"Install poetry if you haven't already."},{"location":"developing_a_pheval_plugin/#install-dependencies","text":"poetry install","title":"Install dependencies"},{"location":"developing_a_pheval_plugin/#add-pheval-dependency","text":"poetry add pheval","title":"Add PhEval dependency"},{"location":"developing_a_pheval_plugin/#run-tox-to-see-if-the-setup-works","text":"poetry run tox","title":"Run tox to see if the setup works"},{"location":"developing_a_pheval_plugin/#3-implement-pheval-custom-runner","text":"The runner name is arbitrary and custom Runner name was chose by demonstrative purposes Create a runner file inside the plugin project, e.g: \"\"\"Custom Pheval Runner.\"\"\" from dataclasses import dataclass import click from pheval.runners.runner import PhEvalRunner @dataclass class CustomPhevalRunner ( PhEvalRunner ): \"\"\"CustomPhevalRunner Class.\"\"\" inputdir : click . Path testdatadir : click . Path tmpdir : click . Path outputdir : click . Path config : click . Path def prepare ( self ): \"\"\"prepare method.\"\"\" print ( \"preparing\" ) def run ( self ): \"\"\"run method.\"\"\" print ( \"running with custom pheval Runner\" ) def post_process ( self ): \"\"\"post_process method.\"\"\" print ( \"post processing\" )","title":"3. Implement PhEval Custom Runner"},{"location":"developing_a_pheval_plugin/#4-add-pheval-plugins-section-into-the-pyprojecttoml-file","text":"[tool.poetry.plugins.\"pheval.plugins\"] customrunner = \"pheval_plugin_example.runner:CustomPhevalRunner\" Replace the value above with the path to your custom runner plugin","title":"4. Add PhEval Plugins section into the pyproject.toml file"},{"location":"developing_a_pheval_plugin/#5-test-it","text":"To update your custom pheval runner implementation, you must first install the package poetry install Now you have to be able to run PhEval passing your custom runner as parameter. e.g pheval run -i input.txt -t './test' -r 'customphevalrunner' -o out.txt The -r parameter stands for your plugin runner class name and it must be entirely lowercase. Output: preparing running with custom pheval Runner post processing Pay attention to \" running with custom pheval Runner \" line, this is exactly what we had implemented in the CustomPhevalRunner Example","title":"5. Test it."},{"location":"pipeline/","text":"PhEval Pipeline Jinja Template PhEval Makefile Generator Requirements To generate a PhEval Makefile we use the Jinja template engine. PhEval Configuration File In resources folder, there is a file named pheval-config.yaml , this file is responsible for storing the PhEval Makefile generation. \ud83d\udce6resources \u2523 \ud83d\udcdcMakefile.j2 \u2523 \ud83d\udcdccustom.Makefile \u2523 \ud83d\udcdcgeneratemakefile.sh \u2517 \ud83d\udcdcpheval-config.yaml Phenotype Section phenotype : version : 2302 hg : hg19 url : https://data.monarchinitiative.org/exomiser/latest/ Directories Section directories : tmp : data/tmp testdata : testdata config : configurations h2jar : /home/vinicius/.local/share/DBeaverData/drivers/maven/maven-central/com.h2database/h2-1.4.199.jar phen2gene : /home/vinicius/Documents/softwares/Phen2Gene exomiser : /home/data/exomiser-data/ phenotype : /home/data/exomiser-data/2302_phenotype workspace : /home/vinicius/workspace/pheval Configs Section configs : - tool : phen2gene version : 1.2.3 configuration : default - tool : exomiser version : 13.2.0 configuration : default exomiser_db : semsim1 This section is responsible for setting up the configuration folder. All software declared in the configs section will be linked in this folder. In the configuration above, for example, we have one configuration for phen2gene and one for exomiser. In the Directories Section , these two configurations must have one corresponding property set up. PhEval pipeline invokes the prepare-inputs goal, and in the preceding example, a configuration folder structure will be built that looks like this: \ud83d\udce6configurations \u2523 \ud83d\udcc2exomiser-13.2.0-default \u2517 \ud83d\udcc2phen2gene-1.2.3-default Each of these folders is a symbolic link that points to the corresponding software folder indicated in the Directories Section Corpora Section corpora : - id : lirical scrambled : - factor : 0.5 - factor : 0.7 custom_variants : - id : no_phenotype - id : phen2gene scrambled : - factor : 0.2 - factor : 0.9 custom_variants : - id : no_phenotype In this corpora section we can set up different experiments for corpus scrambling. Currently, PhEval provides corpora data from lirical, phen2gene, small_test and structural_variants \ud83d\udce6corpora \u2523 \ud83d\udcc2lirical \u2523 \ud83d\udcc2phen2gene \u2523 \ud83d\udcc2small_test \u2517 \ud83d\udcc2structural_variants The scramble property defines the magnitude of the scrambling factor during Phenopackets and VCF variants spiking process. Using the configuration in the example above, a corpora structure will be created like this: \ud83d\udce6corpora \u2523 \ud83d\udcc2lirical \u2503 \u2517 \ud83d\udcc2default \u2503 \u2517 \ud83d\udcc2scrambled-0.5 \u2503 \u2517 \ud83d\udcc2scrambled-0.7 \u2523 \ud83d\udcc2phen2gene \u2503 \u2517 \ud83d\udcc2default \u2503 \u2517 \ud83d\udcc2scrambled-0.2 \u2503 \u2517 \ud83d\udcc2scrambled-0.9 Runs Section runs : - tool : exomiser configuration : default corpus : lirical corpusvariant : scrambled-0.5 version : 13.2.0 - tool : phen2gene configuration : default corpus : phen2gene corpusvariant : scrambled-0.2 version : 1.2.3 Makefile Goals make pheval this runs the entire pipeline including corpus preparation and pheval run $(MAKE) prepare-inputs $(MAKE) prepare-corpora $(MAKE) pheval-run make semsim generate all configured similarity profiles make semsim-shuffle generate new ontology terms to the semsim process make semsim-scramble scramble semsim profile make semsim-convert convert all semsim profiles into exomiser SQL format make semsim-ingest takes all the configured semsim profiles and loads them into the exomiser databases","title":"PhEval Pipeline"},{"location":"pipeline/#pheval-pipeline","text":"","title":"PhEval Pipeline"},{"location":"pipeline/#jinja-template-pheval-makefile-generator-requirements","text":"To generate a PhEval Makefile we use the Jinja template engine.","title":"Jinja Template PhEval Makefile Generator Requirements"},{"location":"pipeline/#pheval-configuration-file","text":"In resources folder, there is a file named pheval-config.yaml , this file is responsible for storing the PhEval Makefile generation. \ud83d\udce6resources \u2523 \ud83d\udcdcMakefile.j2 \u2523 \ud83d\udcdccustom.Makefile \u2523 \ud83d\udcdcgeneratemakefile.sh \u2517 \ud83d\udcdcpheval-config.yaml","title":"PhEval Configuration File"},{"location":"pipeline/#phenotype-section","text":"phenotype : version : 2302 hg : hg19 url : https://data.monarchinitiative.org/exomiser/latest/","title":"Phenotype Section"},{"location":"pipeline/#directories-section","text":"directories : tmp : data/tmp testdata : testdata config : configurations h2jar : /home/vinicius/.local/share/DBeaverData/drivers/maven/maven-central/com.h2database/h2-1.4.199.jar phen2gene : /home/vinicius/Documents/softwares/Phen2Gene exomiser : /home/data/exomiser-data/ phenotype : /home/data/exomiser-data/2302_phenotype workspace : /home/vinicius/workspace/pheval","title":"Directories Section"},{"location":"pipeline/#configs-section","text":"configs : - tool : phen2gene version : 1.2.3 configuration : default - tool : exomiser version : 13.2.0 configuration : default exomiser_db : semsim1 This section is responsible for setting up the configuration folder. All software declared in the configs section will be linked in this folder. In the configuration above, for example, we have one configuration for phen2gene and one for exomiser. In the Directories Section , these two configurations must have one corresponding property set up. PhEval pipeline invokes the prepare-inputs goal, and in the preceding example, a configuration folder structure will be built that looks like this: \ud83d\udce6configurations \u2523 \ud83d\udcc2exomiser-13.2.0-default \u2517 \ud83d\udcc2phen2gene-1.2.3-default Each of these folders is a symbolic link that points to the corresponding software folder indicated in the Directories Section","title":"Configs Section"},{"location":"pipeline/#corpora-section","text":"corpora : - id : lirical scrambled : - factor : 0.5 - factor : 0.7 custom_variants : - id : no_phenotype - id : phen2gene scrambled : - factor : 0.2 - factor : 0.9 custom_variants : - id : no_phenotype In this corpora section we can set up different experiments for corpus scrambling. Currently, PhEval provides corpora data from lirical, phen2gene, small_test and structural_variants \ud83d\udce6corpora \u2523 \ud83d\udcc2lirical \u2523 \ud83d\udcc2phen2gene \u2523 \ud83d\udcc2small_test \u2517 \ud83d\udcc2structural_variants The scramble property defines the magnitude of the scrambling factor during Phenopackets and VCF variants spiking process. Using the configuration in the example above, a corpora structure will be created like this: \ud83d\udce6corpora \u2523 \ud83d\udcc2lirical \u2503 \u2517 \ud83d\udcc2default \u2503 \u2517 \ud83d\udcc2scrambled-0.5 \u2503 \u2517 \ud83d\udcc2scrambled-0.7 \u2523 \ud83d\udcc2phen2gene \u2503 \u2517 \ud83d\udcc2default \u2503 \u2517 \ud83d\udcc2scrambled-0.2 \u2503 \u2517 \ud83d\udcc2scrambled-0.9","title":"Corpora Section"},{"location":"pipeline/#runs-section","text":"runs : - tool : exomiser configuration : default corpus : lirical corpusvariant : scrambled-0.5 version : 13.2.0 - tool : phen2gene configuration : default corpus : phen2gene corpusvariant : scrambled-0.2 version : 1.2.3","title":"Runs Section"},{"location":"pipeline/#makefile-goals","text":"","title":"Makefile Goals"},{"location":"pipeline/#make-pheval","text":"this runs the entire pipeline including corpus preparation and pheval run $(MAKE) prepare-inputs $(MAKE) prepare-corpora $(MAKE) pheval-run","title":"make pheval"},{"location":"pipeline/#make-semsim","text":"generate all configured similarity profiles","title":"make semsim"},{"location":"pipeline/#make-semsim-shuffle","text":"generate new ontology terms to the semsim process","title":"make semsim-shuffle"},{"location":"pipeline/#make-semsim-scramble","text":"scramble semsim profile","title":"make semsim-scramble"},{"location":"pipeline/#make-semsim-convert","text":"convert all semsim profiles into exomiser SQL format","title":"make semsim-convert"},{"location":"pipeline/#make-semsim-ingest","text":"takes all the configured semsim profiles and loads them into the exomiser databases","title":"make semsim-ingest"},{"location":"roadmap/","text":"Roadmap The Roadmap is a rough plan, changes are expected throughout the year. 2023 Q1 Finalising the PhEval architecture (draft is done) End-to-end pipeline for testing PhEval with Exomiser and two versions of HPO Submitting a poster to Biocuration which outlines the full vision Q2 Focus on an analytic framework around PhEval, focusing on studying how changes to ontologies affect changes in variant prioritisation Extend phenotype pipeline to enable base releases and alternative patterns Q3 Improving the analytic framework of PhEval, especially phenotype analysis All intermediate files of pipeline have a corresponding LinkML model Focus on studying the effect of KG snippets (p2ds) on VP performance Q4 Drafting a PhEval paper Building standalone pipeline that reports changes in algorithm behaviours to ontology developers.","title":"Roadmap"},{"location":"roadmap/#roadmap","text":"The Roadmap is a rough plan, changes are expected throughout the year.","title":"Roadmap"},{"location":"roadmap/#2023","text":"","title":"2023"},{"location":"roadmap/#q1","text":"Finalising the PhEval architecture (draft is done) End-to-end pipeline for testing PhEval with Exomiser and two versions of HPO Submitting a poster to Biocuration which outlines the full vision","title":"Q1"},{"location":"roadmap/#q2","text":"Focus on an analytic framework around PhEval, focusing on studying how changes to ontologies affect changes in variant prioritisation Extend phenotype pipeline to enable base releases and alternative patterns","title":"Q2"},{"location":"roadmap/#q3","text":"Improving the analytic framework of PhEval, especially phenotype analysis All intermediate files of pipeline have a corresponding LinkML model Focus on studying the effect of KG snippets (p2ds) on VP performance","title":"Q3"},{"location":"roadmap/#q4","text":"Drafting a PhEval paper Building standalone pipeline that reports changes in algorithm behaviours to ontology developers.","title":"Q4"},{"location":"styleguide/","text":"Monarch Style Guide for PhEval No code in CLI methods","title":"Monarch Style Guide for PhEval"},{"location":"styleguide/#monarch-style-guide-for-pheval","text":"No code in CLI methods","title":"Monarch Style Guide for PhEval"},{"location":"api/pheval/cli/","text":"main main CLI method for PhEval Args: verbose (int, optional): Verbose flag. quiet (bool, optional): Queit Flag. Usage: main [OPTIONS] COMMAND [ARGS]... Options: Name Type Description Default -v , --verbose integer range ( 0 and above) N/A 0 -q , --quiet text N/A None --help boolean Show this message and exit. False pheval pheval Usage: pheval [OPTIONS] COMMAND [ARGS]... Options: Name Type Description Default --help boolean Show this message and exit. False Subcommands run : PhEval Runner Command Line Interface run PhEval Runner Command Line Interface Args: input_dir (Path): The input directory (relative path: e.g exomiser-13.11) testdata_dir (Path): The input directory (relative path: e.g ./data runner (str): Runner implementation (e.g exomiser-13.11) tmp_dir (Path): The path of the temporary directory (optional) output_dir (Path): The path of the output directory config (Path): The path of the configuration file (optional e.g., config.yaml) version (str): The version of the tool implementation Usage: pheval run [OPTIONS] Options: Name Type Description Default --input-dir , -i Path The input directory (relative path: e.g exomiser-13.11) _required --testdata-dir , -t Path The input directory (relative path: e.g ./data) _required --runner , -r text Runner implementation (e.g exomiser-13.11) _required --tmp-dir , -m Path The path of the temporary directory (optional) None --output-dir , -o Path The path of the output directory _required --config , -c text The path of the configuration file (optional e.g config.yaml) None --version , -v text Version of the tool implementation. None --help boolean Show this message and exit. False pheval-utils pheval_utils Usage: pheval-utils [OPTIONS] COMMAND [ARGS]... Options: Name Type Description Default --help boolean Show this message and exit. False Subcommands benchmark : Benchmark the gene/variant prioritisation performance for a single run. benchmark-comparison : Benchmark the gene/variant prioritisation performance for two runs. create-spiked-vcfs : Spikes variants into a template VCF file for a directory of phenopackets. scramble-phenopackets : Generate noisy phenopackets from existing ones. scramble-semsim : scramble_semsim semsim-comparison : Compares two semantic similarity profiles update-phenopackets : Update gene symbols and identifiers for phenopackets. benchmark Benchmark the gene/variant prioritisation performance for a single run. Usage: pheval-utils benchmark [OPTIONS] Options: Name Type Description Default --directory , -d Path General results directory to be benchmarked, assumes contains subdirectories of pheval_gene_results/pheval_variant_results and the tool specific results directory. _required --phenopacket-dir , -p Path Full path to directory containing input phenopackets. _required --output-prefix , -o text Output file prefix. _required --ranking-method , -r text Ranking method for gene prioritisation. _required --threshold , -t float Score threshold. 0.0 --gene-analysis / --no-gene-analysis boolean Analyse gene prioritisation True --variant-analysis / --no-variant-analysis boolean Analyse variant prioritisation True --help boolean Show this message and exit. False benchmark-comparison Benchmark the gene/variant prioritisation performance for two runs. Usage: pheval-utils benchmark-comparison [OPTIONS] Options: Name Type Description Default --directory1 , -d1 Path Baseline results directory for benchmarking, assumes contains subdirectories of pheval_gene_results/pheval_variant_results and the tool specific results directory. _required --directory2 , -d2 Path Comparison results directory for benchmarking, assumes contains subdirectories of pheval_gene_results/pheval_variant_results and the tool specific results directory. _required --phenopacket-dir1 , -p1 Path Full path to directory containing phenopackets for input for baseline directory. _required --phenopacket-dir2 , -p2 Path Full path to directory containing phenopackets for input for comparison directory. _required --output-prefix , -o text Output file prefix. _required --ranking-method , -r text Ranking method for gene prioritisation. _required --threshold , -t float Score threshold. 0.0 --gene-analysis / --no-gene-analysis boolean Analyse gene prioritisation True --variant-analysis / --no-variant-analysis boolean Analyse variant prioritisation True --help boolean Show this message and exit. False create-spiked-vcfs Spikes variants into a template VCF file for a directory of phenopackets. Usage: pheval-utils create-spiked-vcfs [OPTIONS] Options: Name Type Description Default --phenopacket-path , -p Path Path to phenopacket. NOTE: This argument is mutually exclusive with arguments: [phenopacket_dir]. None --phenopacket-dir , -P Path Path to phenopacket directory for updating. NOTE: This argument is mutually exclusive with arguments: [phenopacket_path]. None --template-vcf-path , -t Path Template VCF file NOTE: This argument is mutually exclusive with arguments: [vcf_dir]. None --vcf-dir , -v Path Directory containing template VCF files NOTE: This argument is mutually exclusive with arguments: [template_vcf]. None --output-dir , -O Path Path for creation of output directory vcf --help boolean Show this message and exit. False scramble-phenopackets Generate noisy phenopackets from existing ones. Usage: pheval-utils scramble-phenopackets [OPTIONS] Options: Name Type Description Default --phenopacket-path , -p Path Path to phenopacket. NOTE: This argument is mutually exclusive with arguments: [phenopacket_dir]. None --phenopacket-dir , -P Path Path to phenopackets directory. NOTE: This argument is mutually exclusive with arguments: [phenopacket_path]. None --scramble-factor , -s float Scramble factor for randomising phenopacket phenotypic profiles. 0.5 --output-dir , -O Path Path for creation of output directory noisy_phenopackets --help boolean Show this message and exit. False scramble-semsim scramble_semsim Usage: pheval-utils scramble-semsim [OPTIONS] Options: Name Type Description Default --input , -i text Path to the semantic similarity profile to be scrambled. _required --help boolean Show this message and exit. False semsim-comparison Compares two semantic similarity profiles Args: semsim-left (Path): File path of the first semantic similarity profile semsim-right (Path): File path of the second semantic similarity profile output (Path): Output path for the difference tsv. Defaults to \"percentage_diff.semsim.tsv\". score_column (str): Score column that will be computed (e.g. jaccard_similarity) analysis (str): There are two types of analysis: heatmap - Generates a heatmap plot that shows the differences between the semantic similarity profiles using the score column for this purpose. Defaults to \"heatmap\". percentage_diff - Calculates the score column percentage difference between the semantic similarity profiles. Usage: pheval-utils semsim-comparison [OPTIONS] Options: Name Type Description Default --semsim-left , -L text Path to the first semantic similarity profile. _required --semsim-right , -R text Path to the second semantic similarity profile. _required --score-column , -s choice ( jaccard_similarity | dice_similarity | phenodigm_score ) Score column that will be used in comparison _required --analysis , -a choice ( heatmap | percentage_diff ) There are two types of analysis: heatmap - Generates a heatmap plot that shows the differences between the semantic similarity profiles using the score column for this purpose. Defaults to \"heatmap\". percentage_diff - Calculates the score column percentage difference between the semantic similarity profiles _required --output , -o text Output path for the difference tsv. Defaults to percentage_diff.semsim.tsv percentage_diff.semsim.tsv --help boolean Show this message and exit. False update-phenopackets Update gene symbols and identifiers for phenopackets. Usage: pheval-utils update-phenopackets [OPTIONS] Options: Name Type Description Default --phenopacket-path , -p Path Path to phenopacket. NOTE: This argument is mutually exclusive with arguments: [phenopacket_dir]. None --phenopacket-dir , -P Path Path to phenopacket directory for updating. NOTE: This argument is mutually exclusive with arguments: [phenopacket_path]. None --output-dir , -o Path Path to write phenopacket. _required --gene-identifier , -g choice ( ensembl_id | entrez_id | hgnc_id ) Gene identifier to add to phenopacket ensembl_id --help boolean Show this message and exit. False","title":"Cli"},{"location":"api/pheval/cli/#main","text":"main CLI method for PhEval Args: verbose (int, optional): Verbose flag. quiet (bool, optional): Queit Flag. Usage: main [OPTIONS] COMMAND [ARGS]... Options: Name Type Description Default -v , --verbose integer range ( 0 and above) N/A 0 -q , --quiet text N/A None --help boolean Show this message and exit. False","title":"main"},{"location":"api/pheval/cli/#pheval","text":"pheval Usage: pheval [OPTIONS] COMMAND [ARGS]... Options: Name Type Description Default --help boolean Show this message and exit. False Subcommands run : PhEval Runner Command Line Interface","title":"pheval"},{"location":"api/pheval/cli/#run","text":"PhEval Runner Command Line Interface Args: input_dir (Path): The input directory (relative path: e.g exomiser-13.11) testdata_dir (Path): The input directory (relative path: e.g ./data runner (str): Runner implementation (e.g exomiser-13.11) tmp_dir (Path): The path of the temporary directory (optional) output_dir (Path): The path of the output directory config (Path): The path of the configuration file (optional e.g., config.yaml) version (str): The version of the tool implementation Usage: pheval run [OPTIONS] Options: Name Type Description Default --input-dir , -i Path The input directory (relative path: e.g exomiser-13.11) _required --testdata-dir , -t Path The input directory (relative path: e.g ./data) _required --runner , -r text Runner implementation (e.g exomiser-13.11) _required --tmp-dir , -m Path The path of the temporary directory (optional) None --output-dir , -o Path The path of the output directory _required --config , -c text The path of the configuration file (optional e.g config.yaml) None --version , -v text Version of the tool implementation. None --help boolean Show this message and exit. False","title":"run"},{"location":"api/pheval/cli/#pheval-utils","text":"pheval_utils Usage: pheval-utils [OPTIONS] COMMAND [ARGS]... Options: Name Type Description Default --help boolean Show this message and exit. False Subcommands benchmark : Benchmark the gene/variant prioritisation performance for a single run. benchmark-comparison : Benchmark the gene/variant prioritisation performance for two runs. create-spiked-vcfs : Spikes variants into a template VCF file for a directory of phenopackets. scramble-phenopackets : Generate noisy phenopackets from existing ones. scramble-semsim : scramble_semsim semsim-comparison : Compares two semantic similarity profiles update-phenopackets : Update gene symbols and identifiers for phenopackets.","title":"pheval-utils"},{"location":"api/pheval/cli/#benchmark","text":"Benchmark the gene/variant prioritisation performance for a single run. Usage: pheval-utils benchmark [OPTIONS] Options: Name Type Description Default --directory , -d Path General results directory to be benchmarked, assumes contains subdirectories of pheval_gene_results/pheval_variant_results and the tool specific results directory. _required --phenopacket-dir , -p Path Full path to directory containing input phenopackets. _required --output-prefix , -o text Output file prefix. _required --ranking-method , -r text Ranking method for gene prioritisation. _required --threshold , -t float Score threshold. 0.0 --gene-analysis / --no-gene-analysis boolean Analyse gene prioritisation True --variant-analysis / --no-variant-analysis boolean Analyse variant prioritisation True --help boolean Show this message and exit. False","title":"benchmark"},{"location":"api/pheval/cli/#benchmark-comparison","text":"Benchmark the gene/variant prioritisation performance for two runs. Usage: pheval-utils benchmark-comparison [OPTIONS] Options: Name Type Description Default --directory1 , -d1 Path Baseline results directory for benchmarking, assumes contains subdirectories of pheval_gene_results/pheval_variant_results and the tool specific results directory. _required --directory2 , -d2 Path Comparison results directory for benchmarking, assumes contains subdirectories of pheval_gene_results/pheval_variant_results and the tool specific results directory. _required --phenopacket-dir1 , -p1 Path Full path to directory containing phenopackets for input for baseline directory. _required --phenopacket-dir2 , -p2 Path Full path to directory containing phenopackets for input for comparison directory. _required --output-prefix , -o text Output file prefix. _required --ranking-method , -r text Ranking method for gene prioritisation. _required --threshold , -t float Score threshold. 0.0 --gene-analysis / --no-gene-analysis boolean Analyse gene prioritisation True --variant-analysis / --no-variant-analysis boolean Analyse variant prioritisation True --help boolean Show this message and exit. False","title":"benchmark-comparison"},{"location":"api/pheval/cli/#create-spiked-vcfs","text":"Spikes variants into a template VCF file for a directory of phenopackets. Usage: pheval-utils create-spiked-vcfs [OPTIONS] Options: Name Type Description Default --phenopacket-path , -p Path Path to phenopacket. NOTE: This argument is mutually exclusive with arguments: [phenopacket_dir]. None --phenopacket-dir , -P Path Path to phenopacket directory for updating. NOTE: This argument is mutually exclusive with arguments: [phenopacket_path]. None --template-vcf-path , -t Path Template VCF file NOTE: This argument is mutually exclusive with arguments: [vcf_dir]. None --vcf-dir , -v Path Directory containing template VCF files NOTE: This argument is mutually exclusive with arguments: [template_vcf]. None --output-dir , -O Path Path for creation of output directory vcf --help boolean Show this message and exit. False","title":"create-spiked-vcfs"},{"location":"api/pheval/cli/#scramble-phenopackets","text":"Generate noisy phenopackets from existing ones. Usage: pheval-utils scramble-phenopackets [OPTIONS] Options: Name Type Description Default --phenopacket-path , -p Path Path to phenopacket. NOTE: This argument is mutually exclusive with arguments: [phenopacket_dir]. None --phenopacket-dir , -P Path Path to phenopackets directory. NOTE: This argument is mutually exclusive with arguments: [phenopacket_path]. None --scramble-factor , -s float Scramble factor for randomising phenopacket phenotypic profiles. 0.5 --output-dir , -O Path Path for creation of output directory noisy_phenopackets --help boolean Show this message and exit. False","title":"scramble-phenopackets"},{"location":"api/pheval/cli/#scramble-semsim","text":"scramble_semsim Usage: pheval-utils scramble-semsim [OPTIONS] Options: Name Type Description Default --input , -i text Path to the semantic similarity profile to be scrambled. _required --help boolean Show this message and exit. False","title":"scramble-semsim"},{"location":"api/pheval/cli/#semsim-comparison","text":"Compares two semantic similarity profiles Args: semsim-left (Path): File path of the first semantic similarity profile semsim-right (Path): File path of the second semantic similarity profile output (Path): Output path for the difference tsv. Defaults to \"percentage_diff.semsim.tsv\". score_column (str): Score column that will be computed (e.g. jaccard_similarity) analysis (str): There are two types of analysis: heatmap - Generates a heatmap plot that shows the differences between the semantic similarity profiles using the score column for this purpose. Defaults to \"heatmap\". percentage_diff - Calculates the score column percentage difference between the semantic similarity profiles. Usage: pheval-utils semsim-comparison [OPTIONS] Options: Name Type Description Default --semsim-left , -L text Path to the first semantic similarity profile. _required --semsim-right , -R text Path to the second semantic similarity profile. _required --score-column , -s choice ( jaccard_similarity | dice_similarity | phenodigm_score ) Score column that will be used in comparison _required --analysis , -a choice ( heatmap | percentage_diff ) There are two types of analysis: heatmap - Generates a heatmap plot that shows the differences between the semantic similarity profiles using the score column for this purpose. Defaults to \"heatmap\". percentage_diff - Calculates the score column percentage difference between the semantic similarity profiles _required --output , -o text Output path for the difference tsv. Defaults to percentage_diff.semsim.tsv percentage_diff.semsim.tsv --help boolean Show this message and exit. False","title":"semsim-comparison"},{"location":"api/pheval/cli/#update-phenopackets","text":"Update gene symbols and identifiers for phenopackets. Usage: pheval-utils update-phenopackets [OPTIONS] Options: Name Type Description Default --phenopacket-path , -p Path Path to phenopacket. NOTE: This argument is mutually exclusive with arguments: [phenopacket_dir]. None --phenopacket-dir , -P Path Path to phenopacket directory for updating. NOTE: This argument is mutually exclusive with arguments: [phenopacket_path]. None --output-dir , -o Path Path to write phenopacket. _required --gene-identifier , -g choice ( ensembl_id | entrez_id | hgnc_id ) Gene identifier to add to phenopacket ensembl_id --help boolean Show this message and exit. False","title":"update-phenopackets"},{"location":"api/pheval/analyse/analysis/","text":"AssessGenePrioritisation Assess gene prioritisation. Source code in src/pheval/analyse/analysis.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 class AssessGenePrioritisation : \"\"\"Assess gene prioritisation.\"\"\" def __init__ ( self , phenopacket_path : Path , results_dir : Path , standardised_gene_results : [ dict ], threshold : float , ranking_method : str , proband_causative_genes : [ ProbandCausativeGene ], ): self . phenopacket_path = phenopacket_path self . results_dir = results_dir self . standardised_gene_results = standardised_gene_results self . threshold = threshold self . ranking_method = ranking_method self . proband_causative_genes = proband_causative_genes def record_gene_prioritisation_match ( self , gene : ProbandCausativeGene , result_entry : dict , rank_stats : RankStats ) -> GenePrioritisationResultData : \"\"\"Record the gene prioritisation rank if found within results.\"\"\" rank = result_entry [ \"rank\" ] rank_stats . add_rank ( rank ) gene_match = GenePrioritisationResultData ( self . phenopacket_path , gene . gene_symbol , rank ) return gene_match def assess_gene_with_pvalue_threshold ( self , result_entry : dict , gene : ProbandCausativeGene , rank_stats : RankStats ) -> GenePrioritisationResultData : \"\"\"Record the gene prioritisation rank if it meets the pvalue threshold.\"\"\" if float ( self . threshold ) > float ( result_entry [ \"score\" ]): return self . record_gene_prioritisation_match ( gene , result_entry , rank_stats ) def assess_gene_with_threshold ( self , result_entry : dict , gene : ProbandCausativeGene , rank_stats : RankStats ) -> GenePrioritisationResultData : \"\"\"Record the gene prioritisation rank if it meets the score threshold.\"\"\" if float ( self . threshold ) < float ( result_entry [ \"score\" ]): return self . record_gene_prioritisation_match ( gene , result_entry , rank_stats ) def record_matched_gene ( self , gene , rank_stats , standardised_gene_result ): \"\"\"Return the gene rank result - dealing with the specification of a threshold.\"\"\" if float ( self . threshold ) == 0.0 : return self . record_gene_prioritisation_match ( gene , standardised_gene_result , rank_stats ) else : return ( self . assess_gene_with_threshold ( standardised_gene_result , gene , rank_stats ) if self . ranking_method != \"pValue\" else self . assess_gene_with_pvalue_threshold ( standardised_gene_result , gene , rank_stats ) ) def assess_gene_prioritisation ( self , rank_stats : RankStats , rank_records : defaultdict ): \"\"\"Assess gene prioritisation.\"\"\" for gene in self . proband_causative_genes : rank_stats . total += 1 gene_match = GenePrioritisationResultData ( self . phenopacket_path , gene . gene_symbol ) for _index , standardised_gene_result in self . standardised_gene_results . iterrows (): if ( gene . gene_identifier == standardised_gene_result [ \"gene_identifier\" ] or gene . gene_symbol == standardised_gene_result [ \"gene_symbol\" ] ): gene_match = self . record_matched_gene ( gene , rank_stats , standardised_gene_result ) PrioritisationRankRecorder ( rank_stats . total , self . results_dir , GenePrioritisationResultData ( self . phenopacket_path , gene . gene_symbol ) if gene_match is None else gene_match , rank_records , ) . record_rank () assess_gene_prioritisation ( rank_stats , rank_records ) Assess gene prioritisation. Source code in src/pheval/analyse/analysis.py 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 def assess_gene_prioritisation ( self , rank_stats : RankStats , rank_records : defaultdict ): \"\"\"Assess gene prioritisation.\"\"\" for gene in self . proband_causative_genes : rank_stats . total += 1 gene_match = GenePrioritisationResultData ( self . phenopacket_path , gene . gene_symbol ) for _index , standardised_gene_result in self . standardised_gene_results . iterrows (): if ( gene . gene_identifier == standardised_gene_result [ \"gene_identifier\" ] or gene . gene_symbol == standardised_gene_result [ \"gene_symbol\" ] ): gene_match = self . record_matched_gene ( gene , rank_stats , standardised_gene_result ) PrioritisationRankRecorder ( rank_stats . total , self . results_dir , GenePrioritisationResultData ( self . phenopacket_path , gene . gene_symbol ) if gene_match is None else gene_match , rank_records , ) . record_rank () assess_gene_with_pvalue_threshold ( result_entry , gene , rank_stats ) Record the gene prioritisation rank if it meets the pvalue threshold. Source code in src/pheval/analyse/analysis.py 235 236 237 238 239 240 def assess_gene_with_pvalue_threshold ( self , result_entry : dict , gene : ProbandCausativeGene , rank_stats : RankStats ) -> GenePrioritisationResultData : \"\"\"Record the gene prioritisation rank if it meets the pvalue threshold.\"\"\" if float ( self . threshold ) > float ( result_entry [ \"score\" ]): return self . record_gene_prioritisation_match ( gene , result_entry , rank_stats ) assess_gene_with_threshold ( result_entry , gene , rank_stats ) Record the gene prioritisation rank if it meets the score threshold. Source code in src/pheval/analyse/analysis.py 242 243 244 245 246 247 def assess_gene_with_threshold ( self , result_entry : dict , gene : ProbandCausativeGene , rank_stats : RankStats ) -> GenePrioritisationResultData : \"\"\"Record the gene prioritisation rank if it meets the score threshold.\"\"\" if float ( self . threshold ) < float ( result_entry [ \"score\" ]): return self . record_gene_prioritisation_match ( gene , result_entry , rank_stats ) record_gene_prioritisation_match ( gene , result_entry , rank_stats ) Record the gene prioritisation rank if found within results. Source code in src/pheval/analyse/analysis.py 226 227 228 229 230 231 232 233 def record_gene_prioritisation_match ( self , gene : ProbandCausativeGene , result_entry : dict , rank_stats : RankStats ) -> GenePrioritisationResultData : \"\"\"Record the gene prioritisation rank if found within results.\"\"\" rank = result_entry [ \"rank\" ] rank_stats . add_rank ( rank ) gene_match = GenePrioritisationResultData ( self . phenopacket_path , gene . gene_symbol , rank ) return gene_match record_matched_gene ( gene , rank_stats , standardised_gene_result ) Return the gene rank result - dealing with the specification of a threshold. Source code in src/pheval/analyse/analysis.py 249 250 251 252 253 254 255 256 257 258 259 260 def record_matched_gene ( self , gene , rank_stats , standardised_gene_result ): \"\"\"Return the gene rank result - dealing with the specification of a threshold.\"\"\" if float ( self . threshold ) == 0.0 : return self . record_gene_prioritisation_match ( gene , standardised_gene_result , rank_stats ) else : return ( self . assess_gene_with_threshold ( standardised_gene_result , gene , rank_stats ) if self . ranking_method != \"pValue\" else self . assess_gene_with_pvalue_threshold ( standardised_gene_result , gene , rank_stats ) ) AssessVariantPrioritisation Assess variant prioritisation. Source code in src/pheval/analyse/analysis.py 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 class AssessVariantPrioritisation : \"\"\"Assess variant prioritisation.\"\"\" def __init__ ( self , phenopacket_path : Path , results_dir : Path , standardised_variant_results : [ dict ], threshold : float , ranking_method : str , proband_causative_variants : [ GenomicVariant ], ): self . phenopacket_path = phenopacket_path self . results_dir = results_dir self . standardised_variant_results = standardised_variant_results self . threshold = threshold self . ranking_method = ranking_method self . proband_causative_variants = proband_causative_variants def record_variant_prioritisation_match ( self , result_entry : pd . Series , rank_stats : RankStats , ) -> VariantPrioritisationResultData : \"\"\"Record the variant prioritisation rank if found within results.\"\"\" rank = result_entry [ \"rank\" ] rank_stats . add_rank ( rank ) variant_match = VariantPrioritisationResultData ( self . phenopacket_path , GenomicVariant ( chrom = result_entry [ \"chromosome\" ], pos = result_entry [ \"start\" ], ref = result_entry [ \"ref\" ], alt = result_entry [ \"alt\" ], ), rank , ) return variant_match def assess_variant_with_pvalue_threshold ( self , result_entry : pd . Series , rank_stats : RankStats ) -> VariantPrioritisationResultData : \"\"\"Record the variant prioritisation rank if it meets the pvalue threshold.\"\"\" if float ( self . threshold ) > float ( result_entry [ \"score\" ]): return self . record_variant_prioritisation_match ( result_entry , rank_stats ) def assess_variant_with_threshold ( self , result_entry : pd . Series , rank_stats : RankStats ) -> VariantPrioritisationResultData : \"\"\"Record the variant prioritisation rank if it meets the score threshold.\"\"\" if float ( self . threshold ) < float ( result_entry [ \"score\" ]): return self . record_variant_prioritisation_match ( result_entry , rank_stats ) def record_matched_variant ( self , rank_stats , result ) -> VariantPrioritisationResultData : \"\"\"Return the variant rank result - dealing with the specification of a threshold.\"\"\" if float ( self . threshold ) == 0.0 : return self . record_variant_prioritisation_match ( result , rank_stats ) else : return ( self . assess_variant_with_threshold ( result , rank_stats ) if self . ranking_method != \"pValue\" else self . assess_variant_with_pvalue_threshold ( result , rank_stats ) ) def assess_variant_prioritisation ( self , rank_stats : RankStats , rank_records : defaultdict ): \"\"\"Assess variant prioritisation.\"\"\" for variant in self . proband_causative_variants : rank_stats . total += 1 variant_match = VariantPrioritisationResultData ( self . phenopacket_path , variant ) for _index , result in self . standardised_variant_results . iterrows (): result_variant = GenomicVariant ( chrom = result [ \"chromosome\" ], pos = result [ \"start\" ], ref = result [ \"ref\" ], alt = result [ \"alt\" ], ) if variant == result_variant : variant_match = self . record_matched_variant ( rank_stats , result ) PrioritisationRankRecorder ( rank_stats . total , self . results_dir , VariantPrioritisationResultData ( self . phenopacket_path , variant ) if variant_match is None else variant_match , rank_records , ) . record_rank () assess_variant_prioritisation ( rank_stats , rank_records ) Assess variant prioritisation. Source code in src/pheval/analyse/analysis.py 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 def assess_variant_prioritisation ( self , rank_stats : RankStats , rank_records : defaultdict ): \"\"\"Assess variant prioritisation.\"\"\" for variant in self . proband_causative_variants : rank_stats . total += 1 variant_match = VariantPrioritisationResultData ( self . phenopacket_path , variant ) for _index , result in self . standardised_variant_results . iterrows (): result_variant = GenomicVariant ( chrom = result [ \"chromosome\" ], pos = result [ \"start\" ], ref = result [ \"ref\" ], alt = result [ \"alt\" ], ) if variant == result_variant : variant_match = self . record_matched_variant ( rank_stats , result ) PrioritisationRankRecorder ( rank_stats . total , self . results_dir , VariantPrioritisationResultData ( self . phenopacket_path , variant ) if variant_match is None else variant_match , rank_records , ) . record_rank () assess_variant_with_pvalue_threshold ( result_entry , rank_stats ) Record the variant prioritisation rank if it meets the pvalue threshold. Source code in src/pheval/analyse/analysis.py 324 325 326 327 328 329 def assess_variant_with_pvalue_threshold ( self , result_entry : pd . Series , rank_stats : RankStats ) -> VariantPrioritisationResultData : \"\"\"Record the variant prioritisation rank if it meets the pvalue threshold.\"\"\" if float ( self . threshold ) > float ( result_entry [ \"score\" ]): return self . record_variant_prioritisation_match ( result_entry , rank_stats ) assess_variant_with_threshold ( result_entry , rank_stats ) Record the variant prioritisation rank if it meets the score threshold. Source code in src/pheval/analyse/analysis.py 331 332 333 334 335 336 def assess_variant_with_threshold ( self , result_entry : pd . Series , rank_stats : RankStats ) -> VariantPrioritisationResultData : \"\"\"Record the variant prioritisation rank if it meets the score threshold.\"\"\" if float ( self . threshold ) < float ( result_entry [ \"score\" ]): return self . record_variant_prioritisation_match ( result_entry , rank_stats ) record_matched_variant ( rank_stats , result ) Return the variant rank result - dealing with the specification of a threshold. Source code in src/pheval/analyse/analysis.py 338 339 340 341 342 343 344 345 346 347 def record_matched_variant ( self , rank_stats , result ) -> VariantPrioritisationResultData : \"\"\"Return the variant rank result - dealing with the specification of a threshold.\"\"\" if float ( self . threshold ) == 0.0 : return self . record_variant_prioritisation_match ( result , rank_stats ) else : return ( self . assess_variant_with_threshold ( result , rank_stats ) if self . ranking_method != \"pValue\" else self . assess_variant_with_pvalue_threshold ( result , rank_stats ) ) record_variant_prioritisation_match ( result_entry , rank_stats ) Record the variant prioritisation rank if found within results. Source code in src/pheval/analyse/analysis.py 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 def record_variant_prioritisation_match ( self , result_entry : pd . Series , rank_stats : RankStats , ) -> VariantPrioritisationResultData : \"\"\"Record the variant prioritisation rank if found within results.\"\"\" rank = result_entry [ \"rank\" ] rank_stats . add_rank ( rank ) variant_match = VariantPrioritisationResultData ( self . phenopacket_path , GenomicVariant ( chrom = result_entry [ \"chromosome\" ], pos = result_entry [ \"start\" ], ref = result_entry [ \"ref\" ], alt = result_entry [ \"alt\" ], ), rank , ) return variant_match GenePrioritisationResultData dataclass Store rank data for causative genes. Source code in src/pheval/analyse/analysis.py 26 27 28 29 30 31 32 @dataclass class GenePrioritisationResultData : \"\"\"Store rank data for causative genes.\"\"\" phenopacket : Path gene : str rank : int = 0 PrioritisationRankRecorder dataclass Compare the ranks of different runs. Source code in src/pheval/analyse/analysis.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 @dataclass class PrioritisationRankRecorder : \"\"\"Compare the ranks of different runs.\"\"\" index : int directory : Path prioritisation_run_comparison : VariantPrioritisationResultData or GenePrioritisationResultData run_comparison : defaultdict def record_rank ( self ) -> None : \"\"\"Records the rank for different runs.\"\"\" self . run_comparison [ self . index ][ \"Phenopacket\" ] = self . prioritisation_run_comparison . phenopacket . name if type ( self . prioritisation_run_comparison ) is GenePrioritisationResultData : self . run_comparison [ self . index ][ \"Gene\" ] = self . prioritisation_run_comparison . gene if type ( self . prioritisation_run_comparison ) is VariantPrioritisationResultData : variant_info = self . prioritisation_run_comparison . variant self . run_comparison [ self . index ][ \"Variant\" ] = \"_\" . join ( [ variant_info . chrom , str ( variant_info . pos ), variant_info . ref , variant_info . alt ] ) self . run_comparison [ self . index ][ self . directory ] = self . prioritisation_run_comparison . rank record_rank () Records the rank for different runs. Source code in src/pheval/analyse/analysis.py 53 54 55 56 57 58 59 60 61 62 63 64 65 def record_rank ( self ) -> None : \"\"\"Records the rank for different runs.\"\"\" self . run_comparison [ self . index ][ \"Phenopacket\" ] = self . prioritisation_run_comparison . phenopacket . name if type ( self . prioritisation_run_comparison ) is GenePrioritisationResultData : self . run_comparison [ self . index ][ \"Gene\" ] = self . prioritisation_run_comparison . gene if type ( self . prioritisation_run_comparison ) is VariantPrioritisationResultData : variant_info = self . prioritisation_run_comparison . variant self . run_comparison [ self . index ][ \"Variant\" ] = \"_\" . join ( [ variant_info . chrom , str ( variant_info . pos ), variant_info . ref , variant_info . alt ] ) self . run_comparison [ self . index ][ self . directory ] = self . prioritisation_run_comparison . rank RankComparisonGenerator Write the run comparison of rank assignment for prioritisation. Source code in src/pheval/analyse/analysis.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 class RankComparisonGenerator : \"\"\"Write the run comparison of rank assignment for prioritisation.\"\"\" def __init__ ( self , run_comparison : defaultdict ): self . run_comparison = run_comparison def generate_dataframe ( self ) -> pd . DataFrame : \"\"\"Generate pandas dataframe.\"\"\" return pd . DataFrame . from_dict ( self . run_comparison , orient = \"index\" ) def calculate_rank_difference ( self ) -> pd . DataFrame : \"\"\"Calculate the rank decrease for runs - taking the first directory as a baseline.\"\"\" comparison_df = self . generate_dataframe () comparison_df [ \"rank_decrease\" ] = comparison_df . iloc [:, 3 ] - comparison_df . iloc [:, 2 ] return comparison_df def generate_gene_output ( self , prefix : str ) -> None : \"\"\"Generate the output for gene prioritisation ranks.\"\"\" self . generate_dataframe () . to_csv ( prefix + \"-gene_rank_comparison.tsv\" , sep = \" \\t \" ) def generate_variant_output ( self , prefix : str ) -> None : \"\"\"Generate the output for variant prioritisation ranks.\"\"\" self . generate_dataframe () . to_csv ( prefix + \"-variant_rank_comparison.tsv\" , sep = \" \\t \" ) def generate_gene_comparison_output ( self , prefix : str ) -> None : \"\"\"Generate the output for gene prioritisation rank comparison.\"\"\" self . calculate_rank_difference () . to_csv ( prefix + \"-gene_rank_comparison.tsv\" , sep = \" \\t \" ) def generate_variant_comparison_output ( self , prefix : str ) -> None : \"\"\"Generate the output for variant prioritisation rank comparison.\"\"\" self . calculate_rank_difference () . to_csv ( prefix + \"-variant_rank_comparison.tsv\" , sep = \" \\t \" ) calculate_rank_difference () Calculate the rank decrease for runs - taking the first directory as a baseline. Source code in src/pheval/analyse/analysis.py 78 79 80 81 82 def calculate_rank_difference ( self ) -> pd . DataFrame : \"\"\"Calculate the rank decrease for runs - taking the first directory as a baseline.\"\"\" comparison_df = self . generate_dataframe () comparison_df [ \"rank_decrease\" ] = comparison_df . iloc [:, 3 ] - comparison_df . iloc [:, 2 ] return comparison_df generate_dataframe () Generate pandas dataframe. Source code in src/pheval/analyse/analysis.py 74 75 76 def generate_dataframe ( self ) -> pd . DataFrame : \"\"\"Generate pandas dataframe.\"\"\" return pd . DataFrame . from_dict ( self . run_comparison , orient = \"index\" ) generate_gene_comparison_output ( prefix ) Generate the output for gene prioritisation rank comparison. Source code in src/pheval/analyse/analysis.py 92 93 94 def generate_gene_comparison_output ( self , prefix : str ) -> None : \"\"\"Generate the output for gene prioritisation rank comparison.\"\"\" self . calculate_rank_difference () . to_csv ( prefix + \"-gene_rank_comparison.tsv\" , sep = \" \\t \" ) generate_gene_output ( prefix ) Generate the output for gene prioritisation ranks. Source code in src/pheval/analyse/analysis.py 84 85 86 def generate_gene_output ( self , prefix : str ) -> None : \"\"\"Generate the output for gene prioritisation ranks.\"\"\" self . generate_dataframe () . to_csv ( prefix + \"-gene_rank_comparison.tsv\" , sep = \" \\t \" ) generate_variant_comparison_output ( prefix ) Generate the output for variant prioritisation rank comparison. Source code in src/pheval/analyse/analysis.py 96 97 98 def generate_variant_comparison_output ( self , prefix : str ) -> None : \"\"\"Generate the output for variant prioritisation rank comparison.\"\"\" self . calculate_rank_difference () . to_csv ( prefix + \"-variant_rank_comparison.tsv\" , sep = \" \\t \" ) generate_variant_output ( prefix ) Generate the output for variant prioritisation ranks. Source code in src/pheval/analyse/analysis.py 88 89 90 def generate_variant_output ( self , prefix : str ) -> None : \"\"\"Generate the output for variant prioritisation ranks.\"\"\" self . generate_dataframe () . to_csv ( prefix + \"-variant_rank_comparison.tsv\" , sep = \" \\t \" ) RankStats dataclass Class for keeping track of the rank stats. Source code in src/pheval/analyse/analysis.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 @dataclass class RankStats : \"\"\"Class for keeping track of the rank stats.\"\"\" top : int = 0 top3 : int = 0 top5 : int = 0 found : int = 0 total : int = 0 reciprocal_ranks : list = field ( default_factory = list ) def add_rank ( self , rank : int ) -> None : \"\"\"Add rank for phenopacket.\"\"\" self . reciprocal_ranks . append ( 1 / rank ) self . found += 1 if rank == 1 : self . top += 1 if rank != \"\" and rank <= 3 : self . top3 += 1 if rank != \"\" and rank <= 5 : self . top5 += 1 def percentage_rank ( self , value : int ) -> float : \"\"\"Return a percentage rank.\"\"\" return 100 * value / self . found def percentage_top ( self ) -> float : \"\"\"Return percentage of top matches.\"\"\" return self . percentage_rank ( self . top ) def percentage_top3 ( self ) -> float : \"\"\"Return percentage of matches in the top3.\"\"\" return self . percentage_rank ( self . top3 ) def percentage_top5 ( self ) -> float : \"\"\"Return percentage of matches in the top5.\"\"\" return self . percentage_rank ( self . top5 ) def percentage_found ( self ) -> float : \"\"\"Return percentage of matches found.\"\"\" return 100 * self . found / self . total def mean_reciprocal_rank ( self ) -> float : \"\"\"Return the mean reciprocal rank.\"\"\" return mean ( self . reciprocal_ranks ) add_rank ( rank ) Add rank for phenopacket. Source code in src/pheval/analyse/analysis.py 112 113 114 115 116 117 118 119 120 121 def add_rank ( self , rank : int ) -> None : \"\"\"Add rank for phenopacket.\"\"\" self . reciprocal_ranks . append ( 1 / rank ) self . found += 1 if rank == 1 : self . top += 1 if rank != \"\" and rank <= 3 : self . top3 += 1 if rank != \"\" and rank <= 5 : self . top5 += 1 mean_reciprocal_rank () Return the mean reciprocal rank. Source code in src/pheval/analyse/analysis.py 143 144 145 def mean_reciprocal_rank ( self ) -> float : \"\"\"Return the mean reciprocal rank.\"\"\" return mean ( self . reciprocal_ranks ) percentage_found () Return percentage of matches found. Source code in src/pheval/analyse/analysis.py 139 140 141 def percentage_found ( self ) -> float : \"\"\"Return percentage of matches found.\"\"\" return 100 * self . found / self . total percentage_rank ( value ) Return a percentage rank. Source code in src/pheval/analyse/analysis.py 123 124 125 def percentage_rank ( self , value : int ) -> float : \"\"\"Return a percentage rank.\"\"\" return 100 * value / self . found percentage_top () Return percentage of top matches. Source code in src/pheval/analyse/analysis.py 127 128 129 def percentage_top ( self ) -> float : \"\"\"Return percentage of top matches.\"\"\" return self . percentage_rank ( self . top ) percentage_top3 () Return percentage of matches in the top3. Source code in src/pheval/analyse/analysis.py 131 132 133 def percentage_top3 ( self ) -> float : \"\"\"Return percentage of matches in the top3.\"\"\" return self . percentage_rank ( self . top3 ) percentage_top5 () Return percentage of matches in the top5. Source code in src/pheval/analyse/analysis.py 135 136 137 def percentage_top5 ( self ) -> float : \"\"\"Return percentage of matches in the top5.\"\"\" return self . percentage_rank ( self . top5 ) RankStatsWriter Write the rank stats for each run. Source code in src/pheval/analyse/analysis.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 class RankStatsWriter : \"\"\"Write the rank stats for each run.\"\"\" def __init__ ( self , file : Path ): self . file = open ( file , \"w\" ) self . writer = csv . writer ( self . file , delimiter = \" \\t \" ) self . writer . writerow ( [ \"results_directory_path\" , \"top\" , \"top3\" , \"top5\" , \"found\" , \"total\" , \"mean_reciprocal_rank\" , \"percentage_top\" , \"percentage_top3\" , \"percentage_top5\" , \"percentage_found\" , ] ) def write_row ( self , directory : Path , rank_stats : RankStats ) -> None : \"\"\"Write summary rank stats row for run.\"\"\" try : self . writer . writerow ( [ directory , rank_stats . top , rank_stats . top3 , rank_stats . top5 , rank_stats . found , rank_stats . total , rank_stats . mean_reciprocal_rank (), rank_stats . percentage_top (), rank_stats . percentage_top3 (), rank_stats . percentage_top5 (), rank_stats . percentage_found (), ] ) except IOError : print ( \"Error writing \" , self . file ) def close ( self ): \"\"\"Close file.\"\"\" try : self . file . close () except IOError : print ( \"Error closing \" , self . file ) close () Close file. Source code in src/pheval/analyse/analysis.py 191 192 193 194 195 196 def close ( self ): \"\"\"Close file.\"\"\" try : self . file . close () except IOError : print ( \"Error closing \" , self . file ) write_row ( directory , rank_stats ) Write summary rank stats row for run. Source code in src/pheval/analyse/analysis.py 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 def write_row ( self , directory : Path , rank_stats : RankStats ) -> None : \"\"\"Write summary rank stats row for run.\"\"\" try : self . writer . writerow ( [ directory , rank_stats . top , rank_stats . top3 , rank_stats . top5 , rank_stats . found , rank_stats . total , rank_stats . mean_reciprocal_rank (), rank_stats . percentage_top (), rank_stats . percentage_top3 (), rank_stats . percentage_top5 (), rank_stats . percentage_found (), ] ) except IOError : print ( \"Error writing \" , self . file ) TrackGeneComparisons dataclass Track the gene ranks for each result in a result directory. Source code in src/pheval/analyse/analysis.py 533 534 535 536 537 538 @dataclass class TrackGeneComparisons : \"\"\"Track the gene ranks for each result in a result directory.\"\"\" directory : Path gene_results : dict TrackInputOutputDirectories dataclass Track the input testdata for a corresponding standardised output directory Source code in src/pheval/analyse/analysis.py 199 200 201 202 203 204 @dataclass class TrackInputOutputDirectories : \"\"\"Track the input testdata for a corresponding standardised output directory\"\"\" phenopacket_dir : Path results_dir : Path TrackVariantComparisons dataclass Track the variant ranks for each result in a result directory. Source code in src/pheval/analyse/analysis.py 541 542 543 544 545 546 @dataclass class TrackVariantComparisons : \"\"\"Track the variant ranks for each result in a result directory.\"\"\" directory : Path variant_results : dict VariantPrioritisationResultData dataclass Store rank data for causative variants. Source code in src/pheval/analyse/analysis.py 35 36 37 38 39 40 41 @dataclass class VariantPrioritisationResultData : \"\"\"Store rank data for causative variants.\"\"\" phenopacket : Path variant : GenomicVariant rank : int = 0 assess_phenopacket_gene_prioritisation ( standardised_gene_result , ranking_method , results_dir_and_input , threshold , gene_rank_stats , gene_rank_comparison ) Assess gene prioritisation for a phenopacket. Source code in src/pheval/analyse/analysis.py 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 def assess_phenopacket_gene_prioritisation ( standardised_gene_result : Path , ranking_method : str , results_dir_and_input : TrackInputOutputDirectories , threshold : float , gene_rank_stats : RankStats , gene_rank_comparison : defaultdict , ): \"\"\"Assess gene prioritisation for a phenopacket.\"\"\" phenopacket_path = obtain_closest_file_name ( standardised_gene_result , all_files ( results_dir_and_input . phenopacket_dir ) ) proband_causative_genes = obtain_causative_genes ( phenopacket_path ) AssessGenePrioritisation ( phenopacket_path , results_dir_and_input . results_dir . joinpath ( \"pheval_gene_results/\" ), read_standardised_result ( standardised_gene_result ), threshold , ranking_method , proband_causative_genes , ) . assess_gene_prioritisation ( gene_rank_stats , gene_rank_comparison ) assess_phenopacket_variant_prioritisation ( standardised_variant_result , ranking_method , results_dir_and_input , threshold , variant_rank_stats , variant_rank_comparison ) Assess variant prioritisation for a phenopacket Source code in src/pheval/analyse/analysis.py 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 def assess_phenopacket_variant_prioritisation ( standardised_variant_result : Path , ranking_method : str , results_dir_and_input : TrackInputOutputDirectories , threshold : float , variant_rank_stats : RankStats , variant_rank_comparison : defaultdict , ): \"\"\"Assess variant prioritisation for a phenopacket\"\"\" phenopacket_path = obtain_closest_file_name ( standardised_variant_result , all_files ( results_dir_and_input . phenopacket_dir ) ) proband_causative_variants = obtain_causative_variants ( phenopacket_path ) AssessVariantPrioritisation ( phenopacket_path , results_dir_and_input . results_dir . joinpath ( \"pheval_variant_results/\" ), read_standardised_result ( standardised_variant_result ), threshold , ranking_method , proband_causative_variants , ) . assess_variant_prioritisation ( variant_rank_stats , variant_rank_comparison ) assess_prioritisation_for_results_directory ( results_directory_and_input , ranking_method , threshold , gene_rank_comparison , variant_rank_comparison , gene_stats_writer , variants_stats_writer , gene_analysis , variant_analysis ) Assess prioritisation for a single results directory. Source code in src/pheval/analyse/analysis.py 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 def assess_prioritisation_for_results_directory ( results_directory_and_input : TrackInputOutputDirectories , ranking_method : str , threshold : float , gene_rank_comparison : defaultdict , variant_rank_comparison : defaultdict , gene_stats_writer : RankStatsWriter , variants_stats_writer : RankStatsWriter , gene_analysis : bool , variant_analysis : bool , ): \"\"\"Assess prioritisation for a single results directory.\"\"\" gene_rank_stats , variant_rank_stats = RankStats (), RankStats () if gene_analysis : for standardised_result in files_with_suffix ( results_directory_and_input . results_dir . joinpath ( \"pheval_gene_results/\" ), \".tsv\" ): assess_phenopacket_gene_prioritisation ( standardised_result , ranking_method , results_directory_and_input , threshold , gene_rank_stats , gene_rank_comparison , ) if variant_analysis : for standardised_result in files_with_suffix ( results_directory_and_input . results_dir . joinpath ( \"pheval_variant_results/\" ), \".tsv\" , ): assess_phenopacket_variant_prioritisation ( standardised_result , ranking_method , results_directory_and_input , threshold , variant_rank_stats , variant_rank_comparison , ) gene_stats_writer . write_row ( results_directory_and_input . results_dir , gene_rank_stats ) if gene_analysis else None variants_stats_writer . write_row ( results_directory_and_input . results_dir , variant_rank_stats ) if variant_analysis else None return gene_rank_comparison , variant_rank_comparison benchmark ( directory , phenopacket_dir , ranking_method , output_prefix , threshold , gene_analysis , variant_analysis ) Benchmark the gene/variant prioritisation performance for a single run. Source code in src/pheval/analyse/analysis.py 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 @click . command () @click . option ( \"--directory\" , \"-d\" , required = True , metavar = \"PATH\" , help = \"General results directory to be benchmarked, assumes contains subdirectories of pheval_gene_results/\" \"pheval_variant_results and the tool specific results directory. \" , type = Path , ) @click . option ( \"--phenopacket-dir\" , \"-p\" , required = True , metavar = \"PATH\" , help = \"Full path to directory containing input phenopackets.\" , type = Path , ) @click . option ( \"--output-prefix\" , \"-o\" , metavar = \"<str>\" , required = True , help = \" Output file prefix. \" , ) @click . option ( \"--ranking-method\" , \"-r\" , required = True , help = \"Ranking method for gene prioritisation.\" , ) @click . option ( \"--threshold\" , \"-t\" , metavar = \"<float>\" , default = float ( 0.0 ), required = False , help = \"Score threshold.\" , type = float , ) @click . option ( \"--gene-analysis/--no-gene-analysis\" , default = True , required = False , type = bool , show_default = True , help = \"Analyse gene prioritisation\" , ) @click . option ( \"--variant-analysis/--no-variant-analysis\" , default = True , required = False , type = bool , show_default = True , help = \"Analyse variant prioritisation\" , ) def benchmark ( directory : Path , phenopacket_dir : Path , ranking_method : str , output_prefix : str , threshold : float , gene_analysis : bool , variant_analysis : bool , ): \"\"\"Benchmark the gene/variant prioritisation performance for a single run.\"\"\" benchmark_directory ( TrackInputOutputDirectories ( results_dir = directory , phenopacket_dir = phenopacket_dir ), ranking_method , output_prefix , threshold , gene_analysis , variant_analysis , ) benchmark_comparison ( directory1 , directory2 , phenopacket_dir1 , phenopacket_dir2 , ranking_method , output_prefix , threshold , gene_analysis , variant_analysis ) Benchmark the gene/variant prioritisation performance for two runs. Source code in src/pheval/analyse/analysis.py 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 @click . command () @click . option ( \"--directory1\" , \"-d1\" , required = True , metavar = \"PATH\" , help = \"Baseline results directory for benchmarking, assumes contains subdirectories of pheval_gene_results/\" \"pheval_variant_results and the tool specific results directory.\" , type = Path , ) @click . option ( \"--directory2\" , \"-d2\" , required = True , metavar = \"PATH\" , help = \"Comparison results directory for benchmarking, assumes contains subdirectories of pheval_gene_results/\" \"pheval_variant_results and the tool specific results directory.\" , type = Path , ) @click . option ( \"--phenopacket-dir1\" , \"-p1\" , required = True , metavar = \"PATH\" , help = \"Full path to directory containing phenopackets for input for baseline directory.\" , type = Path , ) @click . option ( \"--phenopacket-dir2\" , \"-p2\" , required = True , metavar = \"PATH\" , help = \"Full path to directory containing phenopackets for input for comparison directory.\" , type = Path , ) @click . option ( \"--output-prefix\" , \"-o\" , metavar = \"<str>\" , required = True , help = \" Output file prefix. \" , ) @click . option ( \"--ranking-method\" , \"-r\" , required = True , help = \"Ranking method for gene prioritisation.\" , ) @click . option ( \"--threshold\" , \"-t\" , metavar = \"<float>\" , default = float ( 0.0 ), required = False , help = \"Score threshold.\" , type = float , ) @click . option ( \"--gene-analysis/--no-gene-analysis\" , default = True , required = False , type = bool , show_default = True , help = \"Analyse gene prioritisation\" , ) @click . option ( \"--variant-analysis/--no-variant-analysis\" , default = True , required = False , type = bool , show_default = True , help = \"Analyse variant prioritisation\" , ) def benchmark_comparison ( directory1 : Path , directory2 : Path , phenopacket_dir1 : Path , phenopacket_dir2 : Path , ranking_method : str , output_prefix : str , threshold : float , gene_analysis : bool , variant_analysis : bool , ): \"\"\"Benchmark the gene/variant prioritisation performance for two runs.\"\"\" benchmark_runs ( [ TrackInputOutputDirectories ( results_dir = directory1 , phenopacket_dir = phenopacket_dir1 ), TrackInputOutputDirectories ( results_dir = directory2 , phenopacket_dir = phenopacket_dir2 ), ], ranking_method , output_prefix , threshold , gene_analysis , variant_analysis , ) benchmark_directory ( results_dir_and_input , ranking_method , output_prefix , threshold , gene_analysis , variant_analysis ) Benchmark prioritisation performance for a single directory. Source code in src/pheval/analyse/analysis.py 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 def benchmark_directory ( results_dir_and_input : TrackInputOutputDirectories , ranking_method : str , output_prefix : str , threshold : float , gene_analysis : bool , variant_analysis : bool , ): \"\"\"Benchmark prioritisation performance for a single directory.\"\"\" gene_stats_writer = ( RankStatsWriter ( Path ( output_prefix + \"-gene_summary.tsv\" )) if gene_analysis else None ) variants_stats_writer = ( RankStatsWriter ( Path ( output_prefix + \"-variant_summary.tsv\" )) if variant_analysis else None ) gene_rank_comparison , variant_rank_comparison = defaultdict ( dict ), defaultdict ( dict ) assess_prioritisation_for_results_directory ( results_dir_and_input , ranking_method , threshold , gene_rank_comparison , variant_rank_comparison , gene_stats_writer , variants_stats_writer , gene_analysis , variant_analysis , ) RankComparisonGenerator ( gene_rank_comparison ) . generate_gene_output ( f \" { results_dir_and_input . results_dir . name } \" ) if gene_analysis else None RankComparisonGenerator ( variant_rank_comparison ) . generate_variant_output ( f \" { results_dir_and_input . results_dir . name } \" ) if variant_analysis else None gene_stats_writer . close () if gene_analysis else None variants_stats_writer . close () if variant_analysis else None benchmark_runs ( results_directories , ranking_method , output_prefix , threshold , gene_analysis , variant_analysis ) Benchmark several result directories. Source code in src/pheval/analyse/analysis.py 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 def benchmark_runs ( results_directories : [ TrackInputOutputDirectories ], ranking_method : str , output_prefix : str , threshold : float , gene_analysis : bool , variant_analysis : bool , ): \"\"\"Benchmark several result directories.\"\"\" gene_stats_writer = ( RankStatsWriter ( Path ( output_prefix + \"-gene_summary.tsv\" )) if gene_analysis else None ) variants_stats_writer = ( RankStatsWriter ( Path ( output_prefix + \"-variant_summary.tsv\" )) if variant_analysis else None ) gene_ranks_for_directories = [] variant_ranks_for_directories = [] for results_dir_and_input in results_directories : gene_rank_comparison , variant_rank_comparison = defaultdict ( dict ), defaultdict ( dict ) gene_ranks , variant_ranks = assess_prioritisation_for_results_directory ( results_dir_and_input , ranking_method , threshold , gene_rank_comparison , variant_rank_comparison , gene_stats_writer , variants_stats_writer , gene_analysis , variant_analysis , ) gene_ranks_for_directories . append ( TrackGeneComparisons ( results_dir_and_input . results_dir , gene_ranks ) ) variant_ranks_for_directories . append ( TrackVariantComparisons ( results_dir_and_input . results_dir , variant_ranks ) ) generate_gene_rank_comparisons ( list ( itertools . combinations ( gene_ranks_for_directories , 2 )) ) if gene_analysis else None generate_variant_rank_comparisons ( list ( itertools . combinations ( variant_ranks_for_directories , 2 )) ) if variant_analysis else None generate_gene_rank_comparisons ( comparison_ranks ) Generate the gene rank comparison of two result directories. Source code in src/pheval/analyse/analysis.py 549 550 551 552 553 554 555 def generate_gene_rank_comparisons ( comparison_ranks : [ tuple ]) -> None : \"\"\"Generate the gene rank comparison of two result directories.\"\"\" for pair in comparison_ranks : merged_results = merge_results ( pair [ 0 ] . gene_results , pair [ 1 ] . gene_results ) RankComparisonGenerator ( merged_results ) . generate_gene_comparison_output ( f \" { pair [ 0 ] . directory . name } __v__ { pair [ 1 ] . directory . name } \" ) generate_variant_rank_comparisons ( comparison_ranks ) Generate the variant rank comparison of two result directories. Source code in src/pheval/analyse/analysis.py 558 559 560 561 562 563 564 def generate_variant_rank_comparisons ( comparison_ranks : [ tuple ]) -> None : \"\"\"Generate the variant rank comparison of two result directories.\"\"\" for pair in comparison_ranks : merged_results = merge_results ( pair [ 0 ] . variant_results , pair [ 1 ] . variant_results ) RankComparisonGenerator ( merged_results ) . generate_variant_comparison_output ( f \" { pair [ 0 ] . directory . name } __v__ { pair [ 1 ] . directory . name } \" ) merge_results ( result1 , result2 ) Merge two nested dictionaries containing results on commonalities. Source code in src/pheval/analyse/analysis.py 517 518 519 520 521 522 523 524 525 526 527 528 529 530 def merge_results ( result1 , result2 ): \"\"\"Merge two nested dictionaries containing results on commonalities.\"\"\" for key , val in result1 . items (): if type ( val ) == dict : if key in result2 and type ( result2 [ key ] == dict ): merge_results ( result1 [ key ], result2 [ key ]) else : if key in result2 : result1 [ key ] = result2 [ key ] for key , val in result2 . items (): if key not in result1 : result1 [ key ] = val return result1 obtain_causative_genes ( phenopacket_path ) Obtain causative genes from a phenopacket. Source code in src/pheval/analyse/analysis.py 373 374 375 376 377 def obtain_causative_genes ( phenopacket_path ): \"\"\"Obtain causative genes from a phenopacket.\"\"\" phenopacket = phenopacket_reader ( phenopacket_path ) phenopacket_util = PhenopacketUtil ( phenopacket ) return phenopacket_util . diagnosed_genes () obtain_causative_variants ( phenopacket_path ) Obtain causative variants from a phenopacket. Source code in src/pheval/analyse/analysis.py 380 381 382 383 384 def obtain_causative_variants ( phenopacket_path ): \"\"\"Obtain causative variants from a phenopacket.\"\"\" phenopacket = phenopacket_reader ( phenopacket_path ) phenopacket_util = PhenopacketUtil ( phenopacket ) return phenopacket_util . diagnosed_variants () read_standardised_result ( standardised_result_path ) Read the standardised result output and return a dictionary. Source code in src/pheval/analyse/analysis.py 21 22 23 def read_standardised_result ( standardised_result_path : Path ) -> dict : \"\"\"Read the standardised result output and return a dictionary.\"\"\" return pd . read_csv ( standardised_result_path , delimiter = \" \\t \" )","title":"Analysis"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.AssessGenePrioritisation","text":"Assess gene prioritisation. Source code in src/pheval/analyse/analysis.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 class AssessGenePrioritisation : \"\"\"Assess gene prioritisation.\"\"\" def __init__ ( self , phenopacket_path : Path , results_dir : Path , standardised_gene_results : [ dict ], threshold : float , ranking_method : str , proband_causative_genes : [ ProbandCausativeGene ], ): self . phenopacket_path = phenopacket_path self . results_dir = results_dir self . standardised_gene_results = standardised_gene_results self . threshold = threshold self . ranking_method = ranking_method self . proband_causative_genes = proband_causative_genes def record_gene_prioritisation_match ( self , gene : ProbandCausativeGene , result_entry : dict , rank_stats : RankStats ) -> GenePrioritisationResultData : \"\"\"Record the gene prioritisation rank if found within results.\"\"\" rank = result_entry [ \"rank\" ] rank_stats . add_rank ( rank ) gene_match = GenePrioritisationResultData ( self . phenopacket_path , gene . gene_symbol , rank ) return gene_match def assess_gene_with_pvalue_threshold ( self , result_entry : dict , gene : ProbandCausativeGene , rank_stats : RankStats ) -> GenePrioritisationResultData : \"\"\"Record the gene prioritisation rank if it meets the pvalue threshold.\"\"\" if float ( self . threshold ) > float ( result_entry [ \"score\" ]): return self . record_gene_prioritisation_match ( gene , result_entry , rank_stats ) def assess_gene_with_threshold ( self , result_entry : dict , gene : ProbandCausativeGene , rank_stats : RankStats ) -> GenePrioritisationResultData : \"\"\"Record the gene prioritisation rank if it meets the score threshold.\"\"\" if float ( self . threshold ) < float ( result_entry [ \"score\" ]): return self . record_gene_prioritisation_match ( gene , result_entry , rank_stats ) def record_matched_gene ( self , gene , rank_stats , standardised_gene_result ): \"\"\"Return the gene rank result - dealing with the specification of a threshold.\"\"\" if float ( self . threshold ) == 0.0 : return self . record_gene_prioritisation_match ( gene , standardised_gene_result , rank_stats ) else : return ( self . assess_gene_with_threshold ( standardised_gene_result , gene , rank_stats ) if self . ranking_method != \"pValue\" else self . assess_gene_with_pvalue_threshold ( standardised_gene_result , gene , rank_stats ) ) def assess_gene_prioritisation ( self , rank_stats : RankStats , rank_records : defaultdict ): \"\"\"Assess gene prioritisation.\"\"\" for gene in self . proband_causative_genes : rank_stats . total += 1 gene_match = GenePrioritisationResultData ( self . phenopacket_path , gene . gene_symbol ) for _index , standardised_gene_result in self . standardised_gene_results . iterrows (): if ( gene . gene_identifier == standardised_gene_result [ \"gene_identifier\" ] or gene . gene_symbol == standardised_gene_result [ \"gene_symbol\" ] ): gene_match = self . record_matched_gene ( gene , rank_stats , standardised_gene_result ) PrioritisationRankRecorder ( rank_stats . total , self . results_dir , GenePrioritisationResultData ( self . phenopacket_path , gene . gene_symbol ) if gene_match is None else gene_match , rank_records , ) . record_rank ()","title":"AssessGenePrioritisation"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.AssessGenePrioritisation.assess_gene_prioritisation","text":"Assess gene prioritisation. Source code in src/pheval/analyse/analysis.py 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 def assess_gene_prioritisation ( self , rank_stats : RankStats , rank_records : defaultdict ): \"\"\"Assess gene prioritisation.\"\"\" for gene in self . proband_causative_genes : rank_stats . total += 1 gene_match = GenePrioritisationResultData ( self . phenopacket_path , gene . gene_symbol ) for _index , standardised_gene_result in self . standardised_gene_results . iterrows (): if ( gene . gene_identifier == standardised_gene_result [ \"gene_identifier\" ] or gene . gene_symbol == standardised_gene_result [ \"gene_symbol\" ] ): gene_match = self . record_matched_gene ( gene , rank_stats , standardised_gene_result ) PrioritisationRankRecorder ( rank_stats . total , self . results_dir , GenePrioritisationResultData ( self . phenopacket_path , gene . gene_symbol ) if gene_match is None else gene_match , rank_records , ) . record_rank ()","title":"assess_gene_prioritisation()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.AssessGenePrioritisation.assess_gene_with_pvalue_threshold","text":"Record the gene prioritisation rank if it meets the pvalue threshold. Source code in src/pheval/analyse/analysis.py 235 236 237 238 239 240 def assess_gene_with_pvalue_threshold ( self , result_entry : dict , gene : ProbandCausativeGene , rank_stats : RankStats ) -> GenePrioritisationResultData : \"\"\"Record the gene prioritisation rank if it meets the pvalue threshold.\"\"\" if float ( self . threshold ) > float ( result_entry [ \"score\" ]): return self . record_gene_prioritisation_match ( gene , result_entry , rank_stats )","title":"assess_gene_with_pvalue_threshold()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.AssessGenePrioritisation.assess_gene_with_threshold","text":"Record the gene prioritisation rank if it meets the score threshold. Source code in src/pheval/analyse/analysis.py 242 243 244 245 246 247 def assess_gene_with_threshold ( self , result_entry : dict , gene : ProbandCausativeGene , rank_stats : RankStats ) -> GenePrioritisationResultData : \"\"\"Record the gene prioritisation rank if it meets the score threshold.\"\"\" if float ( self . threshold ) < float ( result_entry [ \"score\" ]): return self . record_gene_prioritisation_match ( gene , result_entry , rank_stats )","title":"assess_gene_with_threshold()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.AssessGenePrioritisation.record_gene_prioritisation_match","text":"Record the gene prioritisation rank if found within results. Source code in src/pheval/analyse/analysis.py 226 227 228 229 230 231 232 233 def record_gene_prioritisation_match ( self , gene : ProbandCausativeGene , result_entry : dict , rank_stats : RankStats ) -> GenePrioritisationResultData : \"\"\"Record the gene prioritisation rank if found within results.\"\"\" rank = result_entry [ \"rank\" ] rank_stats . add_rank ( rank ) gene_match = GenePrioritisationResultData ( self . phenopacket_path , gene . gene_symbol , rank ) return gene_match","title":"record_gene_prioritisation_match()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.AssessGenePrioritisation.record_matched_gene","text":"Return the gene rank result - dealing with the specification of a threshold. Source code in src/pheval/analyse/analysis.py 249 250 251 252 253 254 255 256 257 258 259 260 def record_matched_gene ( self , gene , rank_stats , standardised_gene_result ): \"\"\"Return the gene rank result - dealing with the specification of a threshold.\"\"\" if float ( self . threshold ) == 0.0 : return self . record_gene_prioritisation_match ( gene , standardised_gene_result , rank_stats ) else : return ( self . assess_gene_with_threshold ( standardised_gene_result , gene , rank_stats ) if self . ranking_method != \"pValue\" else self . assess_gene_with_pvalue_threshold ( standardised_gene_result , gene , rank_stats ) )","title":"record_matched_gene()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.AssessVariantPrioritisation","text":"Assess variant prioritisation. Source code in src/pheval/analyse/analysis.py 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 class AssessVariantPrioritisation : \"\"\"Assess variant prioritisation.\"\"\" def __init__ ( self , phenopacket_path : Path , results_dir : Path , standardised_variant_results : [ dict ], threshold : float , ranking_method : str , proband_causative_variants : [ GenomicVariant ], ): self . phenopacket_path = phenopacket_path self . results_dir = results_dir self . standardised_variant_results = standardised_variant_results self . threshold = threshold self . ranking_method = ranking_method self . proband_causative_variants = proband_causative_variants def record_variant_prioritisation_match ( self , result_entry : pd . Series , rank_stats : RankStats , ) -> VariantPrioritisationResultData : \"\"\"Record the variant prioritisation rank if found within results.\"\"\" rank = result_entry [ \"rank\" ] rank_stats . add_rank ( rank ) variant_match = VariantPrioritisationResultData ( self . phenopacket_path , GenomicVariant ( chrom = result_entry [ \"chromosome\" ], pos = result_entry [ \"start\" ], ref = result_entry [ \"ref\" ], alt = result_entry [ \"alt\" ], ), rank , ) return variant_match def assess_variant_with_pvalue_threshold ( self , result_entry : pd . Series , rank_stats : RankStats ) -> VariantPrioritisationResultData : \"\"\"Record the variant prioritisation rank if it meets the pvalue threshold.\"\"\" if float ( self . threshold ) > float ( result_entry [ \"score\" ]): return self . record_variant_prioritisation_match ( result_entry , rank_stats ) def assess_variant_with_threshold ( self , result_entry : pd . Series , rank_stats : RankStats ) -> VariantPrioritisationResultData : \"\"\"Record the variant prioritisation rank if it meets the score threshold.\"\"\" if float ( self . threshold ) < float ( result_entry [ \"score\" ]): return self . record_variant_prioritisation_match ( result_entry , rank_stats ) def record_matched_variant ( self , rank_stats , result ) -> VariantPrioritisationResultData : \"\"\"Return the variant rank result - dealing with the specification of a threshold.\"\"\" if float ( self . threshold ) == 0.0 : return self . record_variant_prioritisation_match ( result , rank_stats ) else : return ( self . assess_variant_with_threshold ( result , rank_stats ) if self . ranking_method != \"pValue\" else self . assess_variant_with_pvalue_threshold ( result , rank_stats ) ) def assess_variant_prioritisation ( self , rank_stats : RankStats , rank_records : defaultdict ): \"\"\"Assess variant prioritisation.\"\"\" for variant in self . proband_causative_variants : rank_stats . total += 1 variant_match = VariantPrioritisationResultData ( self . phenopacket_path , variant ) for _index , result in self . standardised_variant_results . iterrows (): result_variant = GenomicVariant ( chrom = result [ \"chromosome\" ], pos = result [ \"start\" ], ref = result [ \"ref\" ], alt = result [ \"alt\" ], ) if variant == result_variant : variant_match = self . record_matched_variant ( rank_stats , result ) PrioritisationRankRecorder ( rank_stats . total , self . results_dir , VariantPrioritisationResultData ( self . phenopacket_path , variant ) if variant_match is None else variant_match , rank_records , ) . record_rank ()","title":"AssessVariantPrioritisation"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.AssessVariantPrioritisation.assess_variant_prioritisation","text":"Assess variant prioritisation. Source code in src/pheval/analyse/analysis.py 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 def assess_variant_prioritisation ( self , rank_stats : RankStats , rank_records : defaultdict ): \"\"\"Assess variant prioritisation.\"\"\" for variant in self . proband_causative_variants : rank_stats . total += 1 variant_match = VariantPrioritisationResultData ( self . phenopacket_path , variant ) for _index , result in self . standardised_variant_results . iterrows (): result_variant = GenomicVariant ( chrom = result [ \"chromosome\" ], pos = result [ \"start\" ], ref = result [ \"ref\" ], alt = result [ \"alt\" ], ) if variant == result_variant : variant_match = self . record_matched_variant ( rank_stats , result ) PrioritisationRankRecorder ( rank_stats . total , self . results_dir , VariantPrioritisationResultData ( self . phenopacket_path , variant ) if variant_match is None else variant_match , rank_records , ) . record_rank ()","title":"assess_variant_prioritisation()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.AssessVariantPrioritisation.assess_variant_with_pvalue_threshold","text":"Record the variant prioritisation rank if it meets the pvalue threshold. Source code in src/pheval/analyse/analysis.py 324 325 326 327 328 329 def assess_variant_with_pvalue_threshold ( self , result_entry : pd . Series , rank_stats : RankStats ) -> VariantPrioritisationResultData : \"\"\"Record the variant prioritisation rank if it meets the pvalue threshold.\"\"\" if float ( self . threshold ) > float ( result_entry [ \"score\" ]): return self . record_variant_prioritisation_match ( result_entry , rank_stats )","title":"assess_variant_with_pvalue_threshold()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.AssessVariantPrioritisation.assess_variant_with_threshold","text":"Record the variant prioritisation rank if it meets the score threshold. Source code in src/pheval/analyse/analysis.py 331 332 333 334 335 336 def assess_variant_with_threshold ( self , result_entry : pd . Series , rank_stats : RankStats ) -> VariantPrioritisationResultData : \"\"\"Record the variant prioritisation rank if it meets the score threshold.\"\"\" if float ( self . threshold ) < float ( result_entry [ \"score\" ]): return self . record_variant_prioritisation_match ( result_entry , rank_stats )","title":"assess_variant_with_threshold()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.AssessVariantPrioritisation.record_matched_variant","text":"Return the variant rank result - dealing with the specification of a threshold. Source code in src/pheval/analyse/analysis.py 338 339 340 341 342 343 344 345 346 347 def record_matched_variant ( self , rank_stats , result ) -> VariantPrioritisationResultData : \"\"\"Return the variant rank result - dealing with the specification of a threshold.\"\"\" if float ( self . threshold ) == 0.0 : return self . record_variant_prioritisation_match ( result , rank_stats ) else : return ( self . assess_variant_with_threshold ( result , rank_stats ) if self . ranking_method != \"pValue\" else self . assess_variant_with_pvalue_threshold ( result , rank_stats ) )","title":"record_matched_variant()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.AssessVariantPrioritisation.record_variant_prioritisation_match","text":"Record the variant prioritisation rank if found within results. Source code in src/pheval/analyse/analysis.py 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 def record_variant_prioritisation_match ( self , result_entry : pd . Series , rank_stats : RankStats , ) -> VariantPrioritisationResultData : \"\"\"Record the variant prioritisation rank if found within results.\"\"\" rank = result_entry [ \"rank\" ] rank_stats . add_rank ( rank ) variant_match = VariantPrioritisationResultData ( self . phenopacket_path , GenomicVariant ( chrom = result_entry [ \"chromosome\" ], pos = result_entry [ \"start\" ], ref = result_entry [ \"ref\" ], alt = result_entry [ \"alt\" ], ), rank , ) return variant_match","title":"record_variant_prioritisation_match()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.GenePrioritisationResultData","text":"Store rank data for causative genes. Source code in src/pheval/analyse/analysis.py 26 27 28 29 30 31 32 @dataclass class GenePrioritisationResultData : \"\"\"Store rank data for causative genes.\"\"\" phenopacket : Path gene : str rank : int = 0","title":"GenePrioritisationResultData"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.PrioritisationRankRecorder","text":"Compare the ranks of different runs. Source code in src/pheval/analyse/analysis.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 @dataclass class PrioritisationRankRecorder : \"\"\"Compare the ranks of different runs.\"\"\" index : int directory : Path prioritisation_run_comparison : VariantPrioritisationResultData or GenePrioritisationResultData run_comparison : defaultdict def record_rank ( self ) -> None : \"\"\"Records the rank for different runs.\"\"\" self . run_comparison [ self . index ][ \"Phenopacket\" ] = self . prioritisation_run_comparison . phenopacket . name if type ( self . prioritisation_run_comparison ) is GenePrioritisationResultData : self . run_comparison [ self . index ][ \"Gene\" ] = self . prioritisation_run_comparison . gene if type ( self . prioritisation_run_comparison ) is VariantPrioritisationResultData : variant_info = self . prioritisation_run_comparison . variant self . run_comparison [ self . index ][ \"Variant\" ] = \"_\" . join ( [ variant_info . chrom , str ( variant_info . pos ), variant_info . ref , variant_info . alt ] ) self . run_comparison [ self . index ][ self . directory ] = self . prioritisation_run_comparison . rank","title":"PrioritisationRankRecorder"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.PrioritisationRankRecorder.record_rank","text":"Records the rank for different runs. Source code in src/pheval/analyse/analysis.py 53 54 55 56 57 58 59 60 61 62 63 64 65 def record_rank ( self ) -> None : \"\"\"Records the rank for different runs.\"\"\" self . run_comparison [ self . index ][ \"Phenopacket\" ] = self . prioritisation_run_comparison . phenopacket . name if type ( self . prioritisation_run_comparison ) is GenePrioritisationResultData : self . run_comparison [ self . index ][ \"Gene\" ] = self . prioritisation_run_comparison . gene if type ( self . prioritisation_run_comparison ) is VariantPrioritisationResultData : variant_info = self . prioritisation_run_comparison . variant self . run_comparison [ self . index ][ \"Variant\" ] = \"_\" . join ( [ variant_info . chrom , str ( variant_info . pos ), variant_info . ref , variant_info . alt ] ) self . run_comparison [ self . index ][ self . directory ] = self . prioritisation_run_comparison . rank","title":"record_rank()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.RankComparisonGenerator","text":"Write the run comparison of rank assignment for prioritisation. Source code in src/pheval/analyse/analysis.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 class RankComparisonGenerator : \"\"\"Write the run comparison of rank assignment for prioritisation.\"\"\" def __init__ ( self , run_comparison : defaultdict ): self . run_comparison = run_comparison def generate_dataframe ( self ) -> pd . DataFrame : \"\"\"Generate pandas dataframe.\"\"\" return pd . DataFrame . from_dict ( self . run_comparison , orient = \"index\" ) def calculate_rank_difference ( self ) -> pd . DataFrame : \"\"\"Calculate the rank decrease for runs - taking the first directory as a baseline.\"\"\" comparison_df = self . generate_dataframe () comparison_df [ \"rank_decrease\" ] = comparison_df . iloc [:, 3 ] - comparison_df . iloc [:, 2 ] return comparison_df def generate_gene_output ( self , prefix : str ) -> None : \"\"\"Generate the output for gene prioritisation ranks.\"\"\" self . generate_dataframe () . to_csv ( prefix + \"-gene_rank_comparison.tsv\" , sep = \" \\t \" ) def generate_variant_output ( self , prefix : str ) -> None : \"\"\"Generate the output for variant prioritisation ranks.\"\"\" self . generate_dataframe () . to_csv ( prefix + \"-variant_rank_comparison.tsv\" , sep = \" \\t \" ) def generate_gene_comparison_output ( self , prefix : str ) -> None : \"\"\"Generate the output for gene prioritisation rank comparison.\"\"\" self . calculate_rank_difference () . to_csv ( prefix + \"-gene_rank_comparison.tsv\" , sep = \" \\t \" ) def generate_variant_comparison_output ( self , prefix : str ) -> None : \"\"\"Generate the output for variant prioritisation rank comparison.\"\"\" self . calculate_rank_difference () . to_csv ( prefix + \"-variant_rank_comparison.tsv\" , sep = \" \\t \" )","title":"RankComparisonGenerator"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.RankComparisonGenerator.calculate_rank_difference","text":"Calculate the rank decrease for runs - taking the first directory as a baseline. Source code in src/pheval/analyse/analysis.py 78 79 80 81 82 def calculate_rank_difference ( self ) -> pd . DataFrame : \"\"\"Calculate the rank decrease for runs - taking the first directory as a baseline.\"\"\" comparison_df = self . generate_dataframe () comparison_df [ \"rank_decrease\" ] = comparison_df . iloc [:, 3 ] - comparison_df . iloc [:, 2 ] return comparison_df","title":"calculate_rank_difference()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.RankComparisonGenerator.generate_dataframe","text":"Generate pandas dataframe. Source code in src/pheval/analyse/analysis.py 74 75 76 def generate_dataframe ( self ) -> pd . DataFrame : \"\"\"Generate pandas dataframe.\"\"\" return pd . DataFrame . from_dict ( self . run_comparison , orient = \"index\" )","title":"generate_dataframe()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.RankComparisonGenerator.generate_gene_comparison_output","text":"Generate the output for gene prioritisation rank comparison. Source code in src/pheval/analyse/analysis.py 92 93 94 def generate_gene_comparison_output ( self , prefix : str ) -> None : \"\"\"Generate the output for gene prioritisation rank comparison.\"\"\" self . calculate_rank_difference () . to_csv ( prefix + \"-gene_rank_comparison.tsv\" , sep = \" \\t \" )","title":"generate_gene_comparison_output()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.RankComparisonGenerator.generate_gene_output","text":"Generate the output for gene prioritisation ranks. Source code in src/pheval/analyse/analysis.py 84 85 86 def generate_gene_output ( self , prefix : str ) -> None : \"\"\"Generate the output for gene prioritisation ranks.\"\"\" self . generate_dataframe () . to_csv ( prefix + \"-gene_rank_comparison.tsv\" , sep = \" \\t \" )","title":"generate_gene_output()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.RankComparisonGenerator.generate_variant_comparison_output","text":"Generate the output for variant prioritisation rank comparison. Source code in src/pheval/analyse/analysis.py 96 97 98 def generate_variant_comparison_output ( self , prefix : str ) -> None : \"\"\"Generate the output for variant prioritisation rank comparison.\"\"\" self . calculate_rank_difference () . to_csv ( prefix + \"-variant_rank_comparison.tsv\" , sep = \" \\t \" )","title":"generate_variant_comparison_output()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.RankComparisonGenerator.generate_variant_output","text":"Generate the output for variant prioritisation ranks. Source code in src/pheval/analyse/analysis.py 88 89 90 def generate_variant_output ( self , prefix : str ) -> None : \"\"\"Generate the output for variant prioritisation ranks.\"\"\" self . generate_dataframe () . to_csv ( prefix + \"-variant_rank_comparison.tsv\" , sep = \" \\t \" )","title":"generate_variant_output()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.RankStats","text":"Class for keeping track of the rank stats. Source code in src/pheval/analyse/analysis.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 @dataclass class RankStats : \"\"\"Class for keeping track of the rank stats.\"\"\" top : int = 0 top3 : int = 0 top5 : int = 0 found : int = 0 total : int = 0 reciprocal_ranks : list = field ( default_factory = list ) def add_rank ( self , rank : int ) -> None : \"\"\"Add rank for phenopacket.\"\"\" self . reciprocal_ranks . append ( 1 / rank ) self . found += 1 if rank == 1 : self . top += 1 if rank != \"\" and rank <= 3 : self . top3 += 1 if rank != \"\" and rank <= 5 : self . top5 += 1 def percentage_rank ( self , value : int ) -> float : \"\"\"Return a percentage rank.\"\"\" return 100 * value / self . found def percentage_top ( self ) -> float : \"\"\"Return percentage of top matches.\"\"\" return self . percentage_rank ( self . top ) def percentage_top3 ( self ) -> float : \"\"\"Return percentage of matches in the top3.\"\"\" return self . percentage_rank ( self . top3 ) def percentage_top5 ( self ) -> float : \"\"\"Return percentage of matches in the top5.\"\"\" return self . percentage_rank ( self . top5 ) def percentage_found ( self ) -> float : \"\"\"Return percentage of matches found.\"\"\" return 100 * self . found / self . total def mean_reciprocal_rank ( self ) -> float : \"\"\"Return the mean reciprocal rank.\"\"\" return mean ( self . reciprocal_ranks )","title":"RankStats"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.RankStats.add_rank","text":"Add rank for phenopacket. Source code in src/pheval/analyse/analysis.py 112 113 114 115 116 117 118 119 120 121 def add_rank ( self , rank : int ) -> None : \"\"\"Add rank for phenopacket.\"\"\" self . reciprocal_ranks . append ( 1 / rank ) self . found += 1 if rank == 1 : self . top += 1 if rank != \"\" and rank <= 3 : self . top3 += 1 if rank != \"\" and rank <= 5 : self . top5 += 1","title":"add_rank()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.RankStats.mean_reciprocal_rank","text":"Return the mean reciprocal rank. Source code in src/pheval/analyse/analysis.py 143 144 145 def mean_reciprocal_rank ( self ) -> float : \"\"\"Return the mean reciprocal rank.\"\"\" return mean ( self . reciprocal_ranks )","title":"mean_reciprocal_rank()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.RankStats.percentage_found","text":"Return percentage of matches found. Source code in src/pheval/analyse/analysis.py 139 140 141 def percentage_found ( self ) -> float : \"\"\"Return percentage of matches found.\"\"\" return 100 * self . found / self . total","title":"percentage_found()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.RankStats.percentage_rank","text":"Return a percentage rank. Source code in src/pheval/analyse/analysis.py 123 124 125 def percentage_rank ( self , value : int ) -> float : \"\"\"Return a percentage rank.\"\"\" return 100 * value / self . found","title":"percentage_rank()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.RankStats.percentage_top","text":"Return percentage of top matches. Source code in src/pheval/analyse/analysis.py 127 128 129 def percentage_top ( self ) -> float : \"\"\"Return percentage of top matches.\"\"\" return self . percentage_rank ( self . top )","title":"percentage_top()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.RankStats.percentage_top3","text":"Return percentage of matches in the top3. Source code in src/pheval/analyse/analysis.py 131 132 133 def percentage_top3 ( self ) -> float : \"\"\"Return percentage of matches in the top3.\"\"\" return self . percentage_rank ( self . top3 )","title":"percentage_top3()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.RankStats.percentage_top5","text":"Return percentage of matches in the top5. Source code in src/pheval/analyse/analysis.py 135 136 137 def percentage_top5 ( self ) -> float : \"\"\"Return percentage of matches in the top5.\"\"\" return self . percentage_rank ( self . top5 )","title":"percentage_top5()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.RankStatsWriter","text":"Write the rank stats for each run. Source code in src/pheval/analyse/analysis.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 class RankStatsWriter : \"\"\"Write the rank stats for each run.\"\"\" def __init__ ( self , file : Path ): self . file = open ( file , \"w\" ) self . writer = csv . writer ( self . file , delimiter = \" \\t \" ) self . writer . writerow ( [ \"results_directory_path\" , \"top\" , \"top3\" , \"top5\" , \"found\" , \"total\" , \"mean_reciprocal_rank\" , \"percentage_top\" , \"percentage_top3\" , \"percentage_top5\" , \"percentage_found\" , ] ) def write_row ( self , directory : Path , rank_stats : RankStats ) -> None : \"\"\"Write summary rank stats row for run.\"\"\" try : self . writer . writerow ( [ directory , rank_stats . top , rank_stats . top3 , rank_stats . top5 , rank_stats . found , rank_stats . total , rank_stats . mean_reciprocal_rank (), rank_stats . percentage_top (), rank_stats . percentage_top3 (), rank_stats . percentage_top5 (), rank_stats . percentage_found (), ] ) except IOError : print ( \"Error writing \" , self . file ) def close ( self ): \"\"\"Close file.\"\"\" try : self . file . close () except IOError : print ( \"Error closing \" , self . file )","title":"RankStatsWriter"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.RankStatsWriter.close","text":"Close file. Source code in src/pheval/analyse/analysis.py 191 192 193 194 195 196 def close ( self ): \"\"\"Close file.\"\"\" try : self . file . close () except IOError : print ( \"Error closing \" , self . file )","title":"close()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.RankStatsWriter.write_row","text":"Write summary rank stats row for run. Source code in src/pheval/analyse/analysis.py 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 def write_row ( self , directory : Path , rank_stats : RankStats ) -> None : \"\"\"Write summary rank stats row for run.\"\"\" try : self . writer . writerow ( [ directory , rank_stats . top , rank_stats . top3 , rank_stats . top5 , rank_stats . found , rank_stats . total , rank_stats . mean_reciprocal_rank (), rank_stats . percentage_top (), rank_stats . percentage_top3 (), rank_stats . percentage_top5 (), rank_stats . percentage_found (), ] ) except IOError : print ( \"Error writing \" , self . file )","title":"write_row()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.TrackGeneComparisons","text":"Track the gene ranks for each result in a result directory. Source code in src/pheval/analyse/analysis.py 533 534 535 536 537 538 @dataclass class TrackGeneComparisons : \"\"\"Track the gene ranks for each result in a result directory.\"\"\" directory : Path gene_results : dict","title":"TrackGeneComparisons"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.TrackInputOutputDirectories","text":"Track the input testdata for a corresponding standardised output directory Source code in src/pheval/analyse/analysis.py 199 200 201 202 203 204 @dataclass class TrackInputOutputDirectories : \"\"\"Track the input testdata for a corresponding standardised output directory\"\"\" phenopacket_dir : Path results_dir : Path","title":"TrackInputOutputDirectories"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.TrackVariantComparisons","text":"Track the variant ranks for each result in a result directory. Source code in src/pheval/analyse/analysis.py 541 542 543 544 545 546 @dataclass class TrackVariantComparisons : \"\"\"Track the variant ranks for each result in a result directory.\"\"\" directory : Path variant_results : dict","title":"TrackVariantComparisons"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.VariantPrioritisationResultData","text":"Store rank data for causative variants. Source code in src/pheval/analyse/analysis.py 35 36 37 38 39 40 41 @dataclass class VariantPrioritisationResultData : \"\"\"Store rank data for causative variants.\"\"\" phenopacket : Path variant : GenomicVariant rank : int = 0","title":"VariantPrioritisationResultData"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.assess_phenopacket_gene_prioritisation","text":"Assess gene prioritisation for a phenopacket. Source code in src/pheval/analyse/analysis.py 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 def assess_phenopacket_gene_prioritisation ( standardised_gene_result : Path , ranking_method : str , results_dir_and_input : TrackInputOutputDirectories , threshold : float , gene_rank_stats : RankStats , gene_rank_comparison : defaultdict , ): \"\"\"Assess gene prioritisation for a phenopacket.\"\"\" phenopacket_path = obtain_closest_file_name ( standardised_gene_result , all_files ( results_dir_and_input . phenopacket_dir ) ) proband_causative_genes = obtain_causative_genes ( phenopacket_path ) AssessGenePrioritisation ( phenopacket_path , results_dir_and_input . results_dir . joinpath ( \"pheval_gene_results/\" ), read_standardised_result ( standardised_gene_result ), threshold , ranking_method , proband_causative_genes , ) . assess_gene_prioritisation ( gene_rank_stats , gene_rank_comparison )","title":"assess_phenopacket_gene_prioritisation()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.assess_phenopacket_variant_prioritisation","text":"Assess variant prioritisation for a phenopacket Source code in src/pheval/analyse/analysis.py 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 def assess_phenopacket_variant_prioritisation ( standardised_variant_result : Path , ranking_method : str , results_dir_and_input : TrackInputOutputDirectories , threshold : float , variant_rank_stats : RankStats , variant_rank_comparison : defaultdict , ): \"\"\"Assess variant prioritisation for a phenopacket\"\"\" phenopacket_path = obtain_closest_file_name ( standardised_variant_result , all_files ( results_dir_and_input . phenopacket_dir ) ) proband_causative_variants = obtain_causative_variants ( phenopacket_path ) AssessVariantPrioritisation ( phenopacket_path , results_dir_and_input . results_dir . joinpath ( \"pheval_variant_results/\" ), read_standardised_result ( standardised_variant_result ), threshold , ranking_method , proband_causative_variants , ) . assess_variant_prioritisation ( variant_rank_stats , variant_rank_comparison )","title":"assess_phenopacket_variant_prioritisation()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.assess_prioritisation_for_results_directory","text":"Assess prioritisation for a single results directory. Source code in src/pheval/analyse/analysis.py 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 def assess_prioritisation_for_results_directory ( results_directory_and_input : TrackInputOutputDirectories , ranking_method : str , threshold : float , gene_rank_comparison : defaultdict , variant_rank_comparison : defaultdict , gene_stats_writer : RankStatsWriter , variants_stats_writer : RankStatsWriter , gene_analysis : bool , variant_analysis : bool , ): \"\"\"Assess prioritisation for a single results directory.\"\"\" gene_rank_stats , variant_rank_stats = RankStats (), RankStats () if gene_analysis : for standardised_result in files_with_suffix ( results_directory_and_input . results_dir . joinpath ( \"pheval_gene_results/\" ), \".tsv\" ): assess_phenopacket_gene_prioritisation ( standardised_result , ranking_method , results_directory_and_input , threshold , gene_rank_stats , gene_rank_comparison , ) if variant_analysis : for standardised_result in files_with_suffix ( results_directory_and_input . results_dir . joinpath ( \"pheval_variant_results/\" ), \".tsv\" , ): assess_phenopacket_variant_prioritisation ( standardised_result , ranking_method , results_directory_and_input , threshold , variant_rank_stats , variant_rank_comparison , ) gene_stats_writer . write_row ( results_directory_and_input . results_dir , gene_rank_stats ) if gene_analysis else None variants_stats_writer . write_row ( results_directory_and_input . results_dir , variant_rank_stats ) if variant_analysis else None return gene_rank_comparison , variant_rank_comparison","title":"assess_prioritisation_for_results_directory()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.benchmark","text":"Benchmark the gene/variant prioritisation performance for a single run. Source code in src/pheval/analyse/analysis.py 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 @click . command () @click . option ( \"--directory\" , \"-d\" , required = True , metavar = \"PATH\" , help = \"General results directory to be benchmarked, assumes contains subdirectories of pheval_gene_results/\" \"pheval_variant_results and the tool specific results directory. \" , type = Path , ) @click . option ( \"--phenopacket-dir\" , \"-p\" , required = True , metavar = \"PATH\" , help = \"Full path to directory containing input phenopackets.\" , type = Path , ) @click . option ( \"--output-prefix\" , \"-o\" , metavar = \"<str>\" , required = True , help = \" Output file prefix. \" , ) @click . option ( \"--ranking-method\" , \"-r\" , required = True , help = \"Ranking method for gene prioritisation.\" , ) @click . option ( \"--threshold\" , \"-t\" , metavar = \"<float>\" , default = float ( 0.0 ), required = False , help = \"Score threshold.\" , type = float , ) @click . option ( \"--gene-analysis/--no-gene-analysis\" , default = True , required = False , type = bool , show_default = True , help = \"Analyse gene prioritisation\" , ) @click . option ( \"--variant-analysis/--no-variant-analysis\" , default = True , required = False , type = bool , show_default = True , help = \"Analyse variant prioritisation\" , ) def benchmark ( directory : Path , phenopacket_dir : Path , ranking_method : str , output_prefix : str , threshold : float , gene_analysis : bool , variant_analysis : bool , ): \"\"\"Benchmark the gene/variant prioritisation performance for a single run.\"\"\" benchmark_directory ( TrackInputOutputDirectories ( results_dir = directory , phenopacket_dir = phenopacket_dir ), ranking_method , output_prefix , threshold , gene_analysis , variant_analysis , )","title":"benchmark()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.benchmark_comparison","text":"Benchmark the gene/variant prioritisation performance for two runs. Source code in src/pheval/analyse/analysis.py 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 @click . command () @click . option ( \"--directory1\" , \"-d1\" , required = True , metavar = \"PATH\" , help = \"Baseline results directory for benchmarking, assumes contains subdirectories of pheval_gene_results/\" \"pheval_variant_results and the tool specific results directory.\" , type = Path , ) @click . option ( \"--directory2\" , \"-d2\" , required = True , metavar = \"PATH\" , help = \"Comparison results directory for benchmarking, assumes contains subdirectories of pheval_gene_results/\" \"pheval_variant_results and the tool specific results directory.\" , type = Path , ) @click . option ( \"--phenopacket-dir1\" , \"-p1\" , required = True , metavar = \"PATH\" , help = \"Full path to directory containing phenopackets for input for baseline directory.\" , type = Path , ) @click . option ( \"--phenopacket-dir2\" , \"-p2\" , required = True , metavar = \"PATH\" , help = \"Full path to directory containing phenopackets for input for comparison directory.\" , type = Path , ) @click . option ( \"--output-prefix\" , \"-o\" , metavar = \"<str>\" , required = True , help = \" Output file prefix. \" , ) @click . option ( \"--ranking-method\" , \"-r\" , required = True , help = \"Ranking method for gene prioritisation.\" , ) @click . option ( \"--threshold\" , \"-t\" , metavar = \"<float>\" , default = float ( 0.0 ), required = False , help = \"Score threshold.\" , type = float , ) @click . option ( \"--gene-analysis/--no-gene-analysis\" , default = True , required = False , type = bool , show_default = True , help = \"Analyse gene prioritisation\" , ) @click . option ( \"--variant-analysis/--no-variant-analysis\" , default = True , required = False , type = bool , show_default = True , help = \"Analyse variant prioritisation\" , ) def benchmark_comparison ( directory1 : Path , directory2 : Path , phenopacket_dir1 : Path , phenopacket_dir2 : Path , ranking_method : str , output_prefix : str , threshold : float , gene_analysis : bool , variant_analysis : bool , ): \"\"\"Benchmark the gene/variant prioritisation performance for two runs.\"\"\" benchmark_runs ( [ TrackInputOutputDirectories ( results_dir = directory1 , phenopacket_dir = phenopacket_dir1 ), TrackInputOutputDirectories ( results_dir = directory2 , phenopacket_dir = phenopacket_dir2 ), ], ranking_method , output_prefix , threshold , gene_analysis , variant_analysis , )","title":"benchmark_comparison()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.benchmark_directory","text":"Benchmark prioritisation performance for a single directory. Source code in src/pheval/analyse/analysis.py 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 def benchmark_directory ( results_dir_and_input : TrackInputOutputDirectories , ranking_method : str , output_prefix : str , threshold : float , gene_analysis : bool , variant_analysis : bool , ): \"\"\"Benchmark prioritisation performance for a single directory.\"\"\" gene_stats_writer = ( RankStatsWriter ( Path ( output_prefix + \"-gene_summary.tsv\" )) if gene_analysis else None ) variants_stats_writer = ( RankStatsWriter ( Path ( output_prefix + \"-variant_summary.tsv\" )) if variant_analysis else None ) gene_rank_comparison , variant_rank_comparison = defaultdict ( dict ), defaultdict ( dict ) assess_prioritisation_for_results_directory ( results_dir_and_input , ranking_method , threshold , gene_rank_comparison , variant_rank_comparison , gene_stats_writer , variants_stats_writer , gene_analysis , variant_analysis , ) RankComparisonGenerator ( gene_rank_comparison ) . generate_gene_output ( f \" { results_dir_and_input . results_dir . name } \" ) if gene_analysis else None RankComparisonGenerator ( variant_rank_comparison ) . generate_variant_output ( f \" { results_dir_and_input . results_dir . name } \" ) if variant_analysis else None gene_stats_writer . close () if gene_analysis else None variants_stats_writer . close () if variant_analysis else None","title":"benchmark_directory()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.benchmark_runs","text":"Benchmark several result directories. Source code in src/pheval/analyse/analysis.py 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 def benchmark_runs ( results_directories : [ TrackInputOutputDirectories ], ranking_method : str , output_prefix : str , threshold : float , gene_analysis : bool , variant_analysis : bool , ): \"\"\"Benchmark several result directories.\"\"\" gene_stats_writer = ( RankStatsWriter ( Path ( output_prefix + \"-gene_summary.tsv\" )) if gene_analysis else None ) variants_stats_writer = ( RankStatsWriter ( Path ( output_prefix + \"-variant_summary.tsv\" )) if variant_analysis else None ) gene_ranks_for_directories = [] variant_ranks_for_directories = [] for results_dir_and_input in results_directories : gene_rank_comparison , variant_rank_comparison = defaultdict ( dict ), defaultdict ( dict ) gene_ranks , variant_ranks = assess_prioritisation_for_results_directory ( results_dir_and_input , ranking_method , threshold , gene_rank_comparison , variant_rank_comparison , gene_stats_writer , variants_stats_writer , gene_analysis , variant_analysis , ) gene_ranks_for_directories . append ( TrackGeneComparisons ( results_dir_and_input . results_dir , gene_ranks ) ) variant_ranks_for_directories . append ( TrackVariantComparisons ( results_dir_and_input . results_dir , variant_ranks ) ) generate_gene_rank_comparisons ( list ( itertools . combinations ( gene_ranks_for_directories , 2 )) ) if gene_analysis else None generate_variant_rank_comparisons ( list ( itertools . combinations ( variant_ranks_for_directories , 2 )) ) if variant_analysis else None","title":"benchmark_runs()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.generate_gene_rank_comparisons","text":"Generate the gene rank comparison of two result directories. Source code in src/pheval/analyse/analysis.py 549 550 551 552 553 554 555 def generate_gene_rank_comparisons ( comparison_ranks : [ tuple ]) -> None : \"\"\"Generate the gene rank comparison of two result directories.\"\"\" for pair in comparison_ranks : merged_results = merge_results ( pair [ 0 ] . gene_results , pair [ 1 ] . gene_results ) RankComparisonGenerator ( merged_results ) . generate_gene_comparison_output ( f \" { pair [ 0 ] . directory . name } __v__ { pair [ 1 ] . directory . name } \" )","title":"generate_gene_rank_comparisons()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.generate_variant_rank_comparisons","text":"Generate the variant rank comparison of two result directories. Source code in src/pheval/analyse/analysis.py 558 559 560 561 562 563 564 def generate_variant_rank_comparisons ( comparison_ranks : [ tuple ]) -> None : \"\"\"Generate the variant rank comparison of two result directories.\"\"\" for pair in comparison_ranks : merged_results = merge_results ( pair [ 0 ] . variant_results , pair [ 1 ] . variant_results ) RankComparisonGenerator ( merged_results ) . generate_variant_comparison_output ( f \" { pair [ 0 ] . directory . name } __v__ { pair [ 1 ] . directory . name } \" )","title":"generate_variant_rank_comparisons()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.merge_results","text":"Merge two nested dictionaries containing results on commonalities. Source code in src/pheval/analyse/analysis.py 517 518 519 520 521 522 523 524 525 526 527 528 529 530 def merge_results ( result1 , result2 ): \"\"\"Merge two nested dictionaries containing results on commonalities.\"\"\" for key , val in result1 . items (): if type ( val ) == dict : if key in result2 and type ( result2 [ key ] == dict ): merge_results ( result1 [ key ], result2 [ key ]) else : if key in result2 : result1 [ key ] = result2 [ key ] for key , val in result2 . items (): if key not in result1 : result1 [ key ] = val return result1","title":"merge_results()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.obtain_causative_genes","text":"Obtain causative genes from a phenopacket. Source code in src/pheval/analyse/analysis.py 373 374 375 376 377 def obtain_causative_genes ( phenopacket_path ): \"\"\"Obtain causative genes from a phenopacket.\"\"\" phenopacket = phenopacket_reader ( phenopacket_path ) phenopacket_util = PhenopacketUtil ( phenopacket ) return phenopacket_util . diagnosed_genes ()","title":"obtain_causative_genes()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.obtain_causative_variants","text":"Obtain causative variants from a phenopacket. Source code in src/pheval/analyse/analysis.py 380 381 382 383 384 def obtain_causative_variants ( phenopacket_path ): \"\"\"Obtain causative variants from a phenopacket.\"\"\" phenopacket = phenopacket_reader ( phenopacket_path ) phenopacket_util = PhenopacketUtil ( phenopacket ) return phenopacket_util . diagnosed_variants ()","title":"obtain_causative_variants()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.read_standardised_result","text":"Read the standardised result output and return a dictionary. Source code in src/pheval/analyse/analysis.py 21 22 23 def read_standardised_result ( standardised_result_path : Path ) -> dict : \"\"\"Read the standardised result output and return a dictionary.\"\"\" return pd . read_csv ( standardised_result_path , delimiter = \" \\t \" )","title":"read_standardised_result()"},{"location":"api/pheval/post_processing/post_processing/","text":"PhEvalGeneResult dataclass Minimal data required from tool-specific output for gene prioritisation. Source code in src/pheval/post_processing/post_processing.py 14 15 16 17 18 19 20 @dataclass class PhEvalGeneResult : \"\"\"Minimal data required from tool-specific output for gene prioritisation.\"\"\" gene_symbol : str gene_identifier : str score : float PhEvalVariantResult dataclass Minimal data required from tool-specific output for variant prioritisation. Source code in src/pheval/post_processing/post_processing.py 40 41 42 43 44 45 46 47 48 49 @dataclass class PhEvalVariantResult : \"\"\"Minimal data required from tool-specific output for variant prioritisation.\"\"\" chromosome : str start : int end : int ref : str alt : str score : float RankedPhEvalGeneResult dataclass PhEval gene result with corresponding rank. Source code in src/pheval/post_processing/post_processing.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @dataclass class RankedPhEvalGeneResult : \"\"\"PhEval gene result with corresponding rank.\"\"\" pheval_gene_result : PhEvalGeneResult rank : int def as_dict ( self ): \"\"\"Return PhEval gene result as dictionary.\"\"\" return { \"gene_symbol\" : self . pheval_gene_result . gene_symbol , \"gene_identifier\" : self . pheval_gene_result . gene_identifier , \"score\" : self . pheval_gene_result . score , \"rank\" : self . rank , } as_dict () Return PhEval gene result as dictionary. Source code in src/pheval/post_processing/post_processing.py 30 31 32 33 34 35 36 37 def as_dict ( self ): \"\"\"Return PhEval gene result as dictionary.\"\"\" return { \"gene_symbol\" : self . pheval_gene_result . gene_symbol , \"gene_identifier\" : self . pheval_gene_result . gene_identifier , \"score\" : self . pheval_gene_result . score , \"rank\" : self . rank , } RankedPhEvalVariantResult dataclass PhEval variant result with corresponding rank. Source code in src/pheval/post_processing/post_processing.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 @dataclass class RankedPhEvalVariantResult : \"\"\"PhEval variant result with corresponding rank.\"\"\" pheval_variant_result : PhEvalVariantResult rank : int def as_dict ( self ): \"\"\"Return PhEval variant result as dictionary.\"\"\" return { \"chromosome\" : self . pheval_variant_result . chromosome , \"start\" : self . pheval_variant_result . start , \"end\" : self . pheval_variant_result . end , \"ref\" : self . pheval_variant_result . ref , \"alt\" : self . pheval_variant_result . alt , \"score\" : self . pheval_variant_result . score , \"rank\" : self . rank , } as_dict () Return PhEval variant result as dictionary. Source code in src/pheval/post_processing/post_processing.py 59 60 61 62 63 64 65 66 67 68 69 def as_dict ( self ): \"\"\"Return PhEval variant result as dictionary.\"\"\" return { \"chromosome\" : self . pheval_variant_result . chromosome , \"start\" : self . pheval_variant_result . start , \"end\" : self . pheval_variant_result . end , \"ref\" : self . pheval_variant_result . ref , \"alt\" : self . pheval_variant_result . alt , \"score\" : self . pheval_variant_result . score , \"rank\" : self . rank , } ResultSorter Source code in src/pheval/post_processing/post_processing.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 class ResultSorter : def __init__ ( self , pheval_results : [ PhEvalGeneResult ] or [ PhEvalVariantResult ], sort_order : SortOrder ): self . pheval_results = pheval_results self . sort_order = sort_order def _sort_by_decreasing_score ( self ) -> [ PhEvalGeneResult ] or [ PhEvalVariantResult ]: \"\"\"Sort results in descending order.\"\"\" return sorted ( self . pheval_results , key = operator . attrgetter ( \"score\" ), reverse = True ) def _sort_by_increasing_score ( self ) -> [ PhEvalGeneResult ] or [ PhEvalVariantResult ]: \"\"\"Sort results in ascending order.\"\"\" return sorted ( self . pheval_results , key = operator . attrgetter ( \"score\" ), reverse = False ) def sort_pheval_results ( self ) -> [ PhEvalGeneResult ] or [ PhEvalVariantResult ]: \"\"\"Sort results with best score first.\"\"\" return ( self . _sort_by_increasing_score () if self . sort_order == SortOrder . ASCENDING else self . _sort_by_decreasing_score () ) sort_pheval_results () Sort results with best score first. Source code in src/pheval/post_processing/post_processing.py 92 93 94 95 96 97 98 def sort_pheval_results ( self ) -> [ PhEvalGeneResult ] or [ PhEvalVariantResult ]: \"\"\"Sort results with best score first.\"\"\" return ( self . _sort_by_increasing_score () if self . sort_order == SortOrder . ASCENDING else self . _sort_by_decreasing_score () ) ScoreRanker Source code in src/pheval/post_processing/post_processing.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 class ScoreRanker : rank : int = 0 current_score : float = float ( \"inf\" ) count : int = 0 def __init__ ( self , sort_order : SortOrder ): self . sort_order = sort_order def _check_rank_order ( self , round_score : float ) -> None : \"\"\"Check the results are correctly ordered.\"\"\" if self . sort_order == SortOrder . ASCENDING and round_score < self . current_score != float ( \"inf\" ): raise ValueError ( \"Results are not correctly sorted!\" ) elif self . sort_order == SortOrder . DESCENDING and round_score > self . current_score != float ( \"inf\" ): raise ValueError ( \"Results are not correctly sorted!\" ) def rank_scores ( self , round_score : float ) -> int : \"\"\"Add ranks to a result, equal scores are given the same rank e.g., 1,1,3.\"\"\" self . _check_rank_order ( round_score ) self . count += 1 if self . current_score == round_score : return self . rank self . current_score = round_score self . rank = self . count return self . rank rank_scores ( round_score ) Add ranks to a result, equal scores are given the same rank e.g., 1,1,3. Source code in src/pheval/post_processing/post_processing.py 120 121 122 123 124 125 126 127 128 def rank_scores ( self , round_score : float ) -> int : \"\"\"Add ranks to a result, equal scores are given the same rank e.g., 1,1,3.\"\"\" self . _check_rank_order ( round_score ) self . count += 1 if self . current_score == round_score : return self . rank self . current_score = round_score self . rank = self . count return self . rank calculate_end_pos ( variant_start , variant_ref ) Calculate the end position for a variant. Source code in src/pheval/post_processing/post_processing.py 9 10 11 def calculate_end_pos ( variant_start : int , variant_ref : str ) -> int : \"\"\"Calculate the end position for a variant.\"\"\" return variant_start + len ( variant_ref ) - 1 create_pheval_result ( pheval_result , sort_order_str ) Create PhEval gene/variant result with corresponding ranks. Source code in src/pheval/post_processing/post_processing.py 159 160 161 162 163 164 165 def create_pheval_result ( pheval_result : [ PhEvalGeneResult ] or [ PhEvalVariantResult ], sort_order_str : str ) -> [ RankedPhEvalGeneResult ] or [ RankedPhEvalVariantResult ]: \"\"\"Create PhEval gene/variant result with corresponding ranks.\"\"\" sort_order = _return_sort_order ( sort_order_str ) sorted_pheval_result = ResultSorter ( pheval_result , sort_order ) . sort_pheval_results () return rank_pheval_result ( sorted_pheval_result , sort_order ) rank_pheval_result ( pheval_result , sort_order ) Ranks either a PhEval gene or variant result post-processed from a tool specific output. Deals with ex aequo scores Source code in src/pheval/post_processing/post_processing.py 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 def rank_pheval_result ( pheval_result : [ PhEvalGeneResult ] or [ PhEvalVariantResult ], sort_order : SortOrder ) -> [ RankedPhEvalGeneResult ] or [ RankedPhEvalVariantResult ]: \"\"\"Ranks either a PhEval gene or variant result post-processed from a tool specific output. Deals with ex aequo scores\"\"\" score_ranker = ScoreRanker ( sort_order ) ranked_result = [] for result in pheval_result : ranked_result . append ( RankedPhEvalGeneResult ( pheval_gene_result = result , rank = score_ranker . rank_scores ( result . score ) ) ) if type ( result ) == PhEvalGeneResult else ranked_result . append ( RankedPhEvalVariantResult ( pheval_variant_result = result , rank = score_ranker . rank_scores ( result . score ) ) ) return ranked_result write_pheval_gene_result ( ranked_pheval_result , output_dir , tool_result_path ) Write ranked PhEval gene result to tsv. Source code in src/pheval/post_processing/post_processing.py 168 169 170 171 172 173 174 175 176 177 178 179 180 def write_pheval_gene_result ( ranked_pheval_result : [ RankedPhEvalGeneResult ], output_dir : Path , tool_result_path : Path ) -> None : \"\"\"Write ranked PhEval gene result to tsv.\"\"\" ranked_result = pd . DataFrame ([ x . as_dict () for x in ranked_pheval_result ]) pheval_gene_output = ranked_result . loc [:, [ \"rank\" , \"score\" , \"gene_symbol\" , \"gene_identifier\" ]] pheval_gene_output . to_csv ( output_dir . joinpath ( \"pheval_gene_results/\" + tool_result_path . stem + \"-pheval_gene_result.tsv\" ), sep = \" \\t \" , index = False , ) write_pheval_variant_result ( ranked_pheval_result , output_dir , tool_result_path ) Write ranked PhEval variant result to tsv. Source code in src/pheval/post_processing/post_processing.py 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 def write_pheval_variant_result ( ranked_pheval_result : [ RankedPhEvalVariantResult ], output_dir : Path , tool_result_path : Path ) -> None : \"\"\"Write ranked PhEval variant result to tsv.\"\"\" ranked_result = pd . DataFrame ([ x . as_dict () for x in ranked_pheval_result ]) pheval_variant_output = ranked_result . loc [ :, [ \"rank\" , \"score\" , \"chromosome\" , \"start\" , \"end\" , \"ref\" , \"alt\" ] ] pheval_variant_output . to_csv ( output_dir . joinpath ( \"pheval_variant_results/\" + tool_result_path . stem + \"-pheval_variant_result.tsv\" ), sep = \" \\t \" , index = False , )","title":"Post processing"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.PhEvalGeneResult","text":"Minimal data required from tool-specific output for gene prioritisation. Source code in src/pheval/post_processing/post_processing.py 14 15 16 17 18 19 20 @dataclass class PhEvalGeneResult : \"\"\"Minimal data required from tool-specific output for gene prioritisation.\"\"\" gene_symbol : str gene_identifier : str score : float","title":"PhEvalGeneResult"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.PhEvalVariantResult","text":"Minimal data required from tool-specific output for variant prioritisation. Source code in src/pheval/post_processing/post_processing.py 40 41 42 43 44 45 46 47 48 49 @dataclass class PhEvalVariantResult : \"\"\"Minimal data required from tool-specific output for variant prioritisation.\"\"\" chromosome : str start : int end : int ref : str alt : str score : float","title":"PhEvalVariantResult"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.RankedPhEvalGeneResult","text":"PhEval gene result with corresponding rank. Source code in src/pheval/post_processing/post_processing.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @dataclass class RankedPhEvalGeneResult : \"\"\"PhEval gene result with corresponding rank.\"\"\" pheval_gene_result : PhEvalGeneResult rank : int def as_dict ( self ): \"\"\"Return PhEval gene result as dictionary.\"\"\" return { \"gene_symbol\" : self . pheval_gene_result . gene_symbol , \"gene_identifier\" : self . pheval_gene_result . gene_identifier , \"score\" : self . pheval_gene_result . score , \"rank\" : self . rank , }","title":"RankedPhEvalGeneResult"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.RankedPhEvalGeneResult.as_dict","text":"Return PhEval gene result as dictionary. Source code in src/pheval/post_processing/post_processing.py 30 31 32 33 34 35 36 37 def as_dict ( self ): \"\"\"Return PhEval gene result as dictionary.\"\"\" return { \"gene_symbol\" : self . pheval_gene_result . gene_symbol , \"gene_identifier\" : self . pheval_gene_result . gene_identifier , \"score\" : self . pheval_gene_result . score , \"rank\" : self . rank , }","title":"as_dict()"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.RankedPhEvalVariantResult","text":"PhEval variant result with corresponding rank. Source code in src/pheval/post_processing/post_processing.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 @dataclass class RankedPhEvalVariantResult : \"\"\"PhEval variant result with corresponding rank.\"\"\" pheval_variant_result : PhEvalVariantResult rank : int def as_dict ( self ): \"\"\"Return PhEval variant result as dictionary.\"\"\" return { \"chromosome\" : self . pheval_variant_result . chromosome , \"start\" : self . pheval_variant_result . start , \"end\" : self . pheval_variant_result . end , \"ref\" : self . pheval_variant_result . ref , \"alt\" : self . pheval_variant_result . alt , \"score\" : self . pheval_variant_result . score , \"rank\" : self . rank , }","title":"RankedPhEvalVariantResult"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.RankedPhEvalVariantResult.as_dict","text":"Return PhEval variant result as dictionary. Source code in src/pheval/post_processing/post_processing.py 59 60 61 62 63 64 65 66 67 68 69 def as_dict ( self ): \"\"\"Return PhEval variant result as dictionary.\"\"\" return { \"chromosome\" : self . pheval_variant_result . chromosome , \"start\" : self . pheval_variant_result . start , \"end\" : self . pheval_variant_result . end , \"ref\" : self . pheval_variant_result . ref , \"alt\" : self . pheval_variant_result . alt , \"score\" : self . pheval_variant_result . score , \"rank\" : self . rank , }","title":"as_dict()"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.ResultSorter","text":"Source code in src/pheval/post_processing/post_processing.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 class ResultSorter : def __init__ ( self , pheval_results : [ PhEvalGeneResult ] or [ PhEvalVariantResult ], sort_order : SortOrder ): self . pheval_results = pheval_results self . sort_order = sort_order def _sort_by_decreasing_score ( self ) -> [ PhEvalGeneResult ] or [ PhEvalVariantResult ]: \"\"\"Sort results in descending order.\"\"\" return sorted ( self . pheval_results , key = operator . attrgetter ( \"score\" ), reverse = True ) def _sort_by_increasing_score ( self ) -> [ PhEvalGeneResult ] or [ PhEvalVariantResult ]: \"\"\"Sort results in ascending order.\"\"\" return sorted ( self . pheval_results , key = operator . attrgetter ( \"score\" ), reverse = False ) def sort_pheval_results ( self ) -> [ PhEvalGeneResult ] or [ PhEvalVariantResult ]: \"\"\"Sort results with best score first.\"\"\" return ( self . _sort_by_increasing_score () if self . sort_order == SortOrder . ASCENDING else self . _sort_by_decreasing_score () )","title":"ResultSorter"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.ResultSorter.sort_pheval_results","text":"Sort results with best score first. Source code in src/pheval/post_processing/post_processing.py 92 93 94 95 96 97 98 def sort_pheval_results ( self ) -> [ PhEvalGeneResult ] or [ PhEvalVariantResult ]: \"\"\"Sort results with best score first.\"\"\" return ( self . _sort_by_increasing_score () if self . sort_order == SortOrder . ASCENDING else self . _sort_by_decreasing_score () )","title":"sort_pheval_results()"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.ScoreRanker","text":"Source code in src/pheval/post_processing/post_processing.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 class ScoreRanker : rank : int = 0 current_score : float = float ( \"inf\" ) count : int = 0 def __init__ ( self , sort_order : SortOrder ): self . sort_order = sort_order def _check_rank_order ( self , round_score : float ) -> None : \"\"\"Check the results are correctly ordered.\"\"\" if self . sort_order == SortOrder . ASCENDING and round_score < self . current_score != float ( \"inf\" ): raise ValueError ( \"Results are not correctly sorted!\" ) elif self . sort_order == SortOrder . DESCENDING and round_score > self . current_score != float ( \"inf\" ): raise ValueError ( \"Results are not correctly sorted!\" ) def rank_scores ( self , round_score : float ) -> int : \"\"\"Add ranks to a result, equal scores are given the same rank e.g., 1,1,3.\"\"\" self . _check_rank_order ( round_score ) self . count += 1 if self . current_score == round_score : return self . rank self . current_score = round_score self . rank = self . count return self . rank","title":"ScoreRanker"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.ScoreRanker.rank_scores","text":"Add ranks to a result, equal scores are given the same rank e.g., 1,1,3. Source code in src/pheval/post_processing/post_processing.py 120 121 122 123 124 125 126 127 128 def rank_scores ( self , round_score : float ) -> int : \"\"\"Add ranks to a result, equal scores are given the same rank e.g., 1,1,3.\"\"\" self . _check_rank_order ( round_score ) self . count += 1 if self . current_score == round_score : return self . rank self . current_score = round_score self . rank = self . count return self . rank","title":"rank_scores()"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.calculate_end_pos","text":"Calculate the end position for a variant. Source code in src/pheval/post_processing/post_processing.py 9 10 11 def calculate_end_pos ( variant_start : int , variant_ref : str ) -> int : \"\"\"Calculate the end position for a variant.\"\"\" return variant_start + len ( variant_ref ) - 1","title":"calculate_end_pos()"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.create_pheval_result","text":"Create PhEval gene/variant result with corresponding ranks. Source code in src/pheval/post_processing/post_processing.py 159 160 161 162 163 164 165 def create_pheval_result ( pheval_result : [ PhEvalGeneResult ] or [ PhEvalVariantResult ], sort_order_str : str ) -> [ RankedPhEvalGeneResult ] or [ RankedPhEvalVariantResult ]: \"\"\"Create PhEval gene/variant result with corresponding ranks.\"\"\" sort_order = _return_sort_order ( sort_order_str ) sorted_pheval_result = ResultSorter ( pheval_result , sort_order ) . sort_pheval_results () return rank_pheval_result ( sorted_pheval_result , sort_order )","title":"create_pheval_result()"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.rank_pheval_result","text":"Ranks either a PhEval gene or variant result post-processed from a tool specific output. Deals with ex aequo scores Source code in src/pheval/post_processing/post_processing.py 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 def rank_pheval_result ( pheval_result : [ PhEvalGeneResult ] or [ PhEvalVariantResult ], sort_order : SortOrder ) -> [ RankedPhEvalGeneResult ] or [ RankedPhEvalVariantResult ]: \"\"\"Ranks either a PhEval gene or variant result post-processed from a tool specific output. Deals with ex aequo scores\"\"\" score_ranker = ScoreRanker ( sort_order ) ranked_result = [] for result in pheval_result : ranked_result . append ( RankedPhEvalGeneResult ( pheval_gene_result = result , rank = score_ranker . rank_scores ( result . score ) ) ) if type ( result ) == PhEvalGeneResult else ranked_result . append ( RankedPhEvalVariantResult ( pheval_variant_result = result , rank = score_ranker . rank_scores ( result . score ) ) ) return ranked_result","title":"rank_pheval_result()"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.write_pheval_gene_result","text":"Write ranked PhEval gene result to tsv. Source code in src/pheval/post_processing/post_processing.py 168 169 170 171 172 173 174 175 176 177 178 179 180 def write_pheval_gene_result ( ranked_pheval_result : [ RankedPhEvalGeneResult ], output_dir : Path , tool_result_path : Path ) -> None : \"\"\"Write ranked PhEval gene result to tsv.\"\"\" ranked_result = pd . DataFrame ([ x . as_dict () for x in ranked_pheval_result ]) pheval_gene_output = ranked_result . loc [:, [ \"rank\" , \"score\" , \"gene_symbol\" , \"gene_identifier\" ]] pheval_gene_output . to_csv ( output_dir . joinpath ( \"pheval_gene_results/\" + tool_result_path . stem + \"-pheval_gene_result.tsv\" ), sep = \" \\t \" , index = False , )","title":"write_pheval_gene_result()"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.write_pheval_variant_result","text":"Write ranked PhEval variant result to tsv. Source code in src/pheval/post_processing/post_processing.py 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 def write_pheval_variant_result ( ranked_pheval_result : [ RankedPhEvalVariantResult ], output_dir : Path , tool_result_path : Path ) -> None : \"\"\"Write ranked PhEval variant result to tsv.\"\"\" ranked_result = pd . DataFrame ([ x . as_dict () for x in ranked_pheval_result ]) pheval_variant_output = ranked_result . loc [ :, [ \"rank\" , \"score\" , \"chromosome\" , \"start\" , \"end\" , \"ref\" , \"alt\" ] ] pheval_variant_output . to_csv ( output_dir . joinpath ( \"pheval_variant_results/\" + tool_result_path . stem + \"-pheval_variant_result.tsv\" ), sep = \" \\t \" , index = False , )","title":"write_pheval_variant_result()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/","text":"HpoRandomiser Randomises phenopacket phenotypic features. Source code in src/pheval/prepare/create_noisy_phenopackets.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 class HpoRandomiser : \"\"\"Randomises phenopacket phenotypic features.\"\"\" def __init__ ( self , hpo_ontology , scramble_factor : float ): self . hpo_ontology = hpo_ontology self . phenotypic_abnormalities = set ( hpo_ontology . roots ( predicates = [ \"HP:0000118\" ])) self . scramble_factor = scramble_factor def scramble_factor_proportions ( self , phenotypic_features : list [ PhenotypicFeature ]): \"\"\"Calculate proportion of scrambled hpo terms from scramble factor.\"\"\" if len ( phenotypic_features ) == 1 : return 1 else : return int ( round ( len ( phenotypic_features ) * self . scramble_factor , 0 )) def retrieve_hpo_term ( self , hpo_id : str ) -> PhenotypicFeature : \"\"\"Retrieves term for hpo id.\"\"\" rels = self . hpo_ontology . entity_alias_map ( hpo_id ) hpo_term = \"\" . join ( rels [( list ( rels . keys ())[ 0 ])]) return PhenotypicFeature ( type = OntologyClass ( id = hpo_id , label = hpo_term )) @staticmethod def retain_real_patient_terms ( phenotypic_features : list [ PhenotypicFeature ], number_of_scrambled_terms : int , ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of the maximum number of real patient HPO terms.\"\"\" if len ( phenotypic_features ) > 1 : number_of_real_id = len ( phenotypic_features ) - number_of_scrambled_terms else : number_of_real_id = 1 return random . sample ( phenotypic_features , number_of_real_id ) def convert_patient_terms_to_parent ( self , phenotypic_features : list [ PhenotypicFeature ], retained_phenotypic_features : list [ PhenotypicFeature ], number_of_scrambled_terms : int , ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of the HPO terms that have been converted to a parent term.\"\"\" remaining_hpo = [ i for i in phenotypic_features if i not in retained_phenotypic_features ] if len ( remaining_hpo ) == 0 : number_of_scrambled_terms = 0 hpo_terms_to_be_changed = list ( random . sample ( remaining_hpo , number_of_scrambled_terms )) parent_terms = [] for term in hpo_terms_to_be_changed : try : parent_terms . append ( self . retrieve_hpo_term ( self . hpo_ontology . hierararchical_parents ( term . type . id )[ 0 ] ) ) except IndexError : obsolete_term = self . hpo_ontology . entity_metadata_map ( term . type . id ) updated_term = list ( obsolete_term . values ())[ 0 ][ 0 ] parent_terms . append ( self . retrieve_hpo_term ( self . hpo_ontology . hierararchical_parents ( updated_term )[ 0 ] ) ) return parent_terms def create_random_hpo_terms ( self , number_of_scrambled_terms : int ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of random HPO terms\"\"\" random_ids = list ( random . sample ( sorted ( self . phenotypic_abnormalities ), number_of_scrambled_terms ) ) return [ self . retrieve_hpo_term ( random_id ) for random_id in random_ids ] def randomise_hpo_terms ( self , phenotypic_features : list [ PhenotypicFeature ], ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of randomised HPO terms.\"\"\" number_of_scrambled_terms = self . scramble_factor_proportions ( phenotypic_features ) retained_patient_terms = self . retain_real_patient_terms ( phenotypic_features , number_of_scrambled_terms ) return ( retained_patient_terms + self . convert_patient_terms_to_parent ( phenotypic_features , retained_patient_terms , number_of_scrambled_terms ) + self . create_random_hpo_terms ( number_of_scrambled_terms ) ) convert_patient_terms_to_parent ( phenotypic_features , retained_phenotypic_features , number_of_scrambled_terms ) Returns a list of the HPO terms that have been converted to a parent term. Source code in src/pheval/prepare/create_noisy_phenopackets.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def convert_patient_terms_to_parent ( self , phenotypic_features : list [ PhenotypicFeature ], retained_phenotypic_features : list [ PhenotypicFeature ], number_of_scrambled_terms : int , ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of the HPO terms that have been converted to a parent term.\"\"\" remaining_hpo = [ i for i in phenotypic_features if i not in retained_phenotypic_features ] if len ( remaining_hpo ) == 0 : number_of_scrambled_terms = 0 hpo_terms_to_be_changed = list ( random . sample ( remaining_hpo , number_of_scrambled_terms )) parent_terms = [] for term in hpo_terms_to_be_changed : try : parent_terms . append ( self . retrieve_hpo_term ( self . hpo_ontology . hierararchical_parents ( term . type . id )[ 0 ] ) ) except IndexError : obsolete_term = self . hpo_ontology . entity_metadata_map ( term . type . id ) updated_term = list ( obsolete_term . values ())[ 0 ][ 0 ] parent_terms . append ( self . retrieve_hpo_term ( self . hpo_ontology . hierararchical_parents ( updated_term )[ 0 ] ) ) return parent_terms create_random_hpo_terms ( number_of_scrambled_terms ) Returns a list of random HPO terms Source code in src/pheval/prepare/create_noisy_phenopackets.py 85 86 87 88 89 90 def create_random_hpo_terms ( self , number_of_scrambled_terms : int ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of random HPO terms\"\"\" random_ids = list ( random . sample ( sorted ( self . phenotypic_abnormalities ), number_of_scrambled_terms ) ) return [ self . retrieve_hpo_term ( random_id ) for random_id in random_ids ] randomise_hpo_terms ( phenotypic_features ) Returns a list of randomised HPO terms. Source code in src/pheval/prepare/create_noisy_phenopackets.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 def randomise_hpo_terms ( self , phenotypic_features : list [ PhenotypicFeature ], ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of randomised HPO terms.\"\"\" number_of_scrambled_terms = self . scramble_factor_proportions ( phenotypic_features ) retained_patient_terms = self . retain_real_patient_terms ( phenotypic_features , number_of_scrambled_terms ) return ( retained_patient_terms + self . convert_patient_terms_to_parent ( phenotypic_features , retained_patient_terms , number_of_scrambled_terms ) + self . create_random_hpo_terms ( number_of_scrambled_terms ) ) retain_real_patient_terms ( phenotypic_features , number_of_scrambled_terms ) staticmethod Returns a list of the maximum number of real patient HPO terms. Source code in src/pheval/prepare/create_noisy_phenopackets.py 44 45 46 47 48 49 50 51 52 53 54 @staticmethod def retain_real_patient_terms ( phenotypic_features : list [ PhenotypicFeature ], number_of_scrambled_terms : int , ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of the maximum number of real patient HPO terms.\"\"\" if len ( phenotypic_features ) > 1 : number_of_real_id = len ( phenotypic_features ) - number_of_scrambled_terms else : number_of_real_id = 1 return random . sample ( phenotypic_features , number_of_real_id ) retrieve_hpo_term ( hpo_id ) Retrieves term for hpo id. Source code in src/pheval/prepare/create_noisy_phenopackets.py 38 39 40 41 42 def retrieve_hpo_term ( self , hpo_id : str ) -> PhenotypicFeature : \"\"\"Retrieves term for hpo id.\"\"\" rels = self . hpo_ontology . entity_alias_map ( hpo_id ) hpo_term = \"\" . join ( rels [( list ( rels . keys ())[ 0 ])]) return PhenotypicFeature ( type = OntologyClass ( id = hpo_id , label = hpo_term )) scramble_factor_proportions ( phenotypic_features ) Calculate proportion of scrambled hpo terms from scramble factor. Source code in src/pheval/prepare/create_noisy_phenopackets.py 31 32 33 34 35 36 def scramble_factor_proportions ( self , phenotypic_features : list [ PhenotypicFeature ]): \"\"\"Calculate proportion of scrambled hpo terms from scramble factor.\"\"\" if len ( phenotypic_features ) == 1 : return 1 else : return int ( round ( len ( phenotypic_features ) * self . scramble_factor , 0 )) add_noise_to_phenotypic_profile ( hpo_randomiser , phenopacket ) Randomises the phenotypic profile of a phenopacket. Source code in src/pheval/prepare/create_noisy_phenopackets.py 110 111 112 113 114 115 116 117 118 119 120 def add_noise_to_phenotypic_profile ( hpo_randomiser : HpoRandomiser , phenopacket : Phenopacket or Family , ) -> Phenopacket or Family : \"\"\"Randomises the phenotypic profile of a phenopacket.\"\"\" # phenopacket_util = PhenopacketUtil(phenopacket) # phenotypic_features = phenopacket_util.observed_phenotypic_features() phenotypic_features = PhenopacketUtil ( phenopacket ) . observed_phenotypic_features () random_phenotypes = hpo_randomiser . randomise_hpo_terms ( phenotypic_features ) randomised_phenopacket = PhenopacketRebuilder ( phenopacket ) . add_randomised_hpo ( random_phenotypes ) return randomised_phenopacket create_scrambled_phenopacket ( output_dir , phenopacket_path , scramble_factor ) Creates a scrambled phenopacket. Source code in src/pheval/prepare/create_noisy_phenopackets.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def create_scrambled_phenopacket ( output_dir : Path , phenopacket_path : Path , scramble_factor : float ) -> None : \"\"\"Creates a scrambled phenopacket.\"\"\" try : output_dir . mkdir () except FileExistsError : pass ontology = load_ontology () hpo_randomiser = HpoRandomiser ( ontology , scramble_factor ) phenopacket = phenopacket_reader ( phenopacket_path ) created_noisy_phenopacket = add_noise_to_phenotypic_profile ( hpo_randomiser , phenopacket , ) write_phenopacket ( created_noisy_phenopacket , output_dir . joinpath ( phenopacket_path . name ), ) create_scrambled_phenopackets ( output_dir , phenopacket_dir , scramble_factor ) Creates scrambled phenopackets. Source code in src/pheval/prepare/create_noisy_phenopackets.py 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 def create_scrambled_phenopackets ( output_dir : Path , phenopacket_dir : Path , scramble_factor : float ) -> None : \"\"\"Creates scrambled phenopackets.\"\"\" try : output_dir . mkdir () except FileExistsError : pass ontology = load_ontology () hpo_randomiser = HpoRandomiser ( ontology , scramble_factor ) phenopacket_files = files_with_suffix ( phenopacket_dir , \".json\" ) for phenopacket_path in phenopacket_files : phenopacket = phenopacket_reader ( phenopacket_path ) created_noisy_phenopacket = add_noise_to_phenotypic_profile ( hpo_randomiser , phenopacket ) write_phenopacket ( created_noisy_phenopacket , output_dir . joinpath ( phenopacket_path . name , ), ) load_ontology () Loads human phenotype ontology. Source code in src/pheval/prepare/create_noisy_phenopackets.py 17 18 19 20 def load_ontology (): \"\"\"Loads human phenotype ontology.\"\"\" resource = OntologyResource ( slug = \"hp.obo\" , local = False ) return ProntoImplementation ( resource ) scramble_phenopackets ( output_dir , phenopacket_path , phenopacket_dir , scramble_factor ) Create scrambled phenopackets from either a single phenopacket or directory of phenopackets. Source code in src/pheval/prepare/create_noisy_phenopackets.py 166 167 168 169 170 171 172 173 def scramble_phenopackets ( output_dir : Path , phenopacket_path : Path , phenopacket_dir : Path , scramble_factor : float ) -> None : \"\"\"Create scrambled phenopackets from either a single phenopacket or directory of phenopackets.\"\"\" if phenopacket_path is not None : create_scrambled_phenopacket ( output_dir , phenopacket_path , scramble_factor ) elif phenopacket_dir is not None : create_scrambled_phenopackets ( output_dir , phenopacket_dir , scramble_factor )","title":"Create noisy phenopackets"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.HpoRandomiser","text":"Randomises phenopacket phenotypic features. Source code in src/pheval/prepare/create_noisy_phenopackets.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 class HpoRandomiser : \"\"\"Randomises phenopacket phenotypic features.\"\"\" def __init__ ( self , hpo_ontology , scramble_factor : float ): self . hpo_ontology = hpo_ontology self . phenotypic_abnormalities = set ( hpo_ontology . roots ( predicates = [ \"HP:0000118\" ])) self . scramble_factor = scramble_factor def scramble_factor_proportions ( self , phenotypic_features : list [ PhenotypicFeature ]): \"\"\"Calculate proportion of scrambled hpo terms from scramble factor.\"\"\" if len ( phenotypic_features ) == 1 : return 1 else : return int ( round ( len ( phenotypic_features ) * self . scramble_factor , 0 )) def retrieve_hpo_term ( self , hpo_id : str ) -> PhenotypicFeature : \"\"\"Retrieves term for hpo id.\"\"\" rels = self . hpo_ontology . entity_alias_map ( hpo_id ) hpo_term = \"\" . join ( rels [( list ( rels . keys ())[ 0 ])]) return PhenotypicFeature ( type = OntologyClass ( id = hpo_id , label = hpo_term )) @staticmethod def retain_real_patient_terms ( phenotypic_features : list [ PhenotypicFeature ], number_of_scrambled_terms : int , ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of the maximum number of real patient HPO terms.\"\"\" if len ( phenotypic_features ) > 1 : number_of_real_id = len ( phenotypic_features ) - number_of_scrambled_terms else : number_of_real_id = 1 return random . sample ( phenotypic_features , number_of_real_id ) def convert_patient_terms_to_parent ( self , phenotypic_features : list [ PhenotypicFeature ], retained_phenotypic_features : list [ PhenotypicFeature ], number_of_scrambled_terms : int , ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of the HPO terms that have been converted to a parent term.\"\"\" remaining_hpo = [ i for i in phenotypic_features if i not in retained_phenotypic_features ] if len ( remaining_hpo ) == 0 : number_of_scrambled_terms = 0 hpo_terms_to_be_changed = list ( random . sample ( remaining_hpo , number_of_scrambled_terms )) parent_terms = [] for term in hpo_terms_to_be_changed : try : parent_terms . append ( self . retrieve_hpo_term ( self . hpo_ontology . hierararchical_parents ( term . type . id )[ 0 ] ) ) except IndexError : obsolete_term = self . hpo_ontology . entity_metadata_map ( term . type . id ) updated_term = list ( obsolete_term . values ())[ 0 ][ 0 ] parent_terms . append ( self . retrieve_hpo_term ( self . hpo_ontology . hierararchical_parents ( updated_term )[ 0 ] ) ) return parent_terms def create_random_hpo_terms ( self , number_of_scrambled_terms : int ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of random HPO terms\"\"\" random_ids = list ( random . sample ( sorted ( self . phenotypic_abnormalities ), number_of_scrambled_terms ) ) return [ self . retrieve_hpo_term ( random_id ) for random_id in random_ids ] def randomise_hpo_terms ( self , phenotypic_features : list [ PhenotypicFeature ], ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of randomised HPO terms.\"\"\" number_of_scrambled_terms = self . scramble_factor_proportions ( phenotypic_features ) retained_patient_terms = self . retain_real_patient_terms ( phenotypic_features , number_of_scrambled_terms ) return ( retained_patient_terms + self . convert_patient_terms_to_parent ( phenotypic_features , retained_patient_terms , number_of_scrambled_terms ) + self . create_random_hpo_terms ( number_of_scrambled_terms ) )","title":"HpoRandomiser"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.HpoRandomiser.convert_patient_terms_to_parent","text":"Returns a list of the HPO terms that have been converted to a parent term. Source code in src/pheval/prepare/create_noisy_phenopackets.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def convert_patient_terms_to_parent ( self , phenotypic_features : list [ PhenotypicFeature ], retained_phenotypic_features : list [ PhenotypicFeature ], number_of_scrambled_terms : int , ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of the HPO terms that have been converted to a parent term.\"\"\" remaining_hpo = [ i for i in phenotypic_features if i not in retained_phenotypic_features ] if len ( remaining_hpo ) == 0 : number_of_scrambled_terms = 0 hpo_terms_to_be_changed = list ( random . sample ( remaining_hpo , number_of_scrambled_terms )) parent_terms = [] for term in hpo_terms_to_be_changed : try : parent_terms . append ( self . retrieve_hpo_term ( self . hpo_ontology . hierararchical_parents ( term . type . id )[ 0 ] ) ) except IndexError : obsolete_term = self . hpo_ontology . entity_metadata_map ( term . type . id ) updated_term = list ( obsolete_term . values ())[ 0 ][ 0 ] parent_terms . append ( self . retrieve_hpo_term ( self . hpo_ontology . hierararchical_parents ( updated_term )[ 0 ] ) ) return parent_terms","title":"convert_patient_terms_to_parent()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.HpoRandomiser.create_random_hpo_terms","text":"Returns a list of random HPO terms Source code in src/pheval/prepare/create_noisy_phenopackets.py 85 86 87 88 89 90 def create_random_hpo_terms ( self , number_of_scrambled_terms : int ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of random HPO terms\"\"\" random_ids = list ( random . sample ( sorted ( self . phenotypic_abnormalities ), number_of_scrambled_terms ) ) return [ self . retrieve_hpo_term ( random_id ) for random_id in random_ids ]","title":"create_random_hpo_terms()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.HpoRandomiser.randomise_hpo_terms","text":"Returns a list of randomised HPO terms. Source code in src/pheval/prepare/create_noisy_phenopackets.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 def randomise_hpo_terms ( self , phenotypic_features : list [ PhenotypicFeature ], ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of randomised HPO terms.\"\"\" number_of_scrambled_terms = self . scramble_factor_proportions ( phenotypic_features ) retained_patient_terms = self . retain_real_patient_terms ( phenotypic_features , number_of_scrambled_terms ) return ( retained_patient_terms + self . convert_patient_terms_to_parent ( phenotypic_features , retained_patient_terms , number_of_scrambled_terms ) + self . create_random_hpo_terms ( number_of_scrambled_terms ) )","title":"randomise_hpo_terms()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.HpoRandomiser.retain_real_patient_terms","text":"Returns a list of the maximum number of real patient HPO terms. Source code in src/pheval/prepare/create_noisy_phenopackets.py 44 45 46 47 48 49 50 51 52 53 54 @staticmethod def retain_real_patient_terms ( phenotypic_features : list [ PhenotypicFeature ], number_of_scrambled_terms : int , ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of the maximum number of real patient HPO terms.\"\"\" if len ( phenotypic_features ) > 1 : number_of_real_id = len ( phenotypic_features ) - number_of_scrambled_terms else : number_of_real_id = 1 return random . sample ( phenotypic_features , number_of_real_id )","title":"retain_real_patient_terms()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.HpoRandomiser.retrieve_hpo_term","text":"Retrieves term for hpo id. Source code in src/pheval/prepare/create_noisy_phenopackets.py 38 39 40 41 42 def retrieve_hpo_term ( self , hpo_id : str ) -> PhenotypicFeature : \"\"\"Retrieves term for hpo id.\"\"\" rels = self . hpo_ontology . entity_alias_map ( hpo_id ) hpo_term = \"\" . join ( rels [( list ( rels . keys ())[ 0 ])]) return PhenotypicFeature ( type = OntologyClass ( id = hpo_id , label = hpo_term ))","title":"retrieve_hpo_term()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.HpoRandomiser.scramble_factor_proportions","text":"Calculate proportion of scrambled hpo terms from scramble factor. Source code in src/pheval/prepare/create_noisy_phenopackets.py 31 32 33 34 35 36 def scramble_factor_proportions ( self , phenotypic_features : list [ PhenotypicFeature ]): \"\"\"Calculate proportion of scrambled hpo terms from scramble factor.\"\"\" if len ( phenotypic_features ) == 1 : return 1 else : return int ( round ( len ( phenotypic_features ) * self . scramble_factor , 0 ))","title":"scramble_factor_proportions()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.add_noise_to_phenotypic_profile","text":"Randomises the phenotypic profile of a phenopacket. Source code in src/pheval/prepare/create_noisy_phenopackets.py 110 111 112 113 114 115 116 117 118 119 120 def add_noise_to_phenotypic_profile ( hpo_randomiser : HpoRandomiser , phenopacket : Phenopacket or Family , ) -> Phenopacket or Family : \"\"\"Randomises the phenotypic profile of a phenopacket.\"\"\" # phenopacket_util = PhenopacketUtil(phenopacket) # phenotypic_features = phenopacket_util.observed_phenotypic_features() phenotypic_features = PhenopacketUtil ( phenopacket ) . observed_phenotypic_features () random_phenotypes = hpo_randomiser . randomise_hpo_terms ( phenotypic_features ) randomised_phenopacket = PhenopacketRebuilder ( phenopacket ) . add_randomised_hpo ( random_phenotypes ) return randomised_phenopacket","title":"add_noise_to_phenotypic_profile()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.create_scrambled_phenopacket","text":"Creates a scrambled phenopacket. Source code in src/pheval/prepare/create_noisy_phenopackets.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def create_scrambled_phenopacket ( output_dir : Path , phenopacket_path : Path , scramble_factor : float ) -> None : \"\"\"Creates a scrambled phenopacket.\"\"\" try : output_dir . mkdir () except FileExistsError : pass ontology = load_ontology () hpo_randomiser = HpoRandomiser ( ontology , scramble_factor ) phenopacket = phenopacket_reader ( phenopacket_path ) created_noisy_phenopacket = add_noise_to_phenotypic_profile ( hpo_randomiser , phenopacket , ) write_phenopacket ( created_noisy_phenopacket , output_dir . joinpath ( phenopacket_path . name ), )","title":"create_scrambled_phenopacket()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.create_scrambled_phenopackets","text":"Creates scrambled phenopackets. Source code in src/pheval/prepare/create_noisy_phenopackets.py 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 def create_scrambled_phenopackets ( output_dir : Path , phenopacket_dir : Path , scramble_factor : float ) -> None : \"\"\"Creates scrambled phenopackets.\"\"\" try : output_dir . mkdir () except FileExistsError : pass ontology = load_ontology () hpo_randomiser = HpoRandomiser ( ontology , scramble_factor ) phenopacket_files = files_with_suffix ( phenopacket_dir , \".json\" ) for phenopacket_path in phenopacket_files : phenopacket = phenopacket_reader ( phenopacket_path ) created_noisy_phenopacket = add_noise_to_phenotypic_profile ( hpo_randomiser , phenopacket ) write_phenopacket ( created_noisy_phenopacket , output_dir . joinpath ( phenopacket_path . name , ), )","title":"create_scrambled_phenopackets()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.load_ontology","text":"Loads human phenotype ontology. Source code in src/pheval/prepare/create_noisy_phenopackets.py 17 18 19 20 def load_ontology (): \"\"\"Loads human phenotype ontology.\"\"\" resource = OntologyResource ( slug = \"hp.obo\" , local = False ) return ProntoImplementation ( resource )","title":"load_ontology()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.scramble_phenopackets","text":"Create scrambled phenopackets from either a single phenopacket or directory of phenopackets. Source code in src/pheval/prepare/create_noisy_phenopackets.py 166 167 168 169 170 171 172 173 def scramble_phenopackets ( output_dir : Path , phenopacket_path : Path , phenopacket_dir : Path , scramble_factor : float ) -> None : \"\"\"Create scrambled phenopackets from either a single phenopacket or directory of phenopackets.\"\"\" if phenopacket_path is not None : create_scrambled_phenopacket ( output_dir , phenopacket_path , scramble_factor ) elif phenopacket_dir is not None : create_scrambled_phenopackets ( output_dir , phenopacket_dir , scramble_factor )","title":"scramble_phenopackets()"},{"location":"api/pheval/prepare/create_spiked_vcf/","text":"VcfHeader dataclass Data obtained from VCF header Source code in src/pheval/prepare/create_spiked_vcf.py 77 78 79 80 81 82 83 @dataclass class VcfHeader : \"\"\"Data obtained from VCF header\"\"\" sample_id : str assembly : str chr_status : bool VcfHeaderParser Parses the header of a VCF file. Source code in src/pheval/prepare/create_spiked_vcf.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 class VcfHeaderParser : \"\"\"Parses the header of a VCF file.\"\"\" def __init__ ( self , vcf_contents : list [ str ]): self . vcf_contents = vcf_contents def parse_assembly ( self ) -> tuple [ str , bool ]: \"\"\"Parses the genome assembly and format of vcf_records.\"\"\" vcf_assembly = {} chr_status = False for line in self . vcf_contents : if line . startswith ( \"##contig=<ID\" ): line_split = line . split ( \",\" ) chromosome = line_split [ 0 ] . split ( \"=\" )[ 2 ] if \"chr\" in chromosome : chr_status = True chromosome = chromosome . replace ( \"chr\" , \"\" ) contig_length = line_split [ 1 ] . split ( \"=\" )[ 1 ] vcf_assembly [ chromosome ] = int ( contig_length ) vcf_assembly = { i : vcf_assembly [ i ] for i in vcf_assembly if i . isdigit ()} assembly = [ k for k , v in genome_assemblies . items () if v == vcf_assembly ][ 0 ] return assembly , chr_status def parse_sample_id ( self ) -> str : \"\"\"Parses the sample ID of the VCF.\"\"\" for line in self . vcf_contents : if line . startswith ( \"#CHROM\" ): return line . split ( \" \\t \" )[ 9 ] . rstrip () def parse_vcf_header ( self ) -> VcfHeader : \"\"\"Parses the header of the VCF.\"\"\" assembly , chr_status = self . parse_assembly () sample_id = self . parse_sample_id () return VcfHeader ( sample_id , assembly , chr_status ) parse_assembly () Parses the genome assembly and format of vcf_records. Source code in src/pheval/prepare/create_spiked_vcf.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 def parse_assembly ( self ) -> tuple [ str , bool ]: \"\"\"Parses the genome assembly and format of vcf_records.\"\"\" vcf_assembly = {} chr_status = False for line in self . vcf_contents : if line . startswith ( \"##contig=<ID\" ): line_split = line . split ( \",\" ) chromosome = line_split [ 0 ] . split ( \"=\" )[ 2 ] if \"chr\" in chromosome : chr_status = True chromosome = chromosome . replace ( \"chr\" , \"\" ) contig_length = line_split [ 1 ] . split ( \"=\" )[ 1 ] vcf_assembly [ chromosome ] = int ( contig_length ) vcf_assembly = { i : vcf_assembly [ i ] for i in vcf_assembly if i . isdigit ()} assembly = [ k for k , v in genome_assemblies . items () if v == vcf_assembly ][ 0 ] return assembly , chr_status parse_sample_id () Parses the sample ID of the VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 136 137 138 139 140 def parse_sample_id ( self ) -> str : \"\"\"Parses the sample ID of the VCF.\"\"\" for line in self . vcf_contents : if line . startswith ( \"#CHROM\" ): return line . split ( \" \\t \" )[ 9 ] . rstrip () parse_vcf_header () Parses the header of the VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 142 143 144 145 146 def parse_vcf_header ( self ) -> VcfHeader : \"\"\"Parses the header of the VCF.\"\"\" assembly , chr_status = self . parse_assembly () sample_id = self . parse_sample_id () return VcfHeader ( sample_id , assembly , chr_status ) VcfPicker Chooses a VCF file from random for a directory if provided, otherwise selects the single template. Source code in src/pheval/prepare/create_spiked_vcf.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class VcfPicker : \"\"\"Chooses a VCF file from random for a directory if provided, otherwise selects the single template.\"\"\" def __init__ ( self , template_vcf : Path or None , vcf_dir : Path or None ): self . template_vcf = template_vcf self . vcf_dir = vcf_dir def pick_file_from_dir ( self ) -> Path : \"\"\"Selects a file from a directory at random.\"\"\" return secrets . choice ( all_files ( self . vcf_dir )) def pick_file ( self ) -> Path : \"\"\"Selects a VCF file from random when given a directory, if not, template vcf is assigned.\"\"\" return self . pick_file_from_dir () if self . vcf_dir is not None else self . template_vcf pick_file () Selects a VCF file from random when given a directory, if not, template vcf is assigned. Source code in src/pheval/prepare/create_spiked_vcf.py 97 98 99 def pick_file ( self ) -> Path : \"\"\"Selects a VCF file from random when given a directory, if not, template vcf is assigned.\"\"\" return self . pick_file_from_dir () if self . vcf_dir is not None else self . template_vcf pick_file_from_dir () Selects a file from a directory at random. Source code in src/pheval/prepare/create_spiked_vcf.py 93 94 95 def pick_file_from_dir ( self ) -> Path : \"\"\"Selects a file from a directory at random.\"\"\" return secrets . choice ( all_files ( self . vcf_dir )) VcfSpiker Spikes proband variants into template VCF file contents. Source code in src/pheval/prepare/create_spiked_vcf.py 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 class VcfSpiker : \"\"\"Spikes proband variants into template VCF file contents.\"\"\" def __init__ ( self , vcf_contents : list [ str ], proband_causative_variants : list [ ProbandCausativeVariant ], vcf_header : VcfHeader , ): self . vcf_contents = vcf_contents self . proband_causative_variants = proband_causative_variants self . vcf_header = vcf_header def construct_variant_entry ( self , proband_variant_data : ProbandCausativeVariant ) -> list [ str ]: \"\"\"Constructs variant entries.\"\"\" genotype_codes = { \"hemizygous\" : \"0/1\" , \"homozygous\" : \"1/1\" , \"heterozygous\" : \"0/1\" , \"compound heterozygous\" : \"0/1\" , } if self . vcf_header . chr_status is True and \"chr\" not in proband_variant_data . variant . chrom : proband_variant_data . variant . chrom = \"chr\" + proband_variant_data . variant . chrom return [ proband_variant_data . variant . chrom , str ( proband_variant_data . variant . pos ), \".\" , proband_variant_data . variant . ref , proband_variant_data . variant . alt , \"100\" , \"PASS\" , \"SPIKED_VARIANT_\" + proband_variant_data . genotype . upper (), \"GT:AD:DP:GQ:PL\" , genotype_codes [ proband_variant_data . genotype . lower ()] + \":0,2:2:12:180,12,0\" + \" \\n \" , ] def construct_vcf_records ( self ): \"\"\"Inserts spiked variant into correct position within VCF.\"\"\" updated_vcf_records = copy ( self . vcf_contents ) for variant in self . proband_causative_variants : variant = self . construct_variant_entry ( variant ) variant_entry_position = [ i for i , val in enumerate ( updated_vcf_records ) if val . split ( \" \\t \" )[ 0 ] == variant [ 0 ] and int ( val . split ( \" \\t \" )[ 1 ]) < int ( variant [ 1 ]) ][ - 1 ] + 1 updated_vcf_records . insert ( variant_entry_position , \" \\t \" . join ( variant )) return updated_vcf_records def construct_header ( self , updated_vcf_records ) -> list [ str ]: \"\"\"Constructs the header of the VCF.\"\"\" updated_vcf_file = [] for line in updated_vcf_records : text = line . replace ( self . vcf_header . sample_id , self . proband_causative_variants [ 0 ] . proband_id , ) updated_vcf_file . append ( text ) return updated_vcf_file def construct_vcf ( self ) -> list [ str ]: \"\"\"Constructs the entire spiked VCF.\"\"\" return self . construct_header ( self . construct_vcf_records ()) construct_header ( updated_vcf_records ) Constructs the header of the VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 216 217 218 219 220 221 222 223 224 225 def construct_header ( self , updated_vcf_records ) -> list [ str ]: \"\"\"Constructs the header of the VCF.\"\"\" updated_vcf_file = [] for line in updated_vcf_records : text = line . replace ( self . vcf_header . sample_id , self . proband_causative_variants [ 0 ] . proband_id , ) updated_vcf_file . append ( text ) return updated_vcf_file construct_variant_entry ( proband_variant_data ) Constructs variant entries. Source code in src/pheval/prepare/create_spiked_vcf.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 def construct_variant_entry ( self , proband_variant_data : ProbandCausativeVariant ) -> list [ str ]: \"\"\"Constructs variant entries.\"\"\" genotype_codes = { \"hemizygous\" : \"0/1\" , \"homozygous\" : \"1/1\" , \"heterozygous\" : \"0/1\" , \"compound heterozygous\" : \"0/1\" , } if self . vcf_header . chr_status is True and \"chr\" not in proband_variant_data . variant . chrom : proband_variant_data . variant . chrom = \"chr\" + proband_variant_data . variant . chrom return [ proband_variant_data . variant . chrom , str ( proband_variant_data . variant . pos ), \".\" , proband_variant_data . variant . ref , proband_variant_data . variant . alt , \"100\" , \"PASS\" , \"SPIKED_VARIANT_\" + proband_variant_data . genotype . upper (), \"GT:AD:DP:GQ:PL\" , genotype_codes [ proband_variant_data . genotype . lower ()] + \":0,2:2:12:180,12,0\" + \" \\n \" , ] construct_vcf () Constructs the entire spiked VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 227 228 229 def construct_vcf ( self ) -> list [ str ]: \"\"\"Constructs the entire spiked VCF.\"\"\" return self . construct_header ( self . construct_vcf_records ()) construct_vcf_records () Inserts spiked variant into correct position within VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 203 204 205 206 207 208 209 210 211 212 213 214 def construct_vcf_records ( self ): \"\"\"Inserts spiked variant into correct position within VCF.\"\"\" updated_vcf_records = copy ( self . vcf_contents ) for variant in self . proband_causative_variants : variant = self . construct_variant_entry ( variant ) variant_entry_position = [ i for i , val in enumerate ( updated_vcf_records ) if val . split ( \" \\t \" )[ 0 ] == variant [ 0 ] and int ( val . split ( \" \\t \" )[ 1 ]) < int ( variant [ 1 ]) ][ - 1 ] + 1 updated_vcf_records . insert ( variant_entry_position , \" \\t \" . join ( variant )) return updated_vcf_records VcfWriter Source code in src/pheval/prepare/create_spiked_vcf.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 class VcfWriter : def __init__ ( self , vcf_contents : list [ str ], spiked_vcf_file_path : Path , ): self . vcf_contents = vcf_contents self . spiked_vcf_file_path = spiked_vcf_file_path def write_gzip ( self ) -> None : \"\"\"Writes gzipped vcf file.\"\"\" encoded_contents = [ line . encode () for line in self . vcf_contents ] with gzip . open ( self . spiked_vcf_file_path , \"wb\" ) as f : for line in encoded_contents : f . write ( line ) f . close () def write_uncompressed ( self ) -> None : \"\"\"Writes an uncompressed vcf file.\"\"\" with open ( self . spiked_vcf_file_path , \"w\" ) as file : file . writelines ( self . vcf_contents ) file . close () def write_vcf_file ( self ) -> None : \"\"\"Writes spiked vcf file.\"\"\" self . write_gzip () if is_gzipped ( self . spiked_vcf_file_path ) else self . write_uncompressed () write_gzip () Writes gzipped vcf file. Source code in src/pheval/prepare/create_spiked_vcf.py 241 242 243 244 245 246 247 def write_gzip ( self ) -> None : \"\"\"Writes gzipped vcf file.\"\"\" encoded_contents = [ line . encode () for line in self . vcf_contents ] with gzip . open ( self . spiked_vcf_file_path , \"wb\" ) as f : for line in encoded_contents : f . write ( line ) f . close () write_uncompressed () Writes an uncompressed vcf file. Source code in src/pheval/prepare/create_spiked_vcf.py 249 250 251 252 253 def write_uncompressed ( self ) -> None : \"\"\"Writes an uncompressed vcf file.\"\"\" with open ( self . spiked_vcf_file_path , \"w\" ) as file : file . writelines ( self . vcf_contents ) file . close () write_vcf_file () Writes spiked vcf file. Source code in src/pheval/prepare/create_spiked_vcf.py 255 256 257 def write_vcf_file ( self ) -> None : \"\"\"Writes spiked vcf file.\"\"\" self . write_gzip () if is_gzipped ( self . spiked_vcf_file_path ) else self . write_uncompressed () check_variant_assembly ( proband_causative_variants , vcf_header , phenopacket_path ) Checks the assembly of the variant assembly against the VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 def check_variant_assembly ( proband_causative_variants : list [ ProbandCausativeVariant ], vcf_header : VcfHeader , phenopacket_path : Path , ): \"\"\"Checks the assembly of the variant assembly against the VCF.\"\"\" compatible_genome_assembly = { \"GRCh37\" , \"hg19\" , \"GRCh38\" , \"hg38\" } phenopacket_assembly = list ({ variant . assembly for variant in proband_causative_variants }) if len ( phenopacket_assembly ) > 1 : raise ValueError ( \"Too many genome assemblies!\" ) if phenopacket_assembly [ 0 ] not in compatible_genome_assembly : raise IncompatibleGenomeAssemblyError ( phenopacket_assembly , phenopacket_path ) if phenopacket_assembly [ 0 ] != vcf_header . assembly : raise IncompatibleGenomeAssemblyError ( assembly = phenopacket_assembly , phenopacket = phenopacket_path ) create_spiked_vcf ( output_dir , phenopacket_path , template_vcf_path , vcf_dir ) Creates a spiked vcf for a phenopacket. Source code in src/pheval/prepare/create_spiked_vcf.py 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 def create_spiked_vcf ( output_dir : Path , phenopacket_path : Path , template_vcf_path : Path , vcf_dir : Path ): \"\"\"Creates a spiked vcf for a phenopacket.\"\"\" if template_vcf_path is None and vcf_dir is None : raise InputError ( \"Either a template_vcf or vcf_dir must be specified\" ) vcf_file_path = VcfPicker ( template_vcf_path , vcf_dir ) . pick_file () phenopacket = phenopacket_reader ( phenopacket_path ) spiked_vcf_file_message = generate_spiked_vcf_file ( output_dir , phenopacket , phenopacket_path , vcf_file_path ) updated_phenopacket = PhenopacketRebuilder ( phenopacket ) . add_spiked_vcf_path ( spiked_vcf_file_message ) write_phenopacket ( updated_phenopacket , phenopacket_path ) create_spiked_vcfs ( output_dir , phenopacket_dir , template_vcf_path , vcf_dir ) Creates spiked vcfs for phenopackets. Source code in src/pheval/prepare/create_spiked_vcf.py 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 def create_spiked_vcfs ( output_dir : Path , phenopacket_dir : Path , template_vcf_path : Path , vcf_dir : Path ): \"\"\"Creates spiked vcfs for phenopackets.\"\"\" if template_vcf_path is None and vcf_dir is None : raise InputError ( \"Either a template_vcf or vcf_dir must be specified\" ) for phenopacket_path in files_with_suffix ( phenopacket_dir , \".json\" ): vcf_file_path = VcfPicker ( template_vcf_path , vcf_dir ) . pick_file () phenopacket = phenopacket_reader ( phenopacket_path ) spiked_vcf_file_message = generate_spiked_vcf_file ( output_dir , phenopacket , phenopacket_path , vcf_file_path ) updated_phenopacket = PhenopacketRebuilder ( phenopacket ) . add_spiked_vcf_path ( spiked_vcf_file_message ) write_phenopacket ( updated_phenopacket , phenopacket_path ) generate_spiked_vcf_file ( output_dir , phenopacket , phenopacket_path , chosen_template_vcf ) Writes spiked vcf contents to a new file. Source code in src/pheval/prepare/create_spiked_vcf.py 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 def generate_spiked_vcf_file ( output_dir : Path , phenopacket : Phenopacket or Family , phenopacket_path : Path , chosen_template_vcf : Path , ) -> File : \"\"\"Writes spiked vcf contents to a new file.\"\"\" try : output_dir . mkdir () info_log . info ( f \" Created a directory { output_dir } \" ) except FileExistsError : pass vcf_assembly , spiked_vcf = spike_vcf_contents ( phenopacket , phenopacket_path , chosen_template_vcf ) spiked_vcf_path = ( output_dir . joinpath ( phenopacket_path . name . replace ( \".json\" , \".vcf.gz\" )) if is_gzipped ( chosen_template_vcf ) else output_dir . joinpath ( phenopacket_path . name . replace ( \".json\" , \".vcf\" )) ) VcfWriter ( spiked_vcf , spiked_vcf_path ) . write_vcf_file () return File ( uri = str ( spiked_vcf_path . absolute ()), file_attributes = { \"fileFormat\" : \"VCF\" , \"genomeAssembly\" : vcf_assembly }, ) read_vcf ( vcf_file ) Reads the contents of a VCF file into memory - handles both uncompressed and gzipped. Source code in src/pheval/prepare/create_spiked_vcf.py 102 103 104 105 106 107 108 109 110 def read_vcf ( vcf_file : Path ) -> list [ str ]: \"\"\"Reads the contents of a VCF file into memory - handles both uncompressed and gzipped.\"\"\" open_fn = gzip . open if is_gzipped ( vcf_file ) else open vcf = open_fn ( vcf_file ) vcf_contents = ( [ line . decode () for line in vcf . readlines ()] if is_gzipped ( vcf_file ) else vcf . readlines () ) vcf . close () return vcf_contents spike_vcf_contents ( phenopacket , phenopacket_path , chosen_template_vcf ) Spikes VCF records with variants. Source code in src/pheval/prepare/create_spiked_vcf.py 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 def spike_vcf_contents ( phenopacket : Phenopacket or Family , phenopacket_path : Path , chosen_template_vcf : Path , ) -> tuple [ str , list [ str ]]: \"\"\"Spikes VCF records with variants.\"\"\" # this is a separate function to a click command as it will fail if annotated with click annotations # and referenced from another click command phenopacket_causative_variants = PhenopacketUtil ( phenopacket ) . causative_variants () vcf_contents = read_vcf ( chosen_template_vcf ) vcf_header = VcfHeaderParser ( vcf_contents ) . parse_vcf_header () check_variant_assembly ( phenopacket_causative_variants , vcf_header , phenopacket_path ) return ( vcf_header . assembly , VcfSpiker ( vcf_contents , phenopacket_causative_variants , vcf_header ) . construct_vcf (), ) spike_vcfs ( output_dir , phenopacket_path , phenopacket_dir , template_vcf_path , vcf_dir ) Create spiked VCF from either a phenopacket or a phenopacket directory. Source code in src/pheval/prepare/create_spiked_vcf.py 343 344 345 346 347 348 349 350 351 352 353 354 def spike_vcfs ( output_dir : Path , phenopacket_path : Path , phenopacket_dir : Path , template_vcf_path : Path , vcf_dir : Path , ): \"\"\"Create spiked VCF from either a phenopacket or a phenopacket directory.\"\"\" if phenopacket_path is not None : create_spiked_vcf ( output_dir , phenopacket_path , template_vcf_path , vcf_dir ) elif phenopacket_dir is not None : create_spiked_vcfs ( output_dir , phenopacket_dir , template_vcf_path , vcf_dir )","title":"Create spiked vcf"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfHeader","text":"Data obtained from VCF header Source code in src/pheval/prepare/create_spiked_vcf.py 77 78 79 80 81 82 83 @dataclass class VcfHeader : \"\"\"Data obtained from VCF header\"\"\" sample_id : str assembly : str chr_status : bool","title":"VcfHeader"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfHeaderParser","text":"Parses the header of a VCF file. Source code in src/pheval/prepare/create_spiked_vcf.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 class VcfHeaderParser : \"\"\"Parses the header of a VCF file.\"\"\" def __init__ ( self , vcf_contents : list [ str ]): self . vcf_contents = vcf_contents def parse_assembly ( self ) -> tuple [ str , bool ]: \"\"\"Parses the genome assembly and format of vcf_records.\"\"\" vcf_assembly = {} chr_status = False for line in self . vcf_contents : if line . startswith ( \"##contig=<ID\" ): line_split = line . split ( \",\" ) chromosome = line_split [ 0 ] . split ( \"=\" )[ 2 ] if \"chr\" in chromosome : chr_status = True chromosome = chromosome . replace ( \"chr\" , \"\" ) contig_length = line_split [ 1 ] . split ( \"=\" )[ 1 ] vcf_assembly [ chromosome ] = int ( contig_length ) vcf_assembly = { i : vcf_assembly [ i ] for i in vcf_assembly if i . isdigit ()} assembly = [ k for k , v in genome_assemblies . items () if v == vcf_assembly ][ 0 ] return assembly , chr_status def parse_sample_id ( self ) -> str : \"\"\"Parses the sample ID of the VCF.\"\"\" for line in self . vcf_contents : if line . startswith ( \"#CHROM\" ): return line . split ( \" \\t \" )[ 9 ] . rstrip () def parse_vcf_header ( self ) -> VcfHeader : \"\"\"Parses the header of the VCF.\"\"\" assembly , chr_status = self . parse_assembly () sample_id = self . parse_sample_id () return VcfHeader ( sample_id , assembly , chr_status )","title":"VcfHeaderParser"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfHeaderParser.parse_assembly","text":"Parses the genome assembly and format of vcf_records. Source code in src/pheval/prepare/create_spiked_vcf.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 def parse_assembly ( self ) -> tuple [ str , bool ]: \"\"\"Parses the genome assembly and format of vcf_records.\"\"\" vcf_assembly = {} chr_status = False for line in self . vcf_contents : if line . startswith ( \"##contig=<ID\" ): line_split = line . split ( \",\" ) chromosome = line_split [ 0 ] . split ( \"=\" )[ 2 ] if \"chr\" in chromosome : chr_status = True chromosome = chromosome . replace ( \"chr\" , \"\" ) contig_length = line_split [ 1 ] . split ( \"=\" )[ 1 ] vcf_assembly [ chromosome ] = int ( contig_length ) vcf_assembly = { i : vcf_assembly [ i ] for i in vcf_assembly if i . isdigit ()} assembly = [ k for k , v in genome_assemblies . items () if v == vcf_assembly ][ 0 ] return assembly , chr_status","title":"parse_assembly()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfHeaderParser.parse_sample_id","text":"Parses the sample ID of the VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 136 137 138 139 140 def parse_sample_id ( self ) -> str : \"\"\"Parses the sample ID of the VCF.\"\"\" for line in self . vcf_contents : if line . startswith ( \"#CHROM\" ): return line . split ( \" \\t \" )[ 9 ] . rstrip ()","title":"parse_sample_id()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfHeaderParser.parse_vcf_header","text":"Parses the header of the VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 142 143 144 145 146 def parse_vcf_header ( self ) -> VcfHeader : \"\"\"Parses the header of the VCF.\"\"\" assembly , chr_status = self . parse_assembly () sample_id = self . parse_sample_id () return VcfHeader ( sample_id , assembly , chr_status )","title":"parse_vcf_header()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfPicker","text":"Chooses a VCF file from random for a directory if provided, otherwise selects the single template. Source code in src/pheval/prepare/create_spiked_vcf.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class VcfPicker : \"\"\"Chooses a VCF file from random for a directory if provided, otherwise selects the single template.\"\"\" def __init__ ( self , template_vcf : Path or None , vcf_dir : Path or None ): self . template_vcf = template_vcf self . vcf_dir = vcf_dir def pick_file_from_dir ( self ) -> Path : \"\"\"Selects a file from a directory at random.\"\"\" return secrets . choice ( all_files ( self . vcf_dir )) def pick_file ( self ) -> Path : \"\"\"Selects a VCF file from random when given a directory, if not, template vcf is assigned.\"\"\" return self . pick_file_from_dir () if self . vcf_dir is not None else self . template_vcf","title":"VcfPicker"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfPicker.pick_file","text":"Selects a VCF file from random when given a directory, if not, template vcf is assigned. Source code in src/pheval/prepare/create_spiked_vcf.py 97 98 99 def pick_file ( self ) -> Path : \"\"\"Selects a VCF file from random when given a directory, if not, template vcf is assigned.\"\"\" return self . pick_file_from_dir () if self . vcf_dir is not None else self . template_vcf","title":"pick_file()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfPicker.pick_file_from_dir","text":"Selects a file from a directory at random. Source code in src/pheval/prepare/create_spiked_vcf.py 93 94 95 def pick_file_from_dir ( self ) -> Path : \"\"\"Selects a file from a directory at random.\"\"\" return secrets . choice ( all_files ( self . vcf_dir ))","title":"pick_file_from_dir()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfSpiker","text":"Spikes proband variants into template VCF file contents. Source code in src/pheval/prepare/create_spiked_vcf.py 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 class VcfSpiker : \"\"\"Spikes proband variants into template VCF file contents.\"\"\" def __init__ ( self , vcf_contents : list [ str ], proband_causative_variants : list [ ProbandCausativeVariant ], vcf_header : VcfHeader , ): self . vcf_contents = vcf_contents self . proband_causative_variants = proband_causative_variants self . vcf_header = vcf_header def construct_variant_entry ( self , proband_variant_data : ProbandCausativeVariant ) -> list [ str ]: \"\"\"Constructs variant entries.\"\"\" genotype_codes = { \"hemizygous\" : \"0/1\" , \"homozygous\" : \"1/1\" , \"heterozygous\" : \"0/1\" , \"compound heterozygous\" : \"0/1\" , } if self . vcf_header . chr_status is True and \"chr\" not in proband_variant_data . variant . chrom : proband_variant_data . variant . chrom = \"chr\" + proband_variant_data . variant . chrom return [ proband_variant_data . variant . chrom , str ( proband_variant_data . variant . pos ), \".\" , proband_variant_data . variant . ref , proband_variant_data . variant . alt , \"100\" , \"PASS\" , \"SPIKED_VARIANT_\" + proband_variant_data . genotype . upper (), \"GT:AD:DP:GQ:PL\" , genotype_codes [ proband_variant_data . genotype . lower ()] + \":0,2:2:12:180,12,0\" + \" \\n \" , ] def construct_vcf_records ( self ): \"\"\"Inserts spiked variant into correct position within VCF.\"\"\" updated_vcf_records = copy ( self . vcf_contents ) for variant in self . proband_causative_variants : variant = self . construct_variant_entry ( variant ) variant_entry_position = [ i for i , val in enumerate ( updated_vcf_records ) if val . split ( \" \\t \" )[ 0 ] == variant [ 0 ] and int ( val . split ( \" \\t \" )[ 1 ]) < int ( variant [ 1 ]) ][ - 1 ] + 1 updated_vcf_records . insert ( variant_entry_position , \" \\t \" . join ( variant )) return updated_vcf_records def construct_header ( self , updated_vcf_records ) -> list [ str ]: \"\"\"Constructs the header of the VCF.\"\"\" updated_vcf_file = [] for line in updated_vcf_records : text = line . replace ( self . vcf_header . sample_id , self . proband_causative_variants [ 0 ] . proband_id , ) updated_vcf_file . append ( text ) return updated_vcf_file def construct_vcf ( self ) -> list [ str ]: \"\"\"Constructs the entire spiked VCF.\"\"\" return self . construct_header ( self . construct_vcf_records ())","title":"VcfSpiker"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfSpiker.construct_header","text":"Constructs the header of the VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 216 217 218 219 220 221 222 223 224 225 def construct_header ( self , updated_vcf_records ) -> list [ str ]: \"\"\"Constructs the header of the VCF.\"\"\" updated_vcf_file = [] for line in updated_vcf_records : text = line . replace ( self . vcf_header . sample_id , self . proband_causative_variants [ 0 ] . proband_id , ) updated_vcf_file . append ( text ) return updated_vcf_file","title":"construct_header()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfSpiker.construct_variant_entry","text":"Constructs variant entries. Source code in src/pheval/prepare/create_spiked_vcf.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 def construct_variant_entry ( self , proband_variant_data : ProbandCausativeVariant ) -> list [ str ]: \"\"\"Constructs variant entries.\"\"\" genotype_codes = { \"hemizygous\" : \"0/1\" , \"homozygous\" : \"1/1\" , \"heterozygous\" : \"0/1\" , \"compound heterozygous\" : \"0/1\" , } if self . vcf_header . chr_status is True and \"chr\" not in proband_variant_data . variant . chrom : proband_variant_data . variant . chrom = \"chr\" + proband_variant_data . variant . chrom return [ proband_variant_data . variant . chrom , str ( proband_variant_data . variant . pos ), \".\" , proband_variant_data . variant . ref , proband_variant_data . variant . alt , \"100\" , \"PASS\" , \"SPIKED_VARIANT_\" + proband_variant_data . genotype . upper (), \"GT:AD:DP:GQ:PL\" , genotype_codes [ proband_variant_data . genotype . lower ()] + \":0,2:2:12:180,12,0\" + \" \\n \" , ]","title":"construct_variant_entry()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfSpiker.construct_vcf","text":"Constructs the entire spiked VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 227 228 229 def construct_vcf ( self ) -> list [ str ]: \"\"\"Constructs the entire spiked VCF.\"\"\" return self . construct_header ( self . construct_vcf_records ())","title":"construct_vcf()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfSpiker.construct_vcf_records","text":"Inserts spiked variant into correct position within VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 203 204 205 206 207 208 209 210 211 212 213 214 def construct_vcf_records ( self ): \"\"\"Inserts spiked variant into correct position within VCF.\"\"\" updated_vcf_records = copy ( self . vcf_contents ) for variant in self . proband_causative_variants : variant = self . construct_variant_entry ( variant ) variant_entry_position = [ i for i , val in enumerate ( updated_vcf_records ) if val . split ( \" \\t \" )[ 0 ] == variant [ 0 ] and int ( val . split ( \" \\t \" )[ 1 ]) < int ( variant [ 1 ]) ][ - 1 ] + 1 updated_vcf_records . insert ( variant_entry_position , \" \\t \" . join ( variant )) return updated_vcf_records","title":"construct_vcf_records()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfWriter","text":"Source code in src/pheval/prepare/create_spiked_vcf.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 class VcfWriter : def __init__ ( self , vcf_contents : list [ str ], spiked_vcf_file_path : Path , ): self . vcf_contents = vcf_contents self . spiked_vcf_file_path = spiked_vcf_file_path def write_gzip ( self ) -> None : \"\"\"Writes gzipped vcf file.\"\"\" encoded_contents = [ line . encode () for line in self . vcf_contents ] with gzip . open ( self . spiked_vcf_file_path , \"wb\" ) as f : for line in encoded_contents : f . write ( line ) f . close () def write_uncompressed ( self ) -> None : \"\"\"Writes an uncompressed vcf file.\"\"\" with open ( self . spiked_vcf_file_path , \"w\" ) as file : file . writelines ( self . vcf_contents ) file . close () def write_vcf_file ( self ) -> None : \"\"\"Writes spiked vcf file.\"\"\" self . write_gzip () if is_gzipped ( self . spiked_vcf_file_path ) else self . write_uncompressed ()","title":"VcfWriter"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfWriter.write_gzip","text":"Writes gzipped vcf file. Source code in src/pheval/prepare/create_spiked_vcf.py 241 242 243 244 245 246 247 def write_gzip ( self ) -> None : \"\"\"Writes gzipped vcf file.\"\"\" encoded_contents = [ line . encode () for line in self . vcf_contents ] with gzip . open ( self . spiked_vcf_file_path , \"wb\" ) as f : for line in encoded_contents : f . write ( line ) f . close ()","title":"write_gzip()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfWriter.write_uncompressed","text":"Writes an uncompressed vcf file. Source code in src/pheval/prepare/create_spiked_vcf.py 249 250 251 252 253 def write_uncompressed ( self ) -> None : \"\"\"Writes an uncompressed vcf file.\"\"\" with open ( self . spiked_vcf_file_path , \"w\" ) as file : file . writelines ( self . vcf_contents ) file . close ()","title":"write_uncompressed()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfWriter.write_vcf_file","text":"Writes spiked vcf file. Source code in src/pheval/prepare/create_spiked_vcf.py 255 256 257 def write_vcf_file ( self ) -> None : \"\"\"Writes spiked vcf file.\"\"\" self . write_gzip () if is_gzipped ( self . spiked_vcf_file_path ) else self . write_uncompressed ()","title":"write_vcf_file()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.check_variant_assembly","text":"Checks the assembly of the variant assembly against the VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 def check_variant_assembly ( proband_causative_variants : list [ ProbandCausativeVariant ], vcf_header : VcfHeader , phenopacket_path : Path , ): \"\"\"Checks the assembly of the variant assembly against the VCF.\"\"\" compatible_genome_assembly = { \"GRCh37\" , \"hg19\" , \"GRCh38\" , \"hg38\" } phenopacket_assembly = list ({ variant . assembly for variant in proband_causative_variants }) if len ( phenopacket_assembly ) > 1 : raise ValueError ( \"Too many genome assemblies!\" ) if phenopacket_assembly [ 0 ] not in compatible_genome_assembly : raise IncompatibleGenomeAssemblyError ( phenopacket_assembly , phenopacket_path ) if phenopacket_assembly [ 0 ] != vcf_header . assembly : raise IncompatibleGenomeAssemblyError ( assembly = phenopacket_assembly , phenopacket = phenopacket_path )","title":"check_variant_assembly()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.create_spiked_vcf","text":"Creates a spiked vcf for a phenopacket. Source code in src/pheval/prepare/create_spiked_vcf.py 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 def create_spiked_vcf ( output_dir : Path , phenopacket_path : Path , template_vcf_path : Path , vcf_dir : Path ): \"\"\"Creates a spiked vcf for a phenopacket.\"\"\" if template_vcf_path is None and vcf_dir is None : raise InputError ( \"Either a template_vcf or vcf_dir must be specified\" ) vcf_file_path = VcfPicker ( template_vcf_path , vcf_dir ) . pick_file () phenopacket = phenopacket_reader ( phenopacket_path ) spiked_vcf_file_message = generate_spiked_vcf_file ( output_dir , phenopacket , phenopacket_path , vcf_file_path ) updated_phenopacket = PhenopacketRebuilder ( phenopacket ) . add_spiked_vcf_path ( spiked_vcf_file_message ) write_phenopacket ( updated_phenopacket , phenopacket_path )","title":"create_spiked_vcf()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.create_spiked_vcfs","text":"Creates spiked vcfs for phenopackets. Source code in src/pheval/prepare/create_spiked_vcf.py 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 def create_spiked_vcfs ( output_dir : Path , phenopacket_dir : Path , template_vcf_path : Path , vcf_dir : Path ): \"\"\"Creates spiked vcfs for phenopackets.\"\"\" if template_vcf_path is None and vcf_dir is None : raise InputError ( \"Either a template_vcf or vcf_dir must be specified\" ) for phenopacket_path in files_with_suffix ( phenopacket_dir , \".json\" ): vcf_file_path = VcfPicker ( template_vcf_path , vcf_dir ) . pick_file () phenopacket = phenopacket_reader ( phenopacket_path ) spiked_vcf_file_message = generate_spiked_vcf_file ( output_dir , phenopacket , phenopacket_path , vcf_file_path ) updated_phenopacket = PhenopacketRebuilder ( phenopacket ) . add_spiked_vcf_path ( spiked_vcf_file_message ) write_phenopacket ( updated_phenopacket , phenopacket_path )","title":"create_spiked_vcfs()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.generate_spiked_vcf_file","text":"Writes spiked vcf contents to a new file. Source code in src/pheval/prepare/create_spiked_vcf.py 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 def generate_spiked_vcf_file ( output_dir : Path , phenopacket : Phenopacket or Family , phenopacket_path : Path , chosen_template_vcf : Path , ) -> File : \"\"\"Writes spiked vcf contents to a new file.\"\"\" try : output_dir . mkdir () info_log . info ( f \" Created a directory { output_dir } \" ) except FileExistsError : pass vcf_assembly , spiked_vcf = spike_vcf_contents ( phenopacket , phenopacket_path , chosen_template_vcf ) spiked_vcf_path = ( output_dir . joinpath ( phenopacket_path . name . replace ( \".json\" , \".vcf.gz\" )) if is_gzipped ( chosen_template_vcf ) else output_dir . joinpath ( phenopacket_path . name . replace ( \".json\" , \".vcf\" )) ) VcfWriter ( spiked_vcf , spiked_vcf_path ) . write_vcf_file () return File ( uri = str ( spiked_vcf_path . absolute ()), file_attributes = { \"fileFormat\" : \"VCF\" , \"genomeAssembly\" : vcf_assembly }, )","title":"generate_spiked_vcf_file()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.read_vcf","text":"Reads the contents of a VCF file into memory - handles both uncompressed and gzipped. Source code in src/pheval/prepare/create_spiked_vcf.py 102 103 104 105 106 107 108 109 110 def read_vcf ( vcf_file : Path ) -> list [ str ]: \"\"\"Reads the contents of a VCF file into memory - handles both uncompressed and gzipped.\"\"\" open_fn = gzip . open if is_gzipped ( vcf_file ) else open vcf = open_fn ( vcf_file ) vcf_contents = ( [ line . decode () for line in vcf . readlines ()] if is_gzipped ( vcf_file ) else vcf . readlines () ) vcf . close () return vcf_contents","title":"read_vcf()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.spike_vcf_contents","text":"Spikes VCF records with variants. Source code in src/pheval/prepare/create_spiked_vcf.py 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 def spike_vcf_contents ( phenopacket : Phenopacket or Family , phenopacket_path : Path , chosen_template_vcf : Path , ) -> tuple [ str , list [ str ]]: \"\"\"Spikes VCF records with variants.\"\"\" # this is a separate function to a click command as it will fail if annotated with click annotations # and referenced from another click command phenopacket_causative_variants = PhenopacketUtil ( phenopacket ) . causative_variants () vcf_contents = read_vcf ( chosen_template_vcf ) vcf_header = VcfHeaderParser ( vcf_contents ) . parse_vcf_header () check_variant_assembly ( phenopacket_causative_variants , vcf_header , phenopacket_path ) return ( vcf_header . assembly , VcfSpiker ( vcf_contents , phenopacket_causative_variants , vcf_header ) . construct_vcf (), )","title":"spike_vcf_contents()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.spike_vcfs","text":"Create spiked VCF from either a phenopacket or a phenopacket directory. Source code in src/pheval/prepare/create_spiked_vcf.py 343 344 345 346 347 348 349 350 351 352 353 354 def spike_vcfs ( output_dir : Path , phenopacket_path : Path , phenopacket_dir : Path , template_vcf_path : Path , vcf_dir : Path , ): \"\"\"Create spiked VCF from either a phenopacket or a phenopacket directory.\"\"\" if phenopacket_path is not None : create_spiked_vcf ( output_dir , phenopacket_path , template_vcf_path , vcf_dir ) elif phenopacket_dir is not None : create_spiked_vcfs ( output_dir , phenopacket_dir , template_vcf_path , vcf_dir )","title":"spike_vcfs()"},{"location":"api/pheval/prepare/custom_exceptions/","text":"InputError Bases: Exception Exception raised for missing required inputs. Source code in src/pheval/prepare/custom_exceptions.py 4 5 6 7 8 9 10 11 12 13 class InputError ( Exception ): \"\"\"Exception raised for missing required inputs.\"\"\" def __init__ ( self , file , message = \"Missing required input\" ): self . file : str = file self . message : str = message super () . __init__ ( self . message ) def __str__ ( self ): return f \" { self . message } -> { self . file } \" MutuallyExclusiveOptionError Bases: Option Exception raised for when Source code in src/pheval/prepare/custom_exceptions.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class MutuallyExclusiveOptionError ( Option ): \"\"\"Exception raised for when\"\"\" def __init__ ( self , * args , ** kwargs ): self . mutually_exclusive = set ( kwargs . pop ( \"mutually_exclusive\" , [])) help_ = kwargs . get ( \"help\" , \"\" ) if self . mutually_exclusive : ex_str = \", \" . join ( self . mutually_exclusive ) kwargs [ \"help\" ] = help_ + ( \" NOTE: This argument is mutually exclusive with \" \" arguments: [\" + ex_str + \"].\" ) super ( MutuallyExclusiveOptionError , self ) . __init__ ( * args , ** kwargs ) def handle_parse_result ( self , ctx , opts , args ): if self . mutually_exclusive . intersection ( opts ) and self . name in opts : raise UsageError ( \"Illegal usage: ` {} ` is mutually exclusive with \" \"arguments ` {} `.\" . format ( self . name , \", \" . join ( self . mutually_exclusive )) ) return super ( MutuallyExclusiveOptionError , self ) . handle_parse_result ( ctx , opts , args )","title":"Custom exceptions"},{"location":"api/pheval/prepare/custom_exceptions/#src.pheval.prepare.custom_exceptions.InputError","text":"Bases: Exception Exception raised for missing required inputs. Source code in src/pheval/prepare/custom_exceptions.py 4 5 6 7 8 9 10 11 12 13 class InputError ( Exception ): \"\"\"Exception raised for missing required inputs.\"\"\" def __init__ ( self , file , message = \"Missing required input\" ): self . file : str = file self . message : str = message super () . __init__ ( self . message ) def __str__ ( self ): return f \" { self . message } -> { self . file } \"","title":"InputError"},{"location":"api/pheval/prepare/custom_exceptions/#src.pheval.prepare.custom_exceptions.MutuallyExclusiveOptionError","text":"Bases: Option Exception raised for when Source code in src/pheval/prepare/custom_exceptions.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class MutuallyExclusiveOptionError ( Option ): \"\"\"Exception raised for when\"\"\" def __init__ ( self , * args , ** kwargs ): self . mutually_exclusive = set ( kwargs . pop ( \"mutually_exclusive\" , [])) help_ = kwargs . get ( \"help\" , \"\" ) if self . mutually_exclusive : ex_str = \", \" . join ( self . mutually_exclusive ) kwargs [ \"help\" ] = help_ + ( \" NOTE: This argument is mutually exclusive with \" \" arguments: [\" + ex_str + \"].\" ) super ( MutuallyExclusiveOptionError , self ) . __init__ ( * args , ** kwargs ) def handle_parse_result ( self , ctx , opts , args ): if self . mutually_exclusive . intersection ( opts ) and self . name in opts : raise UsageError ( \"Illegal usage: ` {} ` is mutually exclusive with \" \"arguments ` {} `.\" . format ( self . name , \", \" . join ( self . mutually_exclusive )) ) return super ( MutuallyExclusiveOptionError , self ) . handle_parse_result ( ctx , opts , args )","title":"MutuallyExclusiveOptionError"},{"location":"api/pheval/prepare/update_phenopacket/","text":"create_updated_phenopacket ( gene_identifier , phenopacket_path , output_dir ) Updates the gene context within the interpretations for a phenopacket. Source code in src/pheval/prepare/update_phenopacket.py 28 29 30 31 32 def create_updated_phenopacket ( gene_identifier : str , phenopacket_path : Path , output_dir : Path ): \"\"\"Updates the gene context within the interpretations for a phenopacket.\"\"\" hgnc_data = create_hgnc_dict () updated_phenopacket = update_outdated_gene_context ( phenopacket_path , gene_identifier , hgnc_data ) write_phenopacket ( updated_phenopacket , output_dir . joinpath ( phenopacket_path . name )) create_updated_phenopackets ( gene_identifier , phenopacket_dir , output_dir ) Updates the gene context within the interpretations for phenopackets. Source code in src/pheval/prepare/update_phenopacket.py 35 36 37 38 39 40 41 42 def create_updated_phenopackets ( gene_identifier : str , phenopacket_dir : Path , output_dir : Path ): \"\"\"Updates the gene context within the interpretations for phenopackets.\"\"\" hgnc_data = create_hgnc_dict () for phenopacket_path in all_files ( phenopacket_dir ): updated_phenopacket = update_outdated_gene_context ( phenopacket_path , gene_identifier , hgnc_data ) write_phenopacket ( updated_phenopacket , output_dir . joinpath ( phenopacket_path . name )) update_outdated_gene_context ( phenopacket_path , gene_identifier , hgnc_data ) Updates the gene context of the phenopacket. Source code in src/pheval/prepare/update_phenopacket.py 15 16 17 18 19 20 21 22 23 24 25 def update_outdated_gene_context ( phenopacket_path : Path , gene_identifier : str , hgnc_data : defaultdict ): \"\"\"Updates the gene context of the phenopacket.\"\"\" phenopacket = phenopacket_reader ( phenopacket_path ) interpretations = PhenopacketUtil ( phenopacket ) . interpretations () updated_interpretations = GeneIdentifierUpdater ( hgnc_data , gene_identifier ) . update_genomic_interpretations_gene_identifier ( interpretations ) return PhenopacketRebuilder ( phenopacket ) . update_interpretations ( updated_interpretations ) update_phenopackets ( gene_identifier , phenopacket_path , phenopacket_dir , output_dir ) Update the gene identifiers in either a single phenopacket or a directory of phenopackets. Source code in src/pheval/prepare/update_phenopacket.py 45 46 47 48 49 50 51 52 53 def update_phenopackets ( gene_identifier : str , phenopacket_path : Path , phenopacket_dir : Path , output_dir : Path ): \"\"\"Update the gene identifiers in either a single phenopacket or a directory of phenopackets.\"\"\" output_dir . mkdir ( exist_ok = True ) if phenopacket_path is not None : create_updated_phenopacket ( gene_identifier , phenopacket_path , output_dir ) elif phenopacket_dir is not None : create_updated_phenopackets ( gene_identifier , phenopacket_dir , output_dir )","title":"Update phenopacket"},{"location":"api/pheval/prepare/update_phenopacket/#src.pheval.prepare.update_phenopacket.create_updated_phenopacket","text":"Updates the gene context within the interpretations for a phenopacket. Source code in src/pheval/prepare/update_phenopacket.py 28 29 30 31 32 def create_updated_phenopacket ( gene_identifier : str , phenopacket_path : Path , output_dir : Path ): \"\"\"Updates the gene context within the interpretations for a phenopacket.\"\"\" hgnc_data = create_hgnc_dict () updated_phenopacket = update_outdated_gene_context ( phenopacket_path , gene_identifier , hgnc_data ) write_phenopacket ( updated_phenopacket , output_dir . joinpath ( phenopacket_path . name ))","title":"create_updated_phenopacket()"},{"location":"api/pheval/prepare/update_phenopacket/#src.pheval.prepare.update_phenopacket.create_updated_phenopackets","text":"Updates the gene context within the interpretations for phenopackets. Source code in src/pheval/prepare/update_phenopacket.py 35 36 37 38 39 40 41 42 def create_updated_phenopackets ( gene_identifier : str , phenopacket_dir : Path , output_dir : Path ): \"\"\"Updates the gene context within the interpretations for phenopackets.\"\"\" hgnc_data = create_hgnc_dict () for phenopacket_path in all_files ( phenopacket_dir ): updated_phenopacket = update_outdated_gene_context ( phenopacket_path , gene_identifier , hgnc_data ) write_phenopacket ( updated_phenopacket , output_dir . joinpath ( phenopacket_path . name ))","title":"create_updated_phenopackets()"},{"location":"api/pheval/prepare/update_phenopacket/#src.pheval.prepare.update_phenopacket.update_outdated_gene_context","text":"Updates the gene context of the phenopacket. Source code in src/pheval/prepare/update_phenopacket.py 15 16 17 18 19 20 21 22 23 24 25 def update_outdated_gene_context ( phenopacket_path : Path , gene_identifier : str , hgnc_data : defaultdict ): \"\"\"Updates the gene context of the phenopacket.\"\"\" phenopacket = phenopacket_reader ( phenopacket_path ) interpretations = PhenopacketUtil ( phenopacket ) . interpretations () updated_interpretations = GeneIdentifierUpdater ( hgnc_data , gene_identifier ) . update_genomic_interpretations_gene_identifier ( interpretations ) return PhenopacketRebuilder ( phenopacket ) . update_interpretations ( updated_interpretations )","title":"update_outdated_gene_context()"},{"location":"api/pheval/prepare/update_phenopacket/#src.pheval.prepare.update_phenopacket.update_phenopackets","text":"Update the gene identifiers in either a single phenopacket or a directory of phenopackets. Source code in src/pheval/prepare/update_phenopacket.py 45 46 47 48 49 50 51 52 53 def update_phenopackets ( gene_identifier : str , phenopacket_path : Path , phenopacket_dir : Path , output_dir : Path ): \"\"\"Update the gene identifiers in either a single phenopacket or a directory of phenopackets.\"\"\" output_dir . mkdir ( exist_ok = True ) if phenopacket_path is not None : create_updated_phenopacket ( gene_identifier , phenopacket_path , output_dir ) elif phenopacket_dir is not None : create_updated_phenopackets ( gene_identifier , phenopacket_dir , output_dir )","title":"update_phenopackets()"},{"location":"api/pheval/runners/runner/","text":"Runners Module DefaultPhEvalRunner Bases: PhEvalRunner DefaultPhEvalRunner Parameters: Name Type Description Default PhEvalRunner PhEvalRunner Abstract PhEvalRunnerClass required Source code in src/pheval/runners/runner.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 class DefaultPhEvalRunner ( PhEvalRunner ): \"\"\"DefaultPhEvalRunner Args: PhEvalRunner (PhEvalRunner): Abstract PhEvalRunnerClass \"\"\" input_dir : Path testdata_dir : Path tmp_dir : Path output_dir : Path config_file : Path version : str def prepare ( self ): print ( \"preparing\" ) def run ( self ): print ( \"running\" ) def post_process ( self ): print ( \"post processing\" ) PhEvalRunner dataclass Bases: ABC PhEvalRunner Class Source code in src/pheval/runners/runner.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @dataclass class PhEvalRunner ( ABC ): \"\"\"PhEvalRunner Class\"\"\" input_dir : Path testdata_dir : Path tmp_dir : Path output_dir : Path config_file : Path version : str @abstractmethod def prepare ( self ) -> str : \"\"\"prepare\"\"\" @abstractmethod def run ( self ): \"\"\"run\"\"\" @abstractmethod def post_process ( self ): \"\"\"post_process\"\"\" post_process () abstractmethod post_process Source code in src/pheval/runners/runner.py 26 27 28 @abstractmethod def post_process ( self ): \"\"\"post_process\"\"\" prepare () abstractmethod prepare Source code in src/pheval/runners/runner.py 18 19 20 @abstractmethod def prepare ( self ) -> str : \"\"\"prepare\"\"\" run () abstractmethod run Source code in src/pheval/runners/runner.py 22 23 24 @abstractmethod def run ( self ): \"\"\"run\"\"\"","title":"Runner"},{"location":"api/pheval/runners/runner/#src.pheval.runners.runner.DefaultPhEvalRunner","text":"Bases: PhEvalRunner DefaultPhEvalRunner Parameters: Name Type Description Default PhEvalRunner PhEvalRunner Abstract PhEvalRunnerClass required Source code in src/pheval/runners/runner.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 class DefaultPhEvalRunner ( PhEvalRunner ): \"\"\"DefaultPhEvalRunner Args: PhEvalRunner (PhEvalRunner): Abstract PhEvalRunnerClass \"\"\" input_dir : Path testdata_dir : Path tmp_dir : Path output_dir : Path config_file : Path version : str def prepare ( self ): print ( \"preparing\" ) def run ( self ): print ( \"running\" ) def post_process ( self ): print ( \"post processing\" )","title":"DefaultPhEvalRunner"},{"location":"api/pheval/runners/runner/#src.pheval.runners.runner.PhEvalRunner","text":"Bases: ABC PhEvalRunner Class Source code in src/pheval/runners/runner.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @dataclass class PhEvalRunner ( ABC ): \"\"\"PhEvalRunner Class\"\"\" input_dir : Path testdata_dir : Path tmp_dir : Path output_dir : Path config_file : Path version : str @abstractmethod def prepare ( self ) -> str : \"\"\"prepare\"\"\" @abstractmethod def run ( self ): \"\"\"run\"\"\" @abstractmethod def post_process ( self ): \"\"\"post_process\"\"\"","title":"PhEvalRunner"},{"location":"api/pheval/runners/runner/#src.pheval.runners.runner.PhEvalRunner.post_process","text":"post_process Source code in src/pheval/runners/runner.py 26 27 28 @abstractmethod def post_process ( self ): \"\"\"post_process\"\"\"","title":"post_process()"},{"location":"api/pheval/runners/runner/#src.pheval.runners.runner.PhEvalRunner.prepare","text":"prepare Source code in src/pheval/runners/runner.py 18 19 20 @abstractmethod def prepare ( self ) -> str : \"\"\"prepare\"\"\"","title":"prepare()"},{"location":"api/pheval/runners/runner/#src.pheval.runners.runner.PhEvalRunner.run","text":"run Source code in src/pheval/runners/runner.py 22 23 24 @abstractmethod def run ( self ): \"\"\"run\"\"\"","title":"run()"},{"location":"api/pheval/utils/file_utils/","text":"all_files ( directory ) Obtains all files from a given directory. Source code in src/pheval/utils/file_utils.py 17 18 19 20 21 def all_files ( directory : Path ) -> list [ Path ]: \"\"\"Obtains all files from a given directory.\"\"\" files = [ path for path in directory . iterdir ()] files . sort () return files ensure_columns_exists ( cols , dataframes , err_message = '' ) Ensures the columns exist in dataframes passed as argument (e.g) \" ensure_columns_exists( cols=['column_a', 'column_b, 'column_c'], err_message=\"Custom error message if any column doesn't exist in any dataframe passed as argument\", dataframes=[data_frame1, data_frame2], ) \" Source code in src/pheval/utils/file_utils.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 def ensure_columns_exists ( cols : list , dataframes : List [ pd . DataFrame ], err_message : str = \"\" ): \"\"\"Ensures the columns exist in dataframes passed as argument (e.g) \" ensure_columns_exists( cols=['column_a', 'column_b, 'column_c'], err_message=\"Custom error message if any column doesn't exist in any dataframe passed as argument\", dataframes=[data_frame1, data_frame2], ) \" \"\"\" flat_cols = list ( itertools . chain ( cols )) if not dataframes or not flat_cols : return if err_message : err_msg = f \"\"\"columns: { \", \" . join ( flat_cols [: - 1 ]) } and { flat_cols [ - 1 ] } { err_message } \"\"\" else : err_msg = f \"\"\"columns: { \", \" . join ( flat_cols [: - 1 ]) } and { flat_cols [ - 1 ] } \\ - must be present in both left and right files\"\"\" for dataframe in dataframes : if not all ( x in dataframe . columns for x in flat_cols ): raise ValueError ( err_msg ) ensure_file_exists ( * files ) Ensures the existence of files passed as parameter Raises: Type Description FileNotFoundError If any file passed as a parameter doesn't exist a FileNotFound Exception will be raised Source code in src/pheval/utils/file_utils.py 44 45 46 47 48 49 50 51 def ensure_file_exists ( * files : str ): \"\"\"Ensures the existence of files passed as parameter Raises: FileNotFoundError: If any file passed as a parameter doesn't exist a FileNotFound Exception will be raised \"\"\" for file in files : if not path . isfile ( file ): raise FileNotFoundError ( f \"File { file } not found\" ) files_with_suffix ( directory , suffix ) Obtains all files ending in a specified suffix from a given directory. Source code in src/pheval/utils/file_utils.py 10 11 12 13 14 def files_with_suffix ( directory : Path , suffix : str ): \"\"\"Obtains all files ending in a specified suffix from a given directory.\"\"\" files = [ path for path in directory . iterdir () if path . suffix == suffix ] files . sort () return files is_gzipped ( path ) Confirms whether a file is gzipped. Source code in src/pheval/utils/file_utils.py 24 25 26 def is_gzipped ( path : Path ) -> bool : \"\"\"Confirms whether a file is gzipped.\"\"\" return path . name . endswith ( \".gz\" ) obtain_closest_file_name ( file_to_be_queried , file_paths ) Obtains the closest file name when given a template file name and a list of full path of files to be queried. Source code in src/pheval/utils/file_utils.py 29 30 31 32 33 34 35 36 37 38 39 40 41 def obtain_closest_file_name ( file_to_be_queried : Path , file_paths : list [ Path ]) -> Path : \"\"\"Obtains the closest file name when given a template file name and a list of full path of files to be queried.\"\"\" closest_file_match = Path ( str ( difflib . get_close_matches ( str ( file_to_be_queried . name ), [ str ( file_path . name ) for file_path in file_paths ], )[ 0 ] ) ) return [ file_path for file_path in file_paths if Path ( closest_file_match ) == Path ( file_path . name ) ][ 0 ]","title":"File utils"},{"location":"api/pheval/utils/file_utils/#src.pheval.utils.file_utils.all_files","text":"Obtains all files from a given directory. Source code in src/pheval/utils/file_utils.py 17 18 19 20 21 def all_files ( directory : Path ) -> list [ Path ]: \"\"\"Obtains all files from a given directory.\"\"\" files = [ path for path in directory . iterdir ()] files . sort () return files","title":"all_files()"},{"location":"api/pheval/utils/file_utils/#src.pheval.utils.file_utils.ensure_columns_exists","text":"Ensures the columns exist in dataframes passed as argument (e.g) \" ensure_columns_exists( cols=['column_a', 'column_b, 'column_c'], err_message=\"Custom error message if any column doesn't exist in any dataframe passed as argument\", dataframes=[data_frame1, data_frame2], ) \" Source code in src/pheval/utils/file_utils.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 def ensure_columns_exists ( cols : list , dataframes : List [ pd . DataFrame ], err_message : str = \"\" ): \"\"\"Ensures the columns exist in dataframes passed as argument (e.g) \" ensure_columns_exists( cols=['column_a', 'column_b, 'column_c'], err_message=\"Custom error message if any column doesn't exist in any dataframe passed as argument\", dataframes=[data_frame1, data_frame2], ) \" \"\"\" flat_cols = list ( itertools . chain ( cols )) if not dataframes or not flat_cols : return if err_message : err_msg = f \"\"\"columns: { \", \" . join ( flat_cols [: - 1 ]) } and { flat_cols [ - 1 ] } { err_message } \"\"\" else : err_msg = f \"\"\"columns: { \", \" . join ( flat_cols [: - 1 ]) } and { flat_cols [ - 1 ] } \\ - must be present in both left and right files\"\"\" for dataframe in dataframes : if not all ( x in dataframe . columns for x in flat_cols ): raise ValueError ( err_msg )","title":"ensure_columns_exists()"},{"location":"api/pheval/utils/file_utils/#src.pheval.utils.file_utils.ensure_file_exists","text":"Ensures the existence of files passed as parameter Raises: Type Description FileNotFoundError If any file passed as a parameter doesn't exist a FileNotFound Exception will be raised Source code in src/pheval/utils/file_utils.py 44 45 46 47 48 49 50 51 def ensure_file_exists ( * files : str ): \"\"\"Ensures the existence of files passed as parameter Raises: FileNotFoundError: If any file passed as a parameter doesn't exist a FileNotFound Exception will be raised \"\"\" for file in files : if not path . isfile ( file ): raise FileNotFoundError ( f \"File { file } not found\" )","title":"ensure_file_exists()"},{"location":"api/pheval/utils/file_utils/#src.pheval.utils.file_utils.files_with_suffix","text":"Obtains all files ending in a specified suffix from a given directory. Source code in src/pheval/utils/file_utils.py 10 11 12 13 14 def files_with_suffix ( directory : Path , suffix : str ): \"\"\"Obtains all files ending in a specified suffix from a given directory.\"\"\" files = [ path for path in directory . iterdir () if path . suffix == suffix ] files . sort () return files","title":"files_with_suffix()"},{"location":"api/pheval/utils/file_utils/#src.pheval.utils.file_utils.is_gzipped","text":"Confirms whether a file is gzipped. Source code in src/pheval/utils/file_utils.py 24 25 26 def is_gzipped ( path : Path ) -> bool : \"\"\"Confirms whether a file is gzipped.\"\"\" return path . name . endswith ( \".gz\" )","title":"is_gzipped()"},{"location":"api/pheval/utils/file_utils/#src.pheval.utils.file_utils.obtain_closest_file_name","text":"Obtains the closest file name when given a template file name and a list of full path of files to be queried. Source code in src/pheval/utils/file_utils.py 29 30 31 32 33 34 35 36 37 38 39 40 41 def obtain_closest_file_name ( file_to_be_queried : Path , file_paths : list [ Path ]) -> Path : \"\"\"Obtains the closest file name when given a template file name and a list of full path of files to be queried.\"\"\" closest_file_match = Path ( str ( difflib . get_close_matches ( str ( file_to_be_queried . name ), [ str ( file_path . name ) for file_path in file_paths ], )[ 0 ] ) ) return [ file_path for file_path in file_paths if Path ( closest_file_match ) == Path ( file_path . name ) ][ 0 ]","title":"obtain_closest_file_name()"},{"location":"api/pheval/utils/phenopacket_utils/","text":"GeneIdentifierUpdater Source code in src/pheval/utils/phenopacket_utils.py 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 class GeneIdentifierUpdater : def __init__ ( self , hgnc_data : defaultdict , gene_identifier : str , ): self . hgnc_data = hgnc_data self . gene_identifier = gene_identifier def find_identifier ( self , gene_symbol : str ) -> str : \"\"\"Finds the specified gene identifier for a gene symbol.\"\"\" if gene_symbol in self . hgnc_data . keys (): return self . hgnc_data [ gene_symbol ][ self . gene_identifier ] else : for _symbol , data in self . hgnc_data . items (): for prev_symbol in data [ \"previous_symbol\" ]: if prev_symbol == gene_symbol : return data [ self . gene_identifier ] def find_alternate_ids ( self , gene_symbol : str ) -> list [ str ]: \"\"\"Finds the alternate IDs for a gene symbol.\"\"\" if gene_symbol in self . hgnc_data . keys (): return [ self . hgnc_data [ gene_symbol ][ \"hgnc_id\" ], \"ncbigene:\" + self . hgnc_data [ gene_symbol ][ \"entrez_id\" ], \"ensembl:\" + self . hgnc_data [ gene_symbol ][ \"ensembl_id\" ], \"symbol:\" + gene_symbol , ] else : for symbol , data in self . hgnc_data . items (): for prev_symbol in data [ \"previous_symbol\" ]: if prev_symbol == gene_symbol : return [ data [ \"hgnc_id\" ], \"ncbigene:\" + data [ \"entrez_id\" ], \"ensembl:\" + data [ \"ensembl_id\" ], \"symbol:\" + symbol , ] def update_genomic_interpretations_gene_identifier ( self , interpretations : list [ Interpretation ] ) -> list [ Interpretation ]: \"\"\"Updates the genomic interpretations of a phenopacket.\"\"\" updated_interpretations = copy ( list ( interpretations )) for updated_interpretation in updated_interpretations : for g in updated_interpretation . diagnosis . genomic_interpretations : g . variant_interpretation . variation_descriptor . gene_context . value_id = ( self . find_identifier ( g . variant_interpretation . variation_descriptor . gene_context . symbol ) ) del g . variant_interpretation . variation_descriptor . gene_context . alternate_ids [:] g . variant_interpretation . variation_descriptor . gene_context . alternate_ids . extend ( self . find_alternate_ids ( g . variant_interpretation . variation_descriptor . gene_context . symbol ) ) return updated_interpretations find_alternate_ids ( gene_symbol ) Finds the alternate IDs for a gene symbol. Source code in src/pheval/utils/phenopacket_utils.py 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 def find_alternate_ids ( self , gene_symbol : str ) -> list [ str ]: \"\"\"Finds the alternate IDs for a gene symbol.\"\"\" if gene_symbol in self . hgnc_data . keys (): return [ self . hgnc_data [ gene_symbol ][ \"hgnc_id\" ], \"ncbigene:\" + self . hgnc_data [ gene_symbol ][ \"entrez_id\" ], \"ensembl:\" + self . hgnc_data [ gene_symbol ][ \"ensembl_id\" ], \"symbol:\" + gene_symbol , ] else : for symbol , data in self . hgnc_data . items (): for prev_symbol in data [ \"previous_symbol\" ]: if prev_symbol == gene_symbol : return [ data [ \"hgnc_id\" ], \"ncbigene:\" + data [ \"entrez_id\" ], \"ensembl:\" + data [ \"ensembl_id\" ], \"symbol:\" + symbol , ] find_identifier ( gene_symbol ) Finds the specified gene identifier for a gene symbol. Source code in src/pheval/utils/phenopacket_utils.py 269 270 271 272 273 274 275 276 277 def find_identifier ( self , gene_symbol : str ) -> str : \"\"\"Finds the specified gene identifier for a gene symbol.\"\"\" if gene_symbol in self . hgnc_data . keys (): return self . hgnc_data [ gene_symbol ][ self . gene_identifier ] else : for _symbol , data in self . hgnc_data . items (): for prev_symbol in data [ \"previous_symbol\" ]: if prev_symbol == gene_symbol : return data [ self . gene_identifier ] update_genomic_interpretations_gene_identifier ( interpretations ) Updates the genomic interpretations of a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 def update_genomic_interpretations_gene_identifier ( self , interpretations : list [ Interpretation ] ) -> list [ Interpretation ]: \"\"\"Updates the genomic interpretations of a phenopacket.\"\"\" updated_interpretations = copy ( list ( interpretations )) for updated_interpretation in updated_interpretations : for g in updated_interpretation . diagnosis . genomic_interpretations : g . variant_interpretation . variation_descriptor . gene_context . value_id = ( self . find_identifier ( g . variant_interpretation . variation_descriptor . gene_context . symbol ) ) del g . variant_interpretation . variation_descriptor . gene_context . alternate_ids [:] g . variant_interpretation . variation_descriptor . gene_context . alternate_ids . extend ( self . find_alternate_ids ( g . variant_interpretation . variation_descriptor . gene_context . symbol ) ) return updated_interpretations IncompatibleGenomeAssemblyError Bases: Exception Exception raised for incompatible genome assembly. Source code in src/pheval/utils/phenopacket_utils.py 17 18 19 20 21 22 23 24 25 26 27 class IncompatibleGenomeAssemblyError ( Exception ): \"\"\"Exception raised for incompatible genome assembly.\"\"\" def __init__ ( self , assembly , phenopacket , message = \"Incompatible Genome Assembly\" ): self . assembly : str = assembly self . phenopacket : Path = phenopacket self . message : str = message super () . __init__ ( self . message ) def __str__ ( self ): return f \" { self . message } -> { self . assembly } in { self . phenopacket } \" PhenopacketRebuilder Rebuilds a Phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 class PhenopacketRebuilder : \"\"\"Rebuilds a Phenopacket.\"\"\" def __init__ ( self , phenopacket : Phenopacket or Family ): self . phenopacket = phenopacket def update_interpretations ( self , interpretations ) -> Phenopacket or Family : \"\"\"Adds the updated interpretations to a phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) if hasattr ( phenopacket , \"proband\" ): del phenopacket . proband . interpretations [:] phenopacket . proband . interpretations . extend ( interpretations ) else : del phenopacket . interpretations [:] phenopacket . interpretations . extend ( interpretations ) return phenopacket def add_randomised_hpo ( self , randomised_hpo ) -> Phenopacket or Family : \"\"\"Adds randomised phenotypic profile to phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) if hasattr ( phenopacket , \"proband\" ): del phenopacket . proband . phenotypic_features [:] phenopacket . proband . phenotypic_features . extend ( randomised_hpo ) else : del phenopacket . phenotypic_features [:] phenopacket . phenotypic_features . extend ( randomised_hpo ) return phenopacket def add_spiked_vcf_path ( self , spiked_vcf_file_data : File ) -> Phenopacket or Family : \"\"\"Adds spiked vcf path to phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) phenopacket_files = [ file for file in phenopacket . files if file . file_attributes [ \"fileFormat\" ] != \"VCF\" ] phenopacket_files . append ( spiked_vcf_file_data ) del phenopacket . files [:] phenopacket . files . extend ( phenopacket_files ) return phenopacket add_randomised_hpo ( randomised_hpo ) Adds randomised phenotypic profile to phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 224 225 226 227 228 229 230 231 232 233 def add_randomised_hpo ( self , randomised_hpo ) -> Phenopacket or Family : \"\"\"Adds randomised phenotypic profile to phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) if hasattr ( phenopacket , \"proband\" ): del phenopacket . proband . phenotypic_features [:] phenopacket . proband . phenotypic_features . extend ( randomised_hpo ) else : del phenopacket . phenotypic_features [:] phenopacket . phenotypic_features . extend ( randomised_hpo ) return phenopacket add_spiked_vcf_path ( spiked_vcf_file_data ) Adds spiked vcf path to phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 235 236 237 238 239 240 241 242 243 244 def add_spiked_vcf_path ( self , spiked_vcf_file_data : File ) -> Phenopacket or Family : \"\"\"Adds spiked vcf path to phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) phenopacket_files = [ file for file in phenopacket . files if file . file_attributes [ \"fileFormat\" ] != \"VCF\" ] phenopacket_files . append ( spiked_vcf_file_data ) del phenopacket . files [:] phenopacket . files . extend ( phenopacket_files ) return phenopacket update_interpretations ( interpretations ) Adds the updated interpretations to a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 213 214 215 216 217 218 219 220 221 222 def update_interpretations ( self , interpretations ) -> Phenopacket or Family : \"\"\"Adds the updated interpretations to a phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) if hasattr ( phenopacket , \"proband\" ): del phenopacket . proband . interpretations [:] phenopacket . proband . interpretations . extend ( interpretations ) else : del phenopacket . interpretations [:] phenopacket . interpretations . extend ( interpretations ) return phenopacket PhenopacketUtil Retrieves relevant data from a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 class PhenopacketUtil : \"\"\"Retrieves relevant data from a phenopacket.\"\"\" def __init__ ( self , phenopacket_contents : Phenopacket ): self . phenopacket_contents = phenopacket_contents def sample_id ( self ) -> str : \"\"\"Retrieve the sample ID from a phenopacket or proband of a family.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . subject . id else : return self . phenopacket_contents . subject . id def phenotypic_features ( self ) -> list [ PhenotypicFeature ]: \"\"\"Retrieves a list of all HPO terms.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . phenotypic_features else : return self . phenopacket_contents . phenotypic_features def observed_phenotypic_features ( self ) -> list [ PhenotypicFeature ]: \"\"\"Removes any HPO terms labelled as excluded.\"\"\" phenotypic_features = [] all_phenotypic_features = self . phenotypic_features () for p in all_phenotypic_features : if p . excluded : continue phenotypic_features . append ( p ) return phenotypic_features def negated_phenotypic_features ( self ) -> [ PhenotypicFeature ]: \"\"\"Retrieve negated phenotypic features.\"\"\" negated_phenotypic_features = [] all_phenotypic_features = self . phenotypic_features () for p in all_phenotypic_features : if p . excluded : negated_phenotypic_features . append ( p ) return negated_phenotypic_features def interpretations ( self ) -> list [ Interpretation ]: \"\"\"Returns all interpretations of a phenopacket.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . interpretations else : return self . phenopacket_contents . interpretations def causative_variants ( self ) -> list [ ProbandCausativeVariant ]: \"\"\"Returns a list of all causative variants listed in a phenopacket.\"\"\" all_variants = [] interpretation = self . interpretations () for i in interpretation : for g in i . diagnosis . genomic_interpretations : vcf_record = g . variant_interpretation . variation_descriptor . vcf_record genotype = g . variant_interpretation . variation_descriptor . allelic_state variant_data = ProbandCausativeVariant ( self . phenopacket_contents . subject . id , vcf_record . genome_assembly , GenomicVariant ( vcf_record . chrom , vcf_record . pos , vcf_record . ref , vcf_record . alt , ), genotype . label , ) all_variants . append ( variant_data ) return all_variants def files ( self ) -> list : \"\"\"Returns all files associated with a phenopacket.\"\"\" return self . phenopacket_contents . files def vcf_file_data ( self , phenopacket_path : Path , vcf_dir : Path ) -> File : \"\"\"Retrieves the genome assembly and vcf name from a phenopacket.\"\"\" compatible_genome_assembly = [ \"GRCh37\" , \"hg19\" , \"GRCh38\" , \"hg38\" ] vcf_data = [ file for file in self . files () if file . file_attributes [ \"fileFormat\" ] == \"VCF\" ][ 0 ] if not Path ( vcf_data . uri ) . name . endswith ( \".vcf\" ) and not Path ( vcf_data . uri ) . name . endswith ( \".vcf.gz\" ): raise IncorrectFileFormatError ( Path ( vcf_data . uri ), \".vcf or .vcf.gz file\" ) if vcf_data . file_attributes [ \"genomeAssembly\" ] not in compatible_genome_assembly : raise IncompatibleGenomeAssemblyError ( vcf_data . file_attributes [ \"genomeAssembly\" ], phenopacket_path ) vcf_data . uri = str ( vcf_dir . joinpath ( Path ( vcf_data . uri ) . name )) return vcf_data def diagnosed_genes ( self ) -> list [ ProbandCausativeGene ]: \"\"\"Returns a unique list of all causative genes and the corresponding gene identifiers from a phenopacket.\"\"\" pheno_interpretation = self . interpretations () genes = [] for i in pheno_interpretation : for g in i . diagnosis . genomic_interpretations : genes . append ( ProbandCausativeGene ( g . variant_interpretation . variation_descriptor . gene_context . symbol , g . variant_interpretation . variation_descriptor . gene_context . value_id , ) ) genes = list ({ gene . gene_symbol : gene for gene in genes } . values ()) return genes def diagnosed_variants ( self ) -> list [ GenomicVariant ]: \"\"\"Returns a list of all variants from a phenopacket - for use in assess-prioritisation.\"\"\" variants = [] pheno_interpretation = self . interpretations () for i in pheno_interpretation : for g in i . diagnosis . genomic_interpretations : variant = GenomicVariant ( chrom = g . variant_interpretation . variation_descriptor . vcf_record . chrom , pos = g . variant_interpretation . variation_descriptor . vcf_record . pos , ref = g . variant_interpretation . variation_descriptor . vcf_record . ref , alt = g . variant_interpretation . variation_descriptor . vcf_record . alt , ) variants . append ( variant ) return variants causative_variants () Returns a list of all causative variants listed in a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 def causative_variants ( self ) -> list [ ProbandCausativeVariant ]: \"\"\"Returns a list of all causative variants listed in a phenopacket.\"\"\" all_variants = [] interpretation = self . interpretations () for i in interpretation : for g in i . diagnosis . genomic_interpretations : vcf_record = g . variant_interpretation . variation_descriptor . vcf_record genotype = g . variant_interpretation . variation_descriptor . allelic_state variant_data = ProbandCausativeVariant ( self . phenopacket_contents . subject . id , vcf_record . genome_assembly , GenomicVariant ( vcf_record . chrom , vcf_record . pos , vcf_record . ref , vcf_record . alt , ), genotype . label , ) all_variants . append ( variant_data ) return all_variants diagnosed_genes () Returns a unique list of all causative genes and the corresponding gene identifiers from a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 def diagnosed_genes ( self ) -> list [ ProbandCausativeGene ]: \"\"\"Returns a unique list of all causative genes and the corresponding gene identifiers from a phenopacket.\"\"\" pheno_interpretation = self . interpretations () genes = [] for i in pheno_interpretation : for g in i . diagnosis . genomic_interpretations : genes . append ( ProbandCausativeGene ( g . variant_interpretation . variation_descriptor . gene_context . symbol , g . variant_interpretation . variation_descriptor . gene_context . value_id , ) ) genes = list ({ gene . gene_symbol : gene for gene in genes } . values ()) return genes diagnosed_variants () Returns a list of all variants from a phenopacket - for use in assess-prioritisation. Source code in src/pheval/utils/phenopacket_utils.py 191 192 193 194 195 196 197 198 199 200 201 202 203 204 def diagnosed_variants ( self ) -> list [ GenomicVariant ]: \"\"\"Returns a list of all variants from a phenopacket - for use in assess-prioritisation.\"\"\" variants = [] pheno_interpretation = self . interpretations () for i in pheno_interpretation : for g in i . diagnosis . genomic_interpretations : variant = GenomicVariant ( chrom = g . variant_interpretation . variation_descriptor . vcf_record . chrom , pos = g . variant_interpretation . variation_descriptor . vcf_record . pos , ref = g . variant_interpretation . variation_descriptor . vcf_record . ref , alt = g . variant_interpretation . variation_descriptor . vcf_record . alt , ) variants . append ( variant ) return variants files () Returns all files associated with a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 157 158 159 def files ( self ) -> list : \"\"\"Returns all files associated with a phenopacket.\"\"\" return self . phenopacket_contents . files interpretations () Returns all interpretations of a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 128 129 130 131 132 133 def interpretations ( self ) -> list [ Interpretation ]: \"\"\"Returns all interpretations of a phenopacket.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . interpretations else : return self . phenopacket_contents . interpretations negated_phenotypic_features () Retrieve negated phenotypic features. Source code in src/pheval/utils/phenopacket_utils.py 119 120 121 122 123 124 125 126 def negated_phenotypic_features ( self ) -> [ PhenotypicFeature ]: \"\"\"Retrieve negated phenotypic features.\"\"\" negated_phenotypic_features = [] all_phenotypic_features = self . phenotypic_features () for p in all_phenotypic_features : if p . excluded : negated_phenotypic_features . append ( p ) return negated_phenotypic_features observed_phenotypic_features () Removes any HPO terms labelled as excluded. Source code in src/pheval/utils/phenopacket_utils.py 109 110 111 112 113 114 115 116 117 def observed_phenotypic_features ( self ) -> list [ PhenotypicFeature ]: \"\"\"Removes any HPO terms labelled as excluded.\"\"\" phenotypic_features = [] all_phenotypic_features = self . phenotypic_features () for p in all_phenotypic_features : if p . excluded : continue phenotypic_features . append ( p ) return phenotypic_features phenotypic_features () Retrieves a list of all HPO terms. Source code in src/pheval/utils/phenopacket_utils.py 102 103 104 105 106 107 def phenotypic_features ( self ) -> list [ PhenotypicFeature ]: \"\"\"Retrieves a list of all HPO terms.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . phenotypic_features else : return self . phenopacket_contents . phenotypic_features sample_id () Retrieve the sample ID from a phenopacket or proband of a family. Source code in src/pheval/utils/phenopacket_utils.py 95 96 97 98 99 100 def sample_id ( self ) -> str : \"\"\"Retrieve the sample ID from a phenopacket or proband of a family.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . subject . id else : return self . phenopacket_contents . subject . id vcf_file_data ( phenopacket_path , vcf_dir ) Retrieves the genome assembly and vcf name from a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 def vcf_file_data ( self , phenopacket_path : Path , vcf_dir : Path ) -> File : \"\"\"Retrieves the genome assembly and vcf name from a phenopacket.\"\"\" compatible_genome_assembly = [ \"GRCh37\" , \"hg19\" , \"GRCh38\" , \"hg38\" ] vcf_data = [ file for file in self . files () if file . file_attributes [ \"fileFormat\" ] == \"VCF\" ][ 0 ] if not Path ( vcf_data . uri ) . name . endswith ( \".vcf\" ) and not Path ( vcf_data . uri ) . name . endswith ( \".vcf.gz\" ): raise IncorrectFileFormatError ( Path ( vcf_data . uri ), \".vcf or .vcf.gz file\" ) if vcf_data . file_attributes [ \"genomeAssembly\" ] not in compatible_genome_assembly : raise IncompatibleGenomeAssemblyError ( vcf_data . file_attributes [ \"genomeAssembly\" ], phenopacket_path ) vcf_data . uri = str ( vcf_dir . joinpath ( Path ( vcf_data . uri ) . name )) return vcf_data create_hgnc_dict () Creates reference for updating gene symbols and identifiers. Source code in src/pheval/utils/phenopacket_utils.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def create_hgnc_dict () -> defaultdict : \"\"\"Creates reference for updating gene symbols and identifiers.\"\"\" hgnc_df = read_hgnc_data () hgnc_data = defaultdict ( dict ) for _index , row in hgnc_df . iterrows (): previous_names = [] hgnc_data [ row [ \"symbol\" ]][ \"ensembl_id\" ] = row [ \"ensembl_gene_id\" ] hgnc_data [ row [ \"symbol\" ]][ \"hgnc_id\" ] = row [ \"hgnc_id\" ] hgnc_data [ row [ \"symbol\" ]][ \"entrez_id\" ] = row [ \"entrez_id\" ] hgnc_data [ row [ \"symbol\" ]][ \"refseq_accession\" ] = row [ \"refseq_accession\" ] previous = str ( row [ \"prev_symbol\" ]) . split ( \"|\" ) for p in previous : previous_names . append ( p . strip ( '\"' )) hgnc_data [ row [ \"symbol\" ]][ \"previous_symbol\" ] = previous_names return hgnc_data create_json_message ( phenopacket ) Creates json message for writing to file. Source code in src/pheval/utils/phenopacket_utils.py 247 248 249 def create_json_message ( phenopacket : Phenopacket or Family ) -> str : \"\"\"Creates json message for writing to file.\"\"\" return MessageToJson ( phenopacket ) phenopacket_reader ( file ) Reads a phenopacket file, returning its contents. Source code in src/pheval/utils/phenopacket_utils.py 78 79 80 81 82 83 84 85 86 def phenopacket_reader ( file : Path ): \"\"\"Reads a phenopacket file, returning its contents.\"\"\" file = open ( file , \"r\" ) phenopacket = json . load ( file ) file . close () if \"proband\" in phenopacket : return Parse ( json . dumps ( phenopacket ), Family ()) else : return Parse ( json . dumps ( phenopacket ), Phenopacket ()) write_phenopacket ( phenopacket , output_file ) Writes a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 252 253 254 255 256 257 def write_phenopacket ( phenopacket : Phenopacket or Family , output_file : Path ) -> None : \"\"\"Writes a phenopacket.\"\"\" phenopacket_json = create_json_message ( phenopacket ) with open ( output_file , \"w\" ) as outfile : outfile . write ( phenopacket_json ) outfile . close ()","title":"Phenopacket utils"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.GeneIdentifierUpdater","text":"Source code in src/pheval/utils/phenopacket_utils.py 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 class GeneIdentifierUpdater : def __init__ ( self , hgnc_data : defaultdict , gene_identifier : str , ): self . hgnc_data = hgnc_data self . gene_identifier = gene_identifier def find_identifier ( self , gene_symbol : str ) -> str : \"\"\"Finds the specified gene identifier for a gene symbol.\"\"\" if gene_symbol in self . hgnc_data . keys (): return self . hgnc_data [ gene_symbol ][ self . gene_identifier ] else : for _symbol , data in self . hgnc_data . items (): for prev_symbol in data [ \"previous_symbol\" ]: if prev_symbol == gene_symbol : return data [ self . gene_identifier ] def find_alternate_ids ( self , gene_symbol : str ) -> list [ str ]: \"\"\"Finds the alternate IDs for a gene symbol.\"\"\" if gene_symbol in self . hgnc_data . keys (): return [ self . hgnc_data [ gene_symbol ][ \"hgnc_id\" ], \"ncbigene:\" + self . hgnc_data [ gene_symbol ][ \"entrez_id\" ], \"ensembl:\" + self . hgnc_data [ gene_symbol ][ \"ensembl_id\" ], \"symbol:\" + gene_symbol , ] else : for symbol , data in self . hgnc_data . items (): for prev_symbol in data [ \"previous_symbol\" ]: if prev_symbol == gene_symbol : return [ data [ \"hgnc_id\" ], \"ncbigene:\" + data [ \"entrez_id\" ], \"ensembl:\" + data [ \"ensembl_id\" ], \"symbol:\" + symbol , ] def update_genomic_interpretations_gene_identifier ( self , interpretations : list [ Interpretation ] ) -> list [ Interpretation ]: \"\"\"Updates the genomic interpretations of a phenopacket.\"\"\" updated_interpretations = copy ( list ( interpretations )) for updated_interpretation in updated_interpretations : for g in updated_interpretation . diagnosis . genomic_interpretations : g . variant_interpretation . variation_descriptor . gene_context . value_id = ( self . find_identifier ( g . variant_interpretation . variation_descriptor . gene_context . symbol ) ) del g . variant_interpretation . variation_descriptor . gene_context . alternate_ids [:] g . variant_interpretation . variation_descriptor . gene_context . alternate_ids . extend ( self . find_alternate_ids ( g . variant_interpretation . variation_descriptor . gene_context . symbol ) ) return updated_interpretations","title":"GeneIdentifierUpdater"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.GeneIdentifierUpdater.find_alternate_ids","text":"Finds the alternate IDs for a gene symbol. Source code in src/pheval/utils/phenopacket_utils.py 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 def find_alternate_ids ( self , gene_symbol : str ) -> list [ str ]: \"\"\"Finds the alternate IDs for a gene symbol.\"\"\" if gene_symbol in self . hgnc_data . keys (): return [ self . hgnc_data [ gene_symbol ][ \"hgnc_id\" ], \"ncbigene:\" + self . hgnc_data [ gene_symbol ][ \"entrez_id\" ], \"ensembl:\" + self . hgnc_data [ gene_symbol ][ \"ensembl_id\" ], \"symbol:\" + gene_symbol , ] else : for symbol , data in self . hgnc_data . items (): for prev_symbol in data [ \"previous_symbol\" ]: if prev_symbol == gene_symbol : return [ data [ \"hgnc_id\" ], \"ncbigene:\" + data [ \"entrez_id\" ], \"ensembl:\" + data [ \"ensembl_id\" ], \"symbol:\" + symbol , ]","title":"find_alternate_ids()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.GeneIdentifierUpdater.find_identifier","text":"Finds the specified gene identifier for a gene symbol. Source code in src/pheval/utils/phenopacket_utils.py 269 270 271 272 273 274 275 276 277 def find_identifier ( self , gene_symbol : str ) -> str : \"\"\"Finds the specified gene identifier for a gene symbol.\"\"\" if gene_symbol in self . hgnc_data . keys (): return self . hgnc_data [ gene_symbol ][ self . gene_identifier ] else : for _symbol , data in self . hgnc_data . items (): for prev_symbol in data [ \"previous_symbol\" ]: if prev_symbol == gene_symbol : return data [ self . gene_identifier ]","title":"find_identifier()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.GeneIdentifierUpdater.update_genomic_interpretations_gene_identifier","text":"Updates the genomic interpretations of a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 def update_genomic_interpretations_gene_identifier ( self , interpretations : list [ Interpretation ] ) -> list [ Interpretation ]: \"\"\"Updates the genomic interpretations of a phenopacket.\"\"\" updated_interpretations = copy ( list ( interpretations )) for updated_interpretation in updated_interpretations : for g in updated_interpretation . diagnosis . genomic_interpretations : g . variant_interpretation . variation_descriptor . gene_context . value_id = ( self . find_identifier ( g . variant_interpretation . variation_descriptor . gene_context . symbol ) ) del g . variant_interpretation . variation_descriptor . gene_context . alternate_ids [:] g . variant_interpretation . variation_descriptor . gene_context . alternate_ids . extend ( self . find_alternate_ids ( g . variant_interpretation . variation_descriptor . gene_context . symbol ) ) return updated_interpretations","title":"update_genomic_interpretations_gene_identifier()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.IncompatibleGenomeAssemblyError","text":"Bases: Exception Exception raised for incompatible genome assembly. Source code in src/pheval/utils/phenopacket_utils.py 17 18 19 20 21 22 23 24 25 26 27 class IncompatibleGenomeAssemblyError ( Exception ): \"\"\"Exception raised for incompatible genome assembly.\"\"\" def __init__ ( self , assembly , phenopacket , message = \"Incompatible Genome Assembly\" ): self . assembly : str = assembly self . phenopacket : Path = phenopacket self . message : str = message super () . __init__ ( self . message ) def __str__ ( self ): return f \" { self . message } -> { self . assembly } in { self . phenopacket } \"","title":"IncompatibleGenomeAssemblyError"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketRebuilder","text":"Rebuilds a Phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 class PhenopacketRebuilder : \"\"\"Rebuilds a Phenopacket.\"\"\" def __init__ ( self , phenopacket : Phenopacket or Family ): self . phenopacket = phenopacket def update_interpretations ( self , interpretations ) -> Phenopacket or Family : \"\"\"Adds the updated interpretations to a phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) if hasattr ( phenopacket , \"proband\" ): del phenopacket . proband . interpretations [:] phenopacket . proband . interpretations . extend ( interpretations ) else : del phenopacket . interpretations [:] phenopacket . interpretations . extend ( interpretations ) return phenopacket def add_randomised_hpo ( self , randomised_hpo ) -> Phenopacket or Family : \"\"\"Adds randomised phenotypic profile to phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) if hasattr ( phenopacket , \"proband\" ): del phenopacket . proband . phenotypic_features [:] phenopacket . proband . phenotypic_features . extend ( randomised_hpo ) else : del phenopacket . phenotypic_features [:] phenopacket . phenotypic_features . extend ( randomised_hpo ) return phenopacket def add_spiked_vcf_path ( self , spiked_vcf_file_data : File ) -> Phenopacket or Family : \"\"\"Adds spiked vcf path to phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) phenopacket_files = [ file for file in phenopacket . files if file . file_attributes [ \"fileFormat\" ] != \"VCF\" ] phenopacket_files . append ( spiked_vcf_file_data ) del phenopacket . files [:] phenopacket . files . extend ( phenopacket_files ) return phenopacket","title":"PhenopacketRebuilder"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketRebuilder.add_randomised_hpo","text":"Adds randomised phenotypic profile to phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 224 225 226 227 228 229 230 231 232 233 def add_randomised_hpo ( self , randomised_hpo ) -> Phenopacket or Family : \"\"\"Adds randomised phenotypic profile to phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) if hasattr ( phenopacket , \"proband\" ): del phenopacket . proband . phenotypic_features [:] phenopacket . proband . phenotypic_features . extend ( randomised_hpo ) else : del phenopacket . phenotypic_features [:] phenopacket . phenotypic_features . extend ( randomised_hpo ) return phenopacket","title":"add_randomised_hpo()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketRebuilder.add_spiked_vcf_path","text":"Adds spiked vcf path to phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 235 236 237 238 239 240 241 242 243 244 def add_spiked_vcf_path ( self , spiked_vcf_file_data : File ) -> Phenopacket or Family : \"\"\"Adds spiked vcf path to phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) phenopacket_files = [ file for file in phenopacket . files if file . file_attributes [ \"fileFormat\" ] != \"VCF\" ] phenopacket_files . append ( spiked_vcf_file_data ) del phenopacket . files [:] phenopacket . files . extend ( phenopacket_files ) return phenopacket","title":"add_spiked_vcf_path()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketRebuilder.update_interpretations","text":"Adds the updated interpretations to a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 213 214 215 216 217 218 219 220 221 222 def update_interpretations ( self , interpretations ) -> Phenopacket or Family : \"\"\"Adds the updated interpretations to a phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) if hasattr ( phenopacket , \"proband\" ): del phenopacket . proband . interpretations [:] phenopacket . proband . interpretations . extend ( interpretations ) else : del phenopacket . interpretations [:] phenopacket . interpretations . extend ( interpretations ) return phenopacket","title":"update_interpretations()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil","text":"Retrieves relevant data from a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 class PhenopacketUtil : \"\"\"Retrieves relevant data from a phenopacket.\"\"\" def __init__ ( self , phenopacket_contents : Phenopacket ): self . phenopacket_contents = phenopacket_contents def sample_id ( self ) -> str : \"\"\"Retrieve the sample ID from a phenopacket or proband of a family.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . subject . id else : return self . phenopacket_contents . subject . id def phenotypic_features ( self ) -> list [ PhenotypicFeature ]: \"\"\"Retrieves a list of all HPO terms.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . phenotypic_features else : return self . phenopacket_contents . phenotypic_features def observed_phenotypic_features ( self ) -> list [ PhenotypicFeature ]: \"\"\"Removes any HPO terms labelled as excluded.\"\"\" phenotypic_features = [] all_phenotypic_features = self . phenotypic_features () for p in all_phenotypic_features : if p . excluded : continue phenotypic_features . append ( p ) return phenotypic_features def negated_phenotypic_features ( self ) -> [ PhenotypicFeature ]: \"\"\"Retrieve negated phenotypic features.\"\"\" negated_phenotypic_features = [] all_phenotypic_features = self . phenotypic_features () for p in all_phenotypic_features : if p . excluded : negated_phenotypic_features . append ( p ) return negated_phenotypic_features def interpretations ( self ) -> list [ Interpretation ]: \"\"\"Returns all interpretations of a phenopacket.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . interpretations else : return self . phenopacket_contents . interpretations def causative_variants ( self ) -> list [ ProbandCausativeVariant ]: \"\"\"Returns a list of all causative variants listed in a phenopacket.\"\"\" all_variants = [] interpretation = self . interpretations () for i in interpretation : for g in i . diagnosis . genomic_interpretations : vcf_record = g . variant_interpretation . variation_descriptor . vcf_record genotype = g . variant_interpretation . variation_descriptor . allelic_state variant_data = ProbandCausativeVariant ( self . phenopacket_contents . subject . id , vcf_record . genome_assembly , GenomicVariant ( vcf_record . chrom , vcf_record . pos , vcf_record . ref , vcf_record . alt , ), genotype . label , ) all_variants . append ( variant_data ) return all_variants def files ( self ) -> list : \"\"\"Returns all files associated with a phenopacket.\"\"\" return self . phenopacket_contents . files def vcf_file_data ( self , phenopacket_path : Path , vcf_dir : Path ) -> File : \"\"\"Retrieves the genome assembly and vcf name from a phenopacket.\"\"\" compatible_genome_assembly = [ \"GRCh37\" , \"hg19\" , \"GRCh38\" , \"hg38\" ] vcf_data = [ file for file in self . files () if file . file_attributes [ \"fileFormat\" ] == \"VCF\" ][ 0 ] if not Path ( vcf_data . uri ) . name . endswith ( \".vcf\" ) and not Path ( vcf_data . uri ) . name . endswith ( \".vcf.gz\" ): raise IncorrectFileFormatError ( Path ( vcf_data . uri ), \".vcf or .vcf.gz file\" ) if vcf_data . file_attributes [ \"genomeAssembly\" ] not in compatible_genome_assembly : raise IncompatibleGenomeAssemblyError ( vcf_data . file_attributes [ \"genomeAssembly\" ], phenopacket_path ) vcf_data . uri = str ( vcf_dir . joinpath ( Path ( vcf_data . uri ) . name )) return vcf_data def diagnosed_genes ( self ) -> list [ ProbandCausativeGene ]: \"\"\"Returns a unique list of all causative genes and the corresponding gene identifiers from a phenopacket.\"\"\" pheno_interpretation = self . interpretations () genes = [] for i in pheno_interpretation : for g in i . diagnosis . genomic_interpretations : genes . append ( ProbandCausativeGene ( g . variant_interpretation . variation_descriptor . gene_context . symbol , g . variant_interpretation . variation_descriptor . gene_context . value_id , ) ) genes = list ({ gene . gene_symbol : gene for gene in genes } . values ()) return genes def diagnosed_variants ( self ) -> list [ GenomicVariant ]: \"\"\"Returns a list of all variants from a phenopacket - for use in assess-prioritisation.\"\"\" variants = [] pheno_interpretation = self . interpretations () for i in pheno_interpretation : for g in i . diagnosis . genomic_interpretations : variant = GenomicVariant ( chrom = g . variant_interpretation . variation_descriptor . vcf_record . chrom , pos = g . variant_interpretation . variation_descriptor . vcf_record . pos , ref = g . variant_interpretation . variation_descriptor . vcf_record . ref , alt = g . variant_interpretation . variation_descriptor . vcf_record . alt , ) variants . append ( variant ) return variants","title":"PhenopacketUtil"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.causative_variants","text":"Returns a list of all causative variants listed in a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 def causative_variants ( self ) -> list [ ProbandCausativeVariant ]: \"\"\"Returns a list of all causative variants listed in a phenopacket.\"\"\" all_variants = [] interpretation = self . interpretations () for i in interpretation : for g in i . diagnosis . genomic_interpretations : vcf_record = g . variant_interpretation . variation_descriptor . vcf_record genotype = g . variant_interpretation . variation_descriptor . allelic_state variant_data = ProbandCausativeVariant ( self . phenopacket_contents . subject . id , vcf_record . genome_assembly , GenomicVariant ( vcf_record . chrom , vcf_record . pos , vcf_record . ref , vcf_record . alt , ), genotype . label , ) all_variants . append ( variant_data ) return all_variants","title":"causative_variants()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.diagnosed_genes","text":"Returns a unique list of all causative genes and the corresponding gene identifiers from a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 def diagnosed_genes ( self ) -> list [ ProbandCausativeGene ]: \"\"\"Returns a unique list of all causative genes and the corresponding gene identifiers from a phenopacket.\"\"\" pheno_interpretation = self . interpretations () genes = [] for i in pheno_interpretation : for g in i . diagnosis . genomic_interpretations : genes . append ( ProbandCausativeGene ( g . variant_interpretation . variation_descriptor . gene_context . symbol , g . variant_interpretation . variation_descriptor . gene_context . value_id , ) ) genes = list ({ gene . gene_symbol : gene for gene in genes } . values ()) return genes","title":"diagnosed_genes()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.diagnosed_variants","text":"Returns a list of all variants from a phenopacket - for use in assess-prioritisation. Source code in src/pheval/utils/phenopacket_utils.py 191 192 193 194 195 196 197 198 199 200 201 202 203 204 def diagnosed_variants ( self ) -> list [ GenomicVariant ]: \"\"\"Returns a list of all variants from a phenopacket - for use in assess-prioritisation.\"\"\" variants = [] pheno_interpretation = self . interpretations () for i in pheno_interpretation : for g in i . diagnosis . genomic_interpretations : variant = GenomicVariant ( chrom = g . variant_interpretation . variation_descriptor . vcf_record . chrom , pos = g . variant_interpretation . variation_descriptor . vcf_record . pos , ref = g . variant_interpretation . variation_descriptor . vcf_record . ref , alt = g . variant_interpretation . variation_descriptor . vcf_record . alt , ) variants . append ( variant ) return variants","title":"diagnosed_variants()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.files","text":"Returns all files associated with a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 157 158 159 def files ( self ) -> list : \"\"\"Returns all files associated with a phenopacket.\"\"\" return self . phenopacket_contents . files","title":"files()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.interpretations","text":"Returns all interpretations of a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 128 129 130 131 132 133 def interpretations ( self ) -> list [ Interpretation ]: \"\"\"Returns all interpretations of a phenopacket.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . interpretations else : return self . phenopacket_contents . interpretations","title":"interpretations()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.negated_phenotypic_features","text":"Retrieve negated phenotypic features. Source code in src/pheval/utils/phenopacket_utils.py 119 120 121 122 123 124 125 126 def negated_phenotypic_features ( self ) -> [ PhenotypicFeature ]: \"\"\"Retrieve negated phenotypic features.\"\"\" negated_phenotypic_features = [] all_phenotypic_features = self . phenotypic_features () for p in all_phenotypic_features : if p . excluded : negated_phenotypic_features . append ( p ) return negated_phenotypic_features","title":"negated_phenotypic_features()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.observed_phenotypic_features","text":"Removes any HPO terms labelled as excluded. Source code in src/pheval/utils/phenopacket_utils.py 109 110 111 112 113 114 115 116 117 def observed_phenotypic_features ( self ) -> list [ PhenotypicFeature ]: \"\"\"Removes any HPO terms labelled as excluded.\"\"\" phenotypic_features = [] all_phenotypic_features = self . phenotypic_features () for p in all_phenotypic_features : if p . excluded : continue phenotypic_features . append ( p ) return phenotypic_features","title":"observed_phenotypic_features()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.phenotypic_features","text":"Retrieves a list of all HPO terms. Source code in src/pheval/utils/phenopacket_utils.py 102 103 104 105 106 107 def phenotypic_features ( self ) -> list [ PhenotypicFeature ]: \"\"\"Retrieves a list of all HPO terms.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . phenotypic_features else : return self . phenopacket_contents . phenotypic_features","title":"phenotypic_features()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.sample_id","text":"Retrieve the sample ID from a phenopacket or proband of a family. Source code in src/pheval/utils/phenopacket_utils.py 95 96 97 98 99 100 def sample_id ( self ) -> str : \"\"\"Retrieve the sample ID from a phenopacket or proband of a family.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . subject . id else : return self . phenopacket_contents . subject . id","title":"sample_id()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.vcf_file_data","text":"Retrieves the genome assembly and vcf name from a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 def vcf_file_data ( self , phenopacket_path : Path , vcf_dir : Path ) -> File : \"\"\"Retrieves the genome assembly and vcf name from a phenopacket.\"\"\" compatible_genome_assembly = [ \"GRCh37\" , \"hg19\" , \"GRCh38\" , \"hg38\" ] vcf_data = [ file for file in self . files () if file . file_attributes [ \"fileFormat\" ] == \"VCF\" ][ 0 ] if not Path ( vcf_data . uri ) . name . endswith ( \".vcf\" ) and not Path ( vcf_data . uri ) . name . endswith ( \".vcf.gz\" ): raise IncorrectFileFormatError ( Path ( vcf_data . uri ), \".vcf or .vcf.gz file\" ) if vcf_data . file_attributes [ \"genomeAssembly\" ] not in compatible_genome_assembly : raise IncompatibleGenomeAssemblyError ( vcf_data . file_attributes [ \"genomeAssembly\" ], phenopacket_path ) vcf_data . uri = str ( vcf_dir . joinpath ( Path ( vcf_data . uri ) . name )) return vcf_data","title":"vcf_file_data()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.create_hgnc_dict","text":"Creates reference for updating gene symbols and identifiers. Source code in src/pheval/utils/phenopacket_utils.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def create_hgnc_dict () -> defaultdict : \"\"\"Creates reference for updating gene symbols and identifiers.\"\"\" hgnc_df = read_hgnc_data () hgnc_data = defaultdict ( dict ) for _index , row in hgnc_df . iterrows (): previous_names = [] hgnc_data [ row [ \"symbol\" ]][ \"ensembl_id\" ] = row [ \"ensembl_gene_id\" ] hgnc_data [ row [ \"symbol\" ]][ \"hgnc_id\" ] = row [ \"hgnc_id\" ] hgnc_data [ row [ \"symbol\" ]][ \"entrez_id\" ] = row [ \"entrez_id\" ] hgnc_data [ row [ \"symbol\" ]][ \"refseq_accession\" ] = row [ \"refseq_accession\" ] previous = str ( row [ \"prev_symbol\" ]) . split ( \"|\" ) for p in previous : previous_names . append ( p . strip ( '\"' )) hgnc_data [ row [ \"symbol\" ]][ \"previous_symbol\" ] = previous_names return hgnc_data","title":"create_hgnc_dict()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.create_json_message","text":"Creates json message for writing to file. Source code in src/pheval/utils/phenopacket_utils.py 247 248 249 def create_json_message ( phenopacket : Phenopacket or Family ) -> str : \"\"\"Creates json message for writing to file.\"\"\" return MessageToJson ( phenopacket )","title":"create_json_message()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.phenopacket_reader","text":"Reads a phenopacket file, returning its contents. Source code in src/pheval/utils/phenopacket_utils.py 78 79 80 81 82 83 84 85 86 def phenopacket_reader ( file : Path ): \"\"\"Reads a phenopacket file, returning its contents.\"\"\" file = open ( file , \"r\" ) phenopacket = json . load ( file ) file . close () if \"proband\" in phenopacket : return Parse ( json . dumps ( phenopacket ), Family ()) else : return Parse ( json . dumps ( phenopacket ), Phenopacket ())","title":"phenopacket_reader()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.write_phenopacket","text":"Writes a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 252 253 254 255 256 257 def write_phenopacket ( phenopacket : Phenopacket or Family , output_file : Path ) -> None : \"\"\"Writes a phenopacket.\"\"\" phenopacket_json = create_json_message ( phenopacket ) with open ( output_file , \"w\" ) as outfile : outfile . write ( phenopacket_json ) outfile . close ()","title":"write_phenopacket()"},{"location":"api/pheval/utils/semsim_utils/","text":"Contains all pheval utility methods diff_semsim ( semsim_left , semsim_right , score_column , absolute_diff ) Calculates score difference between two semantic similarity profiles Parameters: Name Type Description Default semsim_left pd . DataFrame first semantic similarity dataframe required semsim_right pd . DataFrame second semantic similarity dataframe required score_column str Score column that will be computed (e.g. jaccard_similarity) required absolute_diff bool Whether the difference is absolute (True) or percentage (False). required Returns: Type Description pd . DataFrame pd.DataFrame: A dataframe with terms and its scores differences Source code in src/pheval/utils/semsim_utils.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 def diff_semsim ( semsim_left : pd . DataFrame , semsim_right : pd . DataFrame , score_column : str , absolute_diff : bool ) -> pd . DataFrame : \"\"\"Calculates score difference between two semantic similarity profiles Args: semsim_left (pd.DataFrame): first semantic similarity dataframe semsim_right (pd.DataFrame): second semantic similarity dataframe score_column (str): Score column that will be computed (e.g. jaccard_similarity) absolute_diff (bool, optional): Whether the difference is absolute (True) or percentage (False). Defaults to True. Returns: pd.DataFrame: A dataframe with terms and its scores differences \"\"\" df = pd . merge ( semsim_left , semsim_right , on = [ \"subject_id\" , \"object_id\" ], how = \"outer\" ) if absolute_diff : df [ \"diff\" ] = df [ f \" { score_column } _x\" ] - df [ f \" { score_column } _y\" ] return df [[ \"subject_id\" , \"object_id\" , \"diff\" ]] df [ \"diff\" ] = df . apply ( lambda row : get_percentage_diff ( row [ f \" { score_column } _x\" ], row [ f \" { score_column } _y\" ]), axis = 1 ) return df [[ \"subject_id\" , \"object_id\" , f \" { score_column } _x\" , f \" { score_column } _y\" , \"diff\" ]] filter_non_0_score ( data , col ) Removes rows that have value equal to 0 based on the given column passed by col parameter Parameters: Name Type Description Default data pd . DataFrame Dirty dataframe required col str Column to be filtered required Returns: Type Description pd . DataFrame pd.DataFrame: Filtered dataframe Source code in src/pheval/utils/semsim_utils.py 13 14 15 16 17 18 19 20 21 22 23 def filter_non_0_score ( data : pd . DataFrame , col : str ) -> pd . DataFrame : \"\"\"Removes rows that have value equal to 0 based on the given column passed by col parameter Args: data (pd.DataFrame): Dirty dataframe col (str): Column to be filtered Returns: pd.DataFrame: Filtered dataframe \"\"\" return data [ data [ col ] != 0 ] get_percentage_diff ( current_number , previous_number ) Gets the percentage difference between two numbers Parameters: Name Type Description Default current_number float second number in comparison required previous_number float first number in comparison required Returns: Name Type Description float float percentage difference between two numbers Source code in src/pheval/utils/semsim_utils.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 def get_percentage_diff ( current_number : float , previous_number : float ) -> float : \"\"\"Gets the percentage difference between two numbers Args: current_number (float): second number in comparison previous_number (float): first number in comparison Returns: float: percentage difference between two numbers \"\"\" try : if current_number == previous_number : return \" {:.2%} \" . format ( 0 ) if current_number > previous_number : number = ( 1 - (( current_number / previous_number ))) * 100 else : number = ( 100 - (( previous_number / current_number ) * 100 )) * - 1 return \" {:.2%} \" . format ( number / 100 ) except ZeroDivisionError : return None parse_semsim ( df , cols ) Parses semantic similarity profiles converting the score column as a numeric value and dropping the null ones Parameters: Name Type Description Default df pd . DataFrame semantic similarity profile dataframe required cols list list of columns that will be selected on semsim data required Returns: Type Description pd . DataFrame pd.Dataframe: parsed semantic similarity dataframe Source code in src/pheval/utils/semsim_utils.py 26 27 28 29 30 31 32 33 34 35 36 37 38 def parse_semsim ( df : pd . DataFrame , cols : list ) -> pd . DataFrame : \"\"\"Parses semantic similarity profiles converting the score column as a numeric value and dropping the null ones Args: df (pd.DataFrame): semantic similarity profile dataframe cols (list): list of columns that will be selected on semsim data Returns: pd.Dataframe: parsed semantic similarity dataframe \"\"\" df [ cols [ - 1 ]] = pd . to_numeric ( df [ cols [ - 1 ]], errors = \"coerce\" ) df . replace ( \"None\" , numpy . nan ) . dropna ( subset = cols [ - 1 ], inplace = True ) return df percentage_diff ( semsim_left , semsim_right , score_column , output ) Compares two semantic similarity profiles Parameters: Name Type Description Default semsim_left Path File path of the first semantic similarity profile required semsim_right Path File path of the second semantic similarity profile required score_column str Score column that will be computed (e.g. jaccard_similarity) required output Path Output path for the difference tsv file required Source code in src/pheval/utils/semsim_utils.py 66 67 68 69 70 71 72 73 74 75 76 def percentage_diff ( semsim_left : Path , semsim_right : Path , score_column : str , output : Path ): \"\"\"Compares two semantic similarity profiles Args: semsim_left (Path): File path of the first semantic similarity profile semsim_right (Path): File path of the second semantic similarity profile score_column (str): Score column that will be computed (e.g. jaccard_similarity) output (Path): Output path for the difference tsv file \"\"\" clean_df = semsim_analysis ( semsim_left , semsim_right , score_column , absolute_diff = False ) clean_df . sort_values ( by = \"diff\" , ascending = False ) . to_csv ( output , sep = \" \\t \" , index = False ) semsim_analysis ( semsim_left , semsim_right , score_column , absolute_diff = True ) semsim_analysis Parameters: Name Type Description Default semsim_left Path File path of the first semantic similarity profile required semsim_right Path File path of the second semantic similarity profile required score_column str Score column that will be computed (e.g. jaccard_similarity) required absolute_diff bool Whether the difference is absolute (True) or percentage (False). True Returns: Type Description pd . DataFrame [pd.DataFrame]: DataFrame with the differences between two semantic similarity profiles Source code in src/pheval/utils/semsim_utils.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def semsim_analysis ( semsim_left : Path , semsim_right : Path , score_column : str , absolute_diff = True ) -> pd . DataFrame : \"\"\"semsim_analysis Args: semsim_left (Path): File path of the first semantic similarity profile semsim_right (Path): File path of the second semantic similarity profile score_column (str): Score column that will be computed (e.g. jaccard_similarity) absolute_diff (bool, optional): Whether the difference is absolute (True) or percentage (False). Defaults to True. Returns: [pd.DataFrame]: DataFrame with the differences between two semantic similarity profiles \"\"\" validate_semsim_file_comparison ( semsim_left , semsim_right ) cols = [ \"subject_id\" , \"object_id\" , score_column ] semsim_left = pd . read_csv ( semsim_left , sep = \" \\t \" ) semsim_right = pd . read_csv ( semsim_right , sep = \" \\t \" ) file_utils . ensure_columns_exists ( cols = cols , err_message = \"must exist in semsim dataframes\" , dataframes = [ semsim_left , semsim_right ], ) semsim_left = parse_semsim ( semsim_left , cols ) semsim_right = parse_semsim ( semsim_right , cols ) diff_df = diff_semsim ( semsim_left , semsim_right , score_column , absolute_diff ) return filter_non_0_score ( diff_df , \"diff\" ) semsim_heatmap_plot ( semsim_left , semsim_right , score_column ) Plots semantic similarity profiles heatmap Parameters: Name Type Description Default semsim_left Path File path of the first semantic similarity profile required semsim_right Path File path of the second semantic similarity profile required score_column str Score column that will be computed (e.g. jaccard_similarity) required Source code in src/pheval/utils/semsim_utils.py 79 80 81 82 83 84 85 86 87 88 89 90 def semsim_heatmap_plot ( semsim_left : Path , semsim_right : Path , score_column : str ): \"\"\"Plots semantic similarity profiles heatmap Args: semsim_left (Path): File path of the first semantic similarity profile semsim_right (Path): File path of the second semantic similarity profile score_column (str): Score column that will be computed (e.g. jaccard_similarity) \"\"\" clean_df = semsim_analysis ( semsim_left , semsim_right , score_column ) df = clean_df . pivot ( index = \"subject_id\" , columns = \"object_id\" , values = \"diff\" ) fig = px . imshow ( df , text_auto = True ) fig . show () validate_semsim_file_comparison ( semsim_left , semsim_right ) Checks if files exist and whether they're different Parameters: Name Type Description Default semsim_left Path File path of the first semantic similarity profile required semsim_right Path File path of the second semantic similarity profile required Raises: Type Description Exception FileNotFoundException Source code in src/pheval/utils/semsim_utils.py 123 124 125 126 127 128 129 130 131 132 133 134 def validate_semsim_file_comparison ( semsim_left : Path , semsim_right : Path ): \"\"\"Checks if files exist and whether they're different Args: semsim_left (Path): File path of the first semantic similarity profile semsim_right (Path): File path of the second semantic similarity profile Raises: Exception: FileNotFoundException \"\"\" if semsim_left == semsim_right : errmsg = \"Semantic similarity profiles are equal. Make sure you have selected different files to analyze\" raise Exception ( errmsg ) file_utils . ensure_file_exists ( semsim_left , semsim_right )","title":"Semsim utils"},{"location":"api/pheval/utils/semsim_utils/#src.pheval.utils.semsim_utils.diff_semsim","text":"Calculates score difference between two semantic similarity profiles Parameters: Name Type Description Default semsim_left pd . DataFrame first semantic similarity dataframe required semsim_right pd . DataFrame second semantic similarity dataframe required score_column str Score column that will be computed (e.g. jaccard_similarity) required absolute_diff bool Whether the difference is absolute (True) or percentage (False). required Returns: Type Description pd . DataFrame pd.DataFrame: A dataframe with terms and its scores differences Source code in src/pheval/utils/semsim_utils.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 def diff_semsim ( semsim_left : pd . DataFrame , semsim_right : pd . DataFrame , score_column : str , absolute_diff : bool ) -> pd . DataFrame : \"\"\"Calculates score difference between two semantic similarity profiles Args: semsim_left (pd.DataFrame): first semantic similarity dataframe semsim_right (pd.DataFrame): second semantic similarity dataframe score_column (str): Score column that will be computed (e.g. jaccard_similarity) absolute_diff (bool, optional): Whether the difference is absolute (True) or percentage (False). Defaults to True. Returns: pd.DataFrame: A dataframe with terms and its scores differences \"\"\" df = pd . merge ( semsim_left , semsim_right , on = [ \"subject_id\" , \"object_id\" ], how = \"outer\" ) if absolute_diff : df [ \"diff\" ] = df [ f \" { score_column } _x\" ] - df [ f \" { score_column } _y\" ] return df [[ \"subject_id\" , \"object_id\" , \"diff\" ]] df [ \"diff\" ] = df . apply ( lambda row : get_percentage_diff ( row [ f \" { score_column } _x\" ], row [ f \" { score_column } _y\" ]), axis = 1 ) return df [[ \"subject_id\" , \"object_id\" , f \" { score_column } _x\" , f \" { score_column } _y\" , \"diff\" ]]","title":"diff_semsim()"},{"location":"api/pheval/utils/semsim_utils/#src.pheval.utils.semsim_utils.filter_non_0_score","text":"Removes rows that have value equal to 0 based on the given column passed by col parameter Parameters: Name Type Description Default data pd . DataFrame Dirty dataframe required col str Column to be filtered required Returns: Type Description pd . DataFrame pd.DataFrame: Filtered dataframe Source code in src/pheval/utils/semsim_utils.py 13 14 15 16 17 18 19 20 21 22 23 def filter_non_0_score ( data : pd . DataFrame , col : str ) -> pd . DataFrame : \"\"\"Removes rows that have value equal to 0 based on the given column passed by col parameter Args: data (pd.DataFrame): Dirty dataframe col (str): Column to be filtered Returns: pd.DataFrame: Filtered dataframe \"\"\" return data [ data [ col ] != 0 ]","title":"filter_non_0_score()"},{"location":"api/pheval/utils/semsim_utils/#src.pheval.utils.semsim_utils.get_percentage_diff","text":"Gets the percentage difference between two numbers Parameters: Name Type Description Default current_number float second number in comparison required previous_number float first number in comparison required Returns: Name Type Description float float percentage difference between two numbers Source code in src/pheval/utils/semsim_utils.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 def get_percentage_diff ( current_number : float , previous_number : float ) -> float : \"\"\"Gets the percentage difference between two numbers Args: current_number (float): second number in comparison previous_number (float): first number in comparison Returns: float: percentage difference between two numbers \"\"\" try : if current_number == previous_number : return \" {:.2%} \" . format ( 0 ) if current_number > previous_number : number = ( 1 - (( current_number / previous_number ))) * 100 else : number = ( 100 - (( previous_number / current_number ) * 100 )) * - 1 return \" {:.2%} \" . format ( number / 100 ) except ZeroDivisionError : return None","title":"get_percentage_diff()"},{"location":"api/pheval/utils/semsim_utils/#src.pheval.utils.semsim_utils.parse_semsim","text":"Parses semantic similarity profiles converting the score column as a numeric value and dropping the null ones Parameters: Name Type Description Default df pd . DataFrame semantic similarity profile dataframe required cols list list of columns that will be selected on semsim data required Returns: Type Description pd . DataFrame pd.Dataframe: parsed semantic similarity dataframe Source code in src/pheval/utils/semsim_utils.py 26 27 28 29 30 31 32 33 34 35 36 37 38 def parse_semsim ( df : pd . DataFrame , cols : list ) -> pd . DataFrame : \"\"\"Parses semantic similarity profiles converting the score column as a numeric value and dropping the null ones Args: df (pd.DataFrame): semantic similarity profile dataframe cols (list): list of columns that will be selected on semsim data Returns: pd.Dataframe: parsed semantic similarity dataframe \"\"\" df [ cols [ - 1 ]] = pd . to_numeric ( df [ cols [ - 1 ]], errors = \"coerce\" ) df . replace ( \"None\" , numpy . nan ) . dropna ( subset = cols [ - 1 ], inplace = True ) return df","title":"parse_semsim()"},{"location":"api/pheval/utils/semsim_utils/#src.pheval.utils.semsim_utils.percentage_diff","text":"Compares two semantic similarity profiles Parameters: Name Type Description Default semsim_left Path File path of the first semantic similarity profile required semsim_right Path File path of the second semantic similarity profile required score_column str Score column that will be computed (e.g. jaccard_similarity) required output Path Output path for the difference tsv file required Source code in src/pheval/utils/semsim_utils.py 66 67 68 69 70 71 72 73 74 75 76 def percentage_diff ( semsim_left : Path , semsim_right : Path , score_column : str , output : Path ): \"\"\"Compares two semantic similarity profiles Args: semsim_left (Path): File path of the first semantic similarity profile semsim_right (Path): File path of the second semantic similarity profile score_column (str): Score column that will be computed (e.g. jaccard_similarity) output (Path): Output path for the difference tsv file \"\"\" clean_df = semsim_analysis ( semsim_left , semsim_right , score_column , absolute_diff = False ) clean_df . sort_values ( by = \"diff\" , ascending = False ) . to_csv ( output , sep = \" \\t \" , index = False )","title":"percentage_diff()"},{"location":"api/pheval/utils/semsim_utils/#src.pheval.utils.semsim_utils.semsim_analysis","text":"semsim_analysis Parameters: Name Type Description Default semsim_left Path File path of the first semantic similarity profile required semsim_right Path File path of the second semantic similarity profile required score_column str Score column that will be computed (e.g. jaccard_similarity) required absolute_diff bool Whether the difference is absolute (True) or percentage (False). True Returns: Type Description pd . DataFrame [pd.DataFrame]: DataFrame with the differences between two semantic similarity profiles Source code in src/pheval/utils/semsim_utils.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def semsim_analysis ( semsim_left : Path , semsim_right : Path , score_column : str , absolute_diff = True ) -> pd . DataFrame : \"\"\"semsim_analysis Args: semsim_left (Path): File path of the first semantic similarity profile semsim_right (Path): File path of the second semantic similarity profile score_column (str): Score column that will be computed (e.g. jaccard_similarity) absolute_diff (bool, optional): Whether the difference is absolute (True) or percentage (False). Defaults to True. Returns: [pd.DataFrame]: DataFrame with the differences between two semantic similarity profiles \"\"\" validate_semsim_file_comparison ( semsim_left , semsim_right ) cols = [ \"subject_id\" , \"object_id\" , score_column ] semsim_left = pd . read_csv ( semsim_left , sep = \" \\t \" ) semsim_right = pd . read_csv ( semsim_right , sep = \" \\t \" ) file_utils . ensure_columns_exists ( cols = cols , err_message = \"must exist in semsim dataframes\" , dataframes = [ semsim_left , semsim_right ], ) semsim_left = parse_semsim ( semsim_left , cols ) semsim_right = parse_semsim ( semsim_right , cols ) diff_df = diff_semsim ( semsim_left , semsim_right , score_column , absolute_diff ) return filter_non_0_score ( diff_df , \"diff\" )","title":"semsim_analysis()"},{"location":"api/pheval/utils/semsim_utils/#src.pheval.utils.semsim_utils.semsim_heatmap_plot","text":"Plots semantic similarity profiles heatmap Parameters: Name Type Description Default semsim_left Path File path of the first semantic similarity profile required semsim_right Path File path of the second semantic similarity profile required score_column str Score column that will be computed (e.g. jaccard_similarity) required Source code in src/pheval/utils/semsim_utils.py 79 80 81 82 83 84 85 86 87 88 89 90 def semsim_heatmap_plot ( semsim_left : Path , semsim_right : Path , score_column : str ): \"\"\"Plots semantic similarity profiles heatmap Args: semsim_left (Path): File path of the first semantic similarity profile semsim_right (Path): File path of the second semantic similarity profile score_column (str): Score column that will be computed (e.g. jaccard_similarity) \"\"\" clean_df = semsim_analysis ( semsim_left , semsim_right , score_column ) df = clean_df . pivot ( index = \"subject_id\" , columns = \"object_id\" , values = \"diff\" ) fig = px . imshow ( df , text_auto = True ) fig . show ()","title":"semsim_heatmap_plot()"},{"location":"api/pheval/utils/semsim_utils/#src.pheval.utils.semsim_utils.validate_semsim_file_comparison","text":"Checks if files exist and whether they're different Parameters: Name Type Description Default semsim_left Path File path of the first semantic similarity profile required semsim_right Path File path of the second semantic similarity profile required Raises: Type Description Exception FileNotFoundException Source code in src/pheval/utils/semsim_utils.py 123 124 125 126 127 128 129 130 131 132 133 134 def validate_semsim_file_comparison ( semsim_left : Path , semsim_right : Path ): \"\"\"Checks if files exist and whether they're different Args: semsim_left (Path): File path of the first semantic similarity profile semsim_right (Path): File path of the second semantic similarity profile Raises: Exception: FileNotFoundException \"\"\" if semsim_left == semsim_right : errmsg = \"Semantic similarity profiles are equal. Make sure you have selected different files to analyze\" raise Exception ( errmsg ) file_utils . ensure_file_exists ( semsim_left , semsim_right )","title":"validate_semsim_file_comparison()"}]}
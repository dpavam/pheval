{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Introduction PhEval - Phenotypic Inference Evaluation Framework PhEval: Tool-specific processing (VP pipeline) flowchart LR PC-->DP PC[(Phenopackets Corpus)] SSSOM[Semantic Similarity Profiles Mapping Commons]-->|OAK-SEMSIM|DP[Data Prepare] KG[Source data KG - Monarch KG]-->|KGX-BIOLINK|DP[Data Prepare] ONT[Ontologies - Phenio]-->|OAK-ONTO|DP[Data Prepare] DP-->RP[Run Prepare] RP-->PR[PhEval Runner] PR-->DP2[Data Process] ER[Exomiser Runner]-->PR EDP[Exomiser Data Prepare]-->DP ERP[Exomiser Run Prepare]-->RP PPP[Disease-profile similarity prediction Post-process]-->DP2 PV[Phenotype/Variant]-->DP2 GVP[Gene VP Post-process]-->DP2 EPP[Exomiser Post Process]-->GVP GVP-->VPR[VP Report] Quick links: GitHub page","title":"Home"},{"location":"#home","text":"","title":"Home"},{"location":"#introduction","text":"PhEval - Phenotypic Inference Evaluation Framework","title":"Introduction"},{"location":"#pheval-tool-specific-processing-vp-pipeline","text":"flowchart LR PC-->DP PC[(Phenopackets Corpus)] SSSOM[Semantic Similarity Profiles Mapping Commons]-->|OAK-SEMSIM|DP[Data Prepare] KG[Source data KG - Monarch KG]-->|KGX-BIOLINK|DP[Data Prepare] ONT[Ontologies - Phenio]-->|OAK-ONTO|DP[Data Prepare] DP-->RP[Run Prepare] RP-->PR[PhEval Runner] PR-->DP2[Data Process] ER[Exomiser Runner]-->PR EDP[Exomiser Data Prepare]-->DP ERP[Exomiser Run Prepare]-->RP PPP[Disease-profile similarity prediction Post-process]-->DP2 PV[Phenotype/Variant]-->DP2 GVP[Gene VP Post-process]-->DP2 EPP[Exomiser Post Process]-->GVP GVP-->VPR[VP Report] Quick links: GitHub page","title":"PhEval: Tool-specific processing (VP pipeline)"},{"location":"CODE_OF_CONDUCT/","text":"Contributor Covenant Code of Conduct Our Pledge In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to make participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Our Responsibilities Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution This code of conduct has been derived from the excellent code of conduct of the ATOM project which in turn is adapted from the Contributor Covenant , version 1.4, available at https://contributor-covenant.org/version/1/4","title":"Contributor Covenant Code of Conduct"},{"location":"CODE_OF_CONDUCT/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"CODE_OF_CONDUCT/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to make participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"CODE_OF_CONDUCT/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"CODE_OF_CONDUCT/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our Responsibilities"},{"location":"CODE_OF_CONDUCT/#scope","text":"This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"CODE_OF_CONDUCT/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"CODE_OF_CONDUCT/#attribution","text":"This code of conduct has been derived from the excellent code of conduct of the ATOM project which in turn is adapted from the Contributor Covenant , version 1.4, available at https://contributor-covenant.org/version/1/4","title":"Attribution"},{"location":"about/","text":"PhEval - Phenotypic Inference Evaluation Framework Many variant prioritization tools (such as Exomiser and other computational approaches rely on ontologies and phenotype matching, sometimes involving complex processes such as cross-species inference. The performance of such tools is exceedingly hard to evaluate, because of the many factors involved: changes to the structure of the ontology, cross-species mappings and semantic similarity algorithms can have significant consequences. Furthermore, the lack of suitable real-world problems/corpora lead to the situation that many algorithms are evaluated using simulations, which may fail to capture real-world scenarios. The lack of an evaluation framework that enables the study of effects on data and knowledge inputs on real world problems makes it difficult to optimize algorithms. To this end we are developing a modular Phenotypic Inference Evaluation Framework (PhEval) which is delivered it as a community resource.","title":"About"},{"location":"about/#pheval-phenotypic-inference-evaluation-framework","text":"Many variant prioritization tools (such as Exomiser and other computational approaches rely on ontologies and phenotype matching, sometimes involving complex processes such as cross-species inference. The performance of such tools is exceedingly hard to evaluate, because of the many factors involved: changes to the structure of the ontology, cross-species mappings and semantic similarity algorithms can have significant consequences. Furthermore, the lack of suitable real-world problems/corpora lead to the situation that many algorithms are evaluated using simulations, which may fail to capture real-world scenarios. The lack of an evaluation framework that enables the study of effects on data and knowledge inputs on real world problems makes it difficult to optimize algorithms. To this end we are developing a modular Phenotypic Inference Evaluation Framework (PhEval) which is delivered it as a community resource.","title":"PhEval - Phenotypic Inference Evaluation Framework"},{"location":"contact/","text":"Contact The preferred way to contact the PhEval team is through the issue tracker (for problems with PhEval) or the GitHub discussions (for general questions). You can find any of the members of the PhEval core team on GitHub: https://github.com/orgs/monarch-initiative/teams/pheval-team Their GitHub profiles usually also provide email addresses.","title":"Contact Us"},{"location":"contact/#contact","text":"The preferred way to contact the PhEval team is through the issue tracker (for problems with PhEval) or the GitHub discussions (for general questions). You can find any of the members of the PhEval core team on GitHub: https://github.com/orgs/monarch-initiative/teams/pheval-team Their GitHub profiles usually also provide email addresses.","title":"Contact"},{"location":"contributing/","text":"Contributions First of all: Thank you for taking the time to contribute! The following is a set of guidelines for contributing to the PhEval framework. These guidelines are not strict rules. Use your best judgment, and feel free to propose changes to this document in a pull request. Table Of Contents Contributions Table Of Contents Code of Conduct Guidelines for Contributions and Requests Reporting problems with the data model Code of Conduct The monarch-technical-documentation team strives to create a welcoming environment for editors, users and other contributors. Please carefully read our Code of Conduct . Guidelines for Contributions and Requests Reporting problems with the data model Please use our Issue Tracker for reporting problems with the ontology.","title":"Contributions"},{"location":"contributing/#contributions","text":"First of all: Thank you for taking the time to contribute! The following is a set of guidelines for contributing to the PhEval framework. These guidelines are not strict rules. Use your best judgment, and feel free to propose changes to this document in a pull request.","title":"Contributions"},{"location":"contributing/#table-of-contents","text":"Contributions Table Of Contents Code of Conduct Guidelines for Contributions and Requests Reporting problems with the data model","title":"Table Of Contents"},{"location":"contributing/#code-of-conduct","text":"The monarch-technical-documentation team strives to create a welcoming environment for editors, users and other contributors. Please carefully read our Code of Conduct .","title":"Code of Conduct"},{"location":"contributing/#guidelines-for-contributions-and-requests","text":"","title":"Guidelines for Contributions and Requests"},{"location":"contributing/#reporting-problems-with-the-data-model","text":"Please use our Issue Tracker for reporting problems with the ontology.","title":"Reporting problems with the data model"},{"location":"developing_a_pheval_plugin/","text":"Developing a PhEval Plugin Description Plugin development allows PhEval to be extensible, as we have designed it. The plugin goal is to be flexible through custom runner implementations. This plugin development enhances the PhEval functionality. You can build one quickly using this step-by-step process. All custom Runners implementations must implement all PhevalRunner methods Bases: ABC PhEvalRunner Class Source code in src/pheval/runners/runner.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 @dataclass class PhEvalRunner ( ABC ): \"\"\"PhEvalRunner Class\"\"\" input_dir : Path testdata_dir : Path tmp_dir : Path output_dir : Path config_file : Path version : str directory_path = None input_dir_config = None _meta_data = None __raw_results_dir = \"raw_results/\" __pheval_gene_results_dir = \"pheval_gene_results/\" __pheval_variant_results_dir = \"pheval_variant_results/\" __tool_input_commands_dir = \"tool_input_commands/\" __run_meta_data_file = \"results.yml\" def __post_init__ ( self ): self . input_dir_config = parse_input_dir_config ( self . input_dir ) def _get_tool ( self ): return self . input_dir_config . tool def _get_phenotype_only ( self ): return self . input_dir_config . phenotype_only @property def tool_input_commands_dir ( self ): return Path ( self . output_dir ) . joinpath ( self . __tool_input_commands_dir ) @tool_input_commands_dir . setter def tool_input_commands_dir ( self , directory_path ): self . directory_path = Path ( directory_path ) @property def raw_results_dir ( self ): return Path ( self . output_dir ) . joinpath ( self . __raw_results_dir ) @raw_results_dir . setter def raw_results_dir ( self , directory_path ): self . directory_path = Path ( directory_path ) @property def pheval_gene_results_dir ( self ): return Path ( self . output_dir ) . joinpath ( self . __pheval_gene_results_dir ) @pheval_gene_results_dir . setter def pheval_gene_results_dir ( self , directory_path ): self . directory_path = Path ( directory_path ) @property def pheval_variant_results_dir ( self ): return Path ( self . output_dir ) . joinpath ( self . __pheval_variant_results_dir ) @pheval_variant_results_dir . setter def pheval_variant_results_dir ( self , directory_path ): self . directory_path = Path ( directory_path ) def build_output_directory_structure ( self ): \"\"\"build output directory structure\"\"\" self . tool_input_commands_dir . mkdir ( exist_ok = True ) self . raw_results_dir . mkdir ( exist_ok = True ) self . pheval_gene_results_dir . mkdir ( exist_ok = True ) if not self . _get_phenotype_only (): self . pheval_variant_results_dir . mkdir ( exist_ok = True ) @property def meta_data ( self ): self . _meta_data = BasicOutputRunMetaData ( tool = self . input_dir_config . tool , tool_version = self . version , config = f \" { Path ( self . input_dir ) . parent . name } / { Path ( self . input_dir ) . name } \" , run_timestamp = datetime . now () . timestamp (), corpus = f \" { Path ( self . testdata_dir ) . parent . name } / { Path ( self . testdata_dir ) . name } \" , ) return self . _meta_data @meta_data . setter def meta_data ( self , meta_data ): self . _meta_data = meta_data @abstractmethod def prepare ( self ) -> str : \"\"\"prepare\"\"\" @abstractmethod def run ( self ): \"\"\"run\"\"\" @abstractmethod def post_process ( self ): \"\"\"post_process\"\"\" def construct_meta_data ( self ): \"\"\"Construct run output meta data\"\"\" return self . meta_data Step-by-Step Plugin Development Process The plugin structure is derived from a cookiecutter template, Sphintoxetry-cookiecutter , and it uses Sphinx , tox and poetry as core dependencies. This allows PhEval extensibility to be standardized in terms of documentation and dependency management. 1. Sphintoxetry-cookiecutter scaffold First, install the cruft package. Cruft enables keeping projects up-to-date with future updates made to this original template. Install cruft from pip pip install cruft Next, create a project using the sphintoxetry-cookiecutter template. cruft create https://github.com/hrshdhgd/sphintoxetry-cookiecutter 2. Further setup Install poetry if you haven't already. pip install poetry Install dependencies poetry install Add PhEval dependency poetry add pheval Run tox to see if the setup works poetry run tox 3. Implement PhEval Custom Runner The runner name is arbitrary and custom Runner name was chose by demonstrative purposes Create a runner file inside the plugin project, e.g: \"\"\"Custom Pheval Runner.\"\"\" from dataclasses import dataclass import click from pheval.runners.runner import PhEvalRunner @dataclass class CustomPhevalRunner ( PhEvalRunner ): \"\"\"CustomPhevalRunner Class.\"\"\" inputdir : click . Path testdatadir : click . Path tmpdir : click . Path outputdir : click . Path config : click . Path def prepare ( self ): \"\"\"prepare method.\"\"\" print ( \"preparing\" ) def run ( self ): \"\"\"run method.\"\"\" print ( \"running with custom pheval Runner\" ) def post_process ( self ): \"\"\"post_process method.\"\"\" print ( \"post processing\" ) 4. Add PhEval Plugins section into the pyproject.toml file [tool.poetry.plugins.\"pheval.plugins\"] customrunner = \"pheval_plugin_example.runner:CustomPhevalRunner\" Replace the value above with the path to your custom runner plugin 5. Test it. To update your custom pheval runner implementation, you must first install the package poetry install Now you have to be able to run PhEval passing your custom runner as parameter. e.g pheval run -i input.txt -t './test' -r 'customphevalrunner' -o out.txt The -r parameter stands for your plugin runner class name and it must be entirely lowercase. Output: preparing running with custom pheval Runner post processing Pay attention to \" running with custom pheval Runner \" line, this is exactly what we had implemented in the CustomPhevalRunner Example","title":"Developing a PhEval Plugin"},{"location":"developing_a_pheval_plugin/#developing-a-pheval-plugin","text":"","title":"Developing a PhEval Plugin"},{"location":"developing_a_pheval_plugin/#description","text":"Plugin development allows PhEval to be extensible, as we have designed it. The plugin goal is to be flexible through custom runner implementations. This plugin development enhances the PhEval functionality. You can build one quickly using this step-by-step process. All custom Runners implementations must implement all PhevalRunner methods Bases: ABC PhEvalRunner Class Source code in src/pheval/runners/runner.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 @dataclass class PhEvalRunner ( ABC ): \"\"\"PhEvalRunner Class\"\"\" input_dir : Path testdata_dir : Path tmp_dir : Path output_dir : Path config_file : Path version : str directory_path = None input_dir_config = None _meta_data = None __raw_results_dir = \"raw_results/\" __pheval_gene_results_dir = \"pheval_gene_results/\" __pheval_variant_results_dir = \"pheval_variant_results/\" __tool_input_commands_dir = \"tool_input_commands/\" __run_meta_data_file = \"results.yml\" def __post_init__ ( self ): self . input_dir_config = parse_input_dir_config ( self . input_dir ) def _get_tool ( self ): return self . input_dir_config . tool def _get_phenotype_only ( self ): return self . input_dir_config . phenotype_only @property def tool_input_commands_dir ( self ): return Path ( self . output_dir ) . joinpath ( self . __tool_input_commands_dir ) @tool_input_commands_dir . setter def tool_input_commands_dir ( self , directory_path ): self . directory_path = Path ( directory_path ) @property def raw_results_dir ( self ): return Path ( self . output_dir ) . joinpath ( self . __raw_results_dir ) @raw_results_dir . setter def raw_results_dir ( self , directory_path ): self . directory_path = Path ( directory_path ) @property def pheval_gene_results_dir ( self ): return Path ( self . output_dir ) . joinpath ( self . __pheval_gene_results_dir ) @pheval_gene_results_dir . setter def pheval_gene_results_dir ( self , directory_path ): self . directory_path = Path ( directory_path ) @property def pheval_variant_results_dir ( self ): return Path ( self . output_dir ) . joinpath ( self . __pheval_variant_results_dir ) @pheval_variant_results_dir . setter def pheval_variant_results_dir ( self , directory_path ): self . directory_path = Path ( directory_path ) def build_output_directory_structure ( self ): \"\"\"build output directory structure\"\"\" self . tool_input_commands_dir . mkdir ( exist_ok = True ) self . raw_results_dir . mkdir ( exist_ok = True ) self . pheval_gene_results_dir . mkdir ( exist_ok = True ) if not self . _get_phenotype_only (): self . pheval_variant_results_dir . mkdir ( exist_ok = True ) @property def meta_data ( self ): self . _meta_data = BasicOutputRunMetaData ( tool = self . input_dir_config . tool , tool_version = self . version , config = f \" { Path ( self . input_dir ) . parent . name } / { Path ( self . input_dir ) . name } \" , run_timestamp = datetime . now () . timestamp (), corpus = f \" { Path ( self . testdata_dir ) . parent . name } / { Path ( self . testdata_dir ) . name } \" , ) return self . _meta_data @meta_data . setter def meta_data ( self , meta_data ): self . _meta_data = meta_data @abstractmethod def prepare ( self ) -> str : \"\"\"prepare\"\"\" @abstractmethod def run ( self ): \"\"\"run\"\"\" @abstractmethod def post_process ( self ): \"\"\"post_process\"\"\" def construct_meta_data ( self ): \"\"\"Construct run output meta data\"\"\" return self . meta_data","title":"Description"},{"location":"developing_a_pheval_plugin/#step-by-step-plugin-development-process","text":"The plugin structure is derived from a cookiecutter template, Sphintoxetry-cookiecutter , and it uses Sphinx , tox and poetry as core dependencies. This allows PhEval extensibility to be standardized in terms of documentation and dependency management.","title":"Step-by-Step Plugin Development Process"},{"location":"developing_a_pheval_plugin/#1-sphintoxetry-cookiecutter-scaffold","text":"First, install the cruft package. Cruft enables keeping projects up-to-date with future updates made to this original template. Install cruft from pip pip install cruft Next, create a project using the sphintoxetry-cookiecutter template. cruft create https://github.com/hrshdhgd/sphintoxetry-cookiecutter","title":"1. Sphintoxetry-cookiecutter scaffold"},{"location":"developing_a_pheval_plugin/#2-further-setup","text":"","title":"2. Further setup"},{"location":"developing_a_pheval_plugin/#install-poetry-if-you-havent-already","text":"pip install poetry","title":"Install poetry if you haven't already."},{"location":"developing_a_pheval_plugin/#install-dependencies","text":"poetry install","title":"Install dependencies"},{"location":"developing_a_pheval_plugin/#add-pheval-dependency","text":"poetry add pheval","title":"Add PhEval dependency"},{"location":"developing_a_pheval_plugin/#run-tox-to-see-if-the-setup-works","text":"poetry run tox","title":"Run tox to see if the setup works"},{"location":"developing_a_pheval_plugin/#3-implement-pheval-custom-runner","text":"The runner name is arbitrary and custom Runner name was chose by demonstrative purposes Create a runner file inside the plugin project, e.g: \"\"\"Custom Pheval Runner.\"\"\" from dataclasses import dataclass import click from pheval.runners.runner import PhEvalRunner @dataclass class CustomPhevalRunner ( PhEvalRunner ): \"\"\"CustomPhevalRunner Class.\"\"\" inputdir : click . Path testdatadir : click . Path tmpdir : click . Path outputdir : click . Path config : click . Path def prepare ( self ): \"\"\"prepare method.\"\"\" print ( \"preparing\" ) def run ( self ): \"\"\"run method.\"\"\" print ( \"running with custom pheval Runner\" ) def post_process ( self ): \"\"\"post_process method.\"\"\" print ( \"post processing\" )","title":"3. Implement PhEval Custom Runner"},{"location":"developing_a_pheval_plugin/#4-add-pheval-plugins-section-into-the-pyprojecttoml-file","text":"[tool.poetry.plugins.\"pheval.plugins\"] customrunner = \"pheval_plugin_example.runner:CustomPhevalRunner\" Replace the value above with the path to your custom runner plugin","title":"4. Add PhEval Plugins section into the pyproject.toml file"},{"location":"developing_a_pheval_plugin/#5-test-it","text":"To update your custom pheval runner implementation, you must first install the package poetry install Now you have to be able to run PhEval passing your custom runner as parameter. e.g pheval run -i input.txt -t './test' -r 'customphevalrunner' -o out.txt The -r parameter stands for your plugin runner class name and it must be entirely lowercase. Output: preparing running with custom pheval Runner post processing Pay attention to \" running with custom pheval Runner \" line, this is exactly what we had implemented in the CustomPhevalRunner Example","title":"5. Test it."},{"location":"pipeline/","text":"PhEval Pipeline Jinja Template PhEval Makefile Generator Requirements To generate a PhEval Makefile we use the Jinja template engine. Installing Jinja Template Linux (Ubuntu): sudo snap install j2 Mac OS: PhEval Makefile Template (.j2 file) \ud83d\udce6resources \u2523 \ud83d\udcdc Makefile.j2 custom.Makefile is the template that will be generated on the fly based on the pheval-config.yaml . Each of these configurations is filled using a syntax like this: {{ config.tool }} . The value between the curly brackets is replaced by the corresponding configuration in the configuration file. PhEval custom.Makefile \ud83d\udce6resources \u2523 \ud83d\udcdc custom.Makefile PhEval generatemakefile.sh \ud83d\udce6resources \u2523 \ud83d\udcdcgeneratemakefile.sh generatemakefile.sh is only a shortcut for Makefile rendering using the configuration file e.g. bash ./resources/generatemakefile.sh PhEval Configuration File In resources folder, there is a file named pheval-config.yaml , this file is responsible for storing the PhEval Makefile generation. \ud83d\udce6resources \u2517 \ud83d\udcdcpheval-config.yaml Phenotype Section phenotype : version : 2302 hg : hg19 url : https://data.monarchinitiative.org/exomiser/latest/ Directories Section directories : tmp : data/tmp testdata : testdata config : configurations h2jar : /home/vinicius/.local/share/DBeaverData/drivers/maven/maven-central/com.h2database/h2-1.4.199.jar phen2gene : /pathtoPhen2Gene/Phen2Gene exomiser : /pathto/exomiser phenotype : /pathto/exomiser-data/2302_phenotype workspace : /pathto/workspace Configs Section configs : - tool : phen2gene version : 1.2.3 configuration : default - tool : exomiser version : 13.2.0 configuration : default exomiser_db : semsim1 This section is responsible for setting up the configuration folder. All software declared in the configs section will be linked in this folder. In the configuration above, for example, we have one configuration for phen2gene and one for exomiser. In the Directories Section , these two configurations must have one corresponding property set up. PhEval pipeline invokes the prepare-inputs goal, and in the preceding example, a configuration folder structure will be built that looks like this: \ud83d\udce6configurations \u2523 \ud83d\udcc2exomiser-13.2.0-default \u2517 \ud83d\udcc2phen2gene-1.2.3-default Each of these folders is a symbolic link that points to the corresponding software folder indicated in the Directories Section Corpora Section corpora : - id : lirical scrambled : - factor : 0.5 - factor : 0.7 custom_variants : - id : no_phenotype - id : phen2gene scrambled : - factor : 0.2 - factor : 0.9 custom_variants : - id : no_phenotype In this corpora section we can set up different experiments for corpus scrambling. Currently, PhEval provides corpora data from lirical, phen2gene, small_test and structural_variants \ud83d\udce6corpora \u2523 \ud83d\udcc2lirical \u2523 \ud83d\udcc2phen2gene \u2523 \ud83d\udcc2small_test \u2517 \ud83d\udcc2structural_variants The scramble property defines the magnitude of the scrambling factor during Phenopackets and VCF variants spiking process. Using the configuration in the example above, a corpora structure will be created like this: \ud83d\udce6corpora \u2523 \ud83d\udcc2lirical \u2503 \u2517 \ud83d\udcc2default \u2503 \u2517 \ud83d\udcc2scrambled-0.5 \u2503 \u2517 \ud83d\udcc2scrambled-0.7 \u2523 \ud83d\udcc2phen2gene \u2503 \u2517 \ud83d\udcc2default \u2503 \u2517 \ud83d\udcc2scrambled-0.2 \u2503 \u2517 \ud83d\udcc2scrambled-0.9 Runs Section runs : - tool : exomiser configuration : default corpus : lirical corpusvariant : scrambled-0.5 version : 13.2.0 - tool : phen2gene configuration : default corpus : phen2gene corpusvariant : scrambled-0.2 version : 1.2.3 Makefile Goals make pheval this runs the entire pipeline including corpus preparation and pheval run $(MAKE) prepare-inputs $(MAKE) prepare-corpora $(MAKE) pheval-run make semsim generate all configured similarity profiles make semsim-shuffle generate new ontology terms to the semsim process make semsim-scramble scramble semsim profile make semsim-convert convert all semsim profiles into exomiser SQL format make semsim-ingest takes all the configured semsim profiles and loads them into the exomiser databases","title":"PhEval Pipeline"},{"location":"pipeline/#pheval-pipeline","text":"","title":"PhEval Pipeline"},{"location":"pipeline/#jinja-template-pheval-makefile-generator-requirements","text":"To generate a PhEval Makefile we use the Jinja template engine.","title":"Jinja Template PhEval Makefile Generator Requirements"},{"location":"pipeline/#installing-jinja-template","text":"Linux (Ubuntu): sudo snap install j2 Mac OS:","title":"Installing Jinja Template"},{"location":"pipeline/#pheval-makefile-template-j2-file","text":"\ud83d\udce6resources \u2523 \ud83d\udcdc Makefile.j2 custom.Makefile is the template that will be generated on the fly based on the pheval-config.yaml . Each of these configurations is filled using a syntax like this: {{ config.tool }} . The value between the curly brackets is replaced by the corresponding configuration in the configuration file.","title":"PhEval Makefile Template (.j2 file)"},{"location":"pipeline/#pheval-custommakefile","text":"\ud83d\udce6resources \u2523 \ud83d\udcdc custom.Makefile","title":"PhEval custom.Makefile"},{"location":"pipeline/#pheval-generatemakefilesh","text":"\ud83d\udce6resources \u2523 \ud83d\udcdcgeneratemakefile.sh generatemakefile.sh is only a shortcut for Makefile rendering using the configuration file e.g. bash ./resources/generatemakefile.sh","title":"PhEval generatemakefile.sh"},{"location":"pipeline/#pheval-configuration-file","text":"In resources folder, there is a file named pheval-config.yaml , this file is responsible for storing the PhEval Makefile generation. \ud83d\udce6resources \u2517 \ud83d\udcdcpheval-config.yaml","title":"PhEval Configuration File"},{"location":"pipeline/#phenotype-section","text":"phenotype : version : 2302 hg : hg19 url : https://data.monarchinitiative.org/exomiser/latest/","title":"Phenotype Section"},{"location":"pipeline/#directories-section","text":"directories : tmp : data/tmp testdata : testdata config : configurations h2jar : /home/vinicius/.local/share/DBeaverData/drivers/maven/maven-central/com.h2database/h2-1.4.199.jar phen2gene : /pathtoPhen2Gene/Phen2Gene exomiser : /pathto/exomiser phenotype : /pathto/exomiser-data/2302_phenotype workspace : /pathto/workspace","title":"Directories Section"},{"location":"pipeline/#configs-section","text":"configs : - tool : phen2gene version : 1.2.3 configuration : default - tool : exomiser version : 13.2.0 configuration : default exomiser_db : semsim1 This section is responsible for setting up the configuration folder. All software declared in the configs section will be linked in this folder. In the configuration above, for example, we have one configuration for phen2gene and one for exomiser. In the Directories Section , these two configurations must have one corresponding property set up. PhEval pipeline invokes the prepare-inputs goal, and in the preceding example, a configuration folder structure will be built that looks like this: \ud83d\udce6configurations \u2523 \ud83d\udcc2exomiser-13.2.0-default \u2517 \ud83d\udcc2phen2gene-1.2.3-default Each of these folders is a symbolic link that points to the corresponding software folder indicated in the Directories Section","title":"Configs Section"},{"location":"pipeline/#corpora-section","text":"corpora : - id : lirical scrambled : - factor : 0.5 - factor : 0.7 custom_variants : - id : no_phenotype - id : phen2gene scrambled : - factor : 0.2 - factor : 0.9 custom_variants : - id : no_phenotype In this corpora section we can set up different experiments for corpus scrambling. Currently, PhEval provides corpora data from lirical, phen2gene, small_test and structural_variants \ud83d\udce6corpora \u2523 \ud83d\udcc2lirical \u2523 \ud83d\udcc2phen2gene \u2523 \ud83d\udcc2small_test \u2517 \ud83d\udcc2structural_variants The scramble property defines the magnitude of the scrambling factor during Phenopackets and VCF variants spiking process. Using the configuration in the example above, a corpora structure will be created like this: \ud83d\udce6corpora \u2523 \ud83d\udcc2lirical \u2503 \u2517 \ud83d\udcc2default \u2503 \u2517 \ud83d\udcc2scrambled-0.5 \u2503 \u2517 \ud83d\udcc2scrambled-0.7 \u2523 \ud83d\udcc2phen2gene \u2503 \u2517 \ud83d\udcc2default \u2503 \u2517 \ud83d\udcc2scrambled-0.2 \u2503 \u2517 \ud83d\udcc2scrambled-0.9","title":"Corpora Section"},{"location":"pipeline/#runs-section","text":"runs : - tool : exomiser configuration : default corpus : lirical corpusvariant : scrambled-0.5 version : 13.2.0 - tool : phen2gene configuration : default corpus : phen2gene corpusvariant : scrambled-0.2 version : 1.2.3","title":"Runs Section"},{"location":"pipeline/#makefile-goals","text":"","title":"Makefile Goals"},{"location":"pipeline/#make-pheval","text":"this runs the entire pipeline including corpus preparation and pheval run $(MAKE) prepare-inputs $(MAKE) prepare-corpora $(MAKE) pheval-run","title":"make pheval"},{"location":"pipeline/#make-semsim","text":"generate all configured similarity profiles","title":"make semsim"},{"location":"pipeline/#make-semsim-shuffle","text":"generate new ontology terms to the semsim process","title":"make semsim-shuffle"},{"location":"pipeline/#make-semsim-scramble","text":"scramble semsim profile","title":"make semsim-scramble"},{"location":"pipeline/#make-semsim-convert","text":"convert all semsim profiles into exomiser SQL format","title":"make semsim-convert"},{"location":"pipeline/#make-semsim-ingest","text":"takes all the configured semsim profiles and loads them into the exomiser databases","title":"make semsim-ingest"},{"location":"roadmap/","text":"Roadmap The Roadmap is a rough plan, changes are expected throughout the year. 2023 Q1 Finalising the PhEval architecture (draft is done) End-to-end pipeline for testing PhEval with Exomiser and two versions of HPO Submitting a poster to Biocuration which outlines the full vision Q2 Focus on an analytic framework around PhEval, focusing on studying how changes to ontologies affect changes in variant prioritisation Extend phenotype pipeline to enable base releases and alternative patterns Q3 Improving the analytic framework of PhEval, especially phenotype analysis All intermediate files of pipeline have a corresponding LinkML model Focus on studying the effect of KG snippets (p2ds) on VP performance Q4 Drafting a PhEval paper Building standalone pipeline that reports changes in algorithm behaviours to ontology developers.","title":"Roadmap"},{"location":"roadmap/#roadmap","text":"The Roadmap is a rough plan, changes are expected throughout the year.","title":"Roadmap"},{"location":"roadmap/#2023","text":"","title":"2023"},{"location":"roadmap/#q1","text":"Finalising the PhEval architecture (draft is done) End-to-end pipeline for testing PhEval with Exomiser and two versions of HPO Submitting a poster to Biocuration which outlines the full vision","title":"Q1"},{"location":"roadmap/#q2","text":"Focus on an analytic framework around PhEval, focusing on studying how changes to ontologies affect changes in variant prioritisation Extend phenotype pipeline to enable base releases and alternative patterns","title":"Q2"},{"location":"roadmap/#q3","text":"Improving the analytic framework of PhEval, especially phenotype analysis All intermediate files of pipeline have a corresponding LinkML model Focus on studying the effect of KG snippets (p2ds) on VP performance","title":"Q3"},{"location":"roadmap/#q4","text":"Drafting a PhEval paper Building standalone pipeline that reports changes in algorithm behaviours to ontology developers.","title":"Q4"},{"location":"styleguide/","text":"Monarch Style Guide for PhEval No code in CLI methods","title":"Monarch Style Guide for PhEval"},{"location":"styleguide/#monarch-style-guide-for-pheval","text":"No code in CLI methods","title":"Monarch Style Guide for PhEval"},{"location":"api/pheval/cli/","text":"main main CLI method for PhEval Args: verbose (int, optional): Verbose flag. quiet (bool, optional): Queit Flag. Usage: main [OPTIONS] COMMAND [ARGS]... Options: Name Type Description Default -v , --verbose integer range ( 0 and above) N/A 0 -q , --quiet text N/A None --help boolean Show this message and exit. False pheval pheval Usage: pheval [OPTIONS] COMMAND [ARGS]... Options: Name Type Description Default --help boolean Show this message and exit. False Subcommands run : PhEval Runner Command Line Interface run PhEval Runner Command Line Interface Args: input_dir (Path): The input directory (relative path: e.g exomiser-13.11) testdata_dir (Path): The input directory (relative path: e.g ./data runner (str): Runner implementation (e.g exomiser-13.11) tmp_dir (Path): The path of the temporary directory (optional) output_dir (Path): The path of the output directory config (Path): The path of the configuration file (optional e.g., config.yaml) version (str): The version of the tool implementation Usage: pheval run [OPTIONS] Options: Name Type Description Default --input-dir , -i Path The input directory (relative path: e.g exomiser-13.11) _required --testdata-dir , -t Path The input directory (relative path: e.g ./data) _required --runner , -r text Runner implementation (e.g exomiser-13.11) _required --tmp-dir , -m Path The path of the temporary directory (optional) None --output-dir , -o Path The path of the output directory _required --config , -c Path The path of the configuration file (optional e.g config.yaml) None --version , -v text Version of the tool implementation. None --help boolean Show this message and exit. False pheval-utils pheval_utils Usage: pheval-utils [OPTIONS] COMMAND [ARGS]... Options: Name Type Description Default --help boolean Show this message and exit. False Subcommands benchmark : Benchmark the gene/variant prioritisation performance for a single run. benchmark-comparison : Benchmark the gene/variant prioritisation performance for two runs. create-spiked-vcfs : Spikes variants into a template VCF file for a directory of phenopackets. scramble-phenopackets : Generate noisy phenopackets from existing ones. semsim-convert : convert semsim profile to an exomiser database file semsim-scramble : Scrambles semsim profile multiplying score value by scramble factor update-phenopackets : Update gene symbols and identifiers for phenopackets. benchmark Benchmark the gene/variant prioritisation performance for a single run. Usage: pheval-utils benchmark [OPTIONS] Options: Name Type Description Default --directory , -d Path General results directory to be benchmarked, assumes contains subdirectories of pheval_gene_results/pheval_variant_results and the tool specific results directory. _required --phenopacket-dir , -p Path Full path to directory containing input phenopackets. _required --output-prefix , -o text Output file prefix. _required --score-order , -so choice ( ascending | descending ) Ordering of results for ranking. descending --threshold , -t float Score threshold. 0.0 --gene-analysis / --no-gene-analysis boolean Specify analysis for gene prioritisation False --variant-analysis / --no-variant-analysis boolean Specify analysis for variant prioritisation False --plot-type , -p choice ( bar_stacked | bar_cumulative | bar_non_cumulative ) Bar chart type to output. bar_stacked --help boolean Show this message and exit. False benchmark-comparison Benchmark the gene/variant prioritisation performance for two runs. Usage: pheval-utils benchmark-comparison [OPTIONS] Options: Name Type Description Default --run-data , -r Path Path to .txt file containing testdata directory and corresponding results directory separated by tab.Each run contained to a new line with the input testdata listed first and on the same line separated by a tabthe results directory. _required --output-prefix , -o text Output file prefix. _required --score-order , -so choice ( ascending | descending ) Ordering of results for ranking. descending --threshold , -t float Score threshold. 0.0 --gene-analysis / --no-gene-analysis boolean Specify analysis for gene prioritisation False --variant-analysis / --no-variant-analysis boolean Specify analysis for variant prioritisation False --plot-type , -p choice ( bar_stacked | bar_cumulative | bar_non_cumulative ) Bar chart type to output. bar_stacked --help boolean Show this message and exit. False create-spiked-vcfs Spikes variants into a template VCF file for a directory of phenopackets. Usage: pheval-utils create-spiked-vcfs [OPTIONS] Options: Name Type Description Default --phenopacket-path , -p Path Path to phenopacket. NOTE: This argument is mutually exclusive with arguments: [phenopacket_dir]. None --phenopacket-dir , -P Path Path to phenopacket directory for updating. NOTE: This argument is mutually exclusive with arguments: [phenopacket_path]. None --template-vcf-path , -t Path Template VCF file NOTE: This argument is mutually exclusive with arguments: [vcf_dir]. None --vcf-dir , -v Path Directory containing template VCF files NOTE: This argument is mutually exclusive with arguments: [template_vcf]. None --output-dir , -O Path Path for creation of output directory vcf --help boolean Show this message and exit. False scramble-phenopackets Generate noisy phenopackets from existing ones. Usage: pheval-utils scramble-phenopackets [OPTIONS] Options: Name Type Description Default --phenopacket-path , -p Path Path to phenopacket. NOTE: This argument is mutually exclusive with arguments: [phenopacket_dir]. None --phenopacket-dir , -P Path Path to phenopackets directory. NOTE: This argument is mutually exclusive with arguments: [phenopacket_path]. None --scramble-factor , -s float Scramble factor for randomising phenopacket phenotypic profiles. 0.5 --output-dir , -O Path Path for creation of output directory noisy_phenopackets --help boolean Show this message and exit. False semsim-convert convert semsim profile to an exomiser database file Usage: pheval-utils semsim-convert [OPTIONS] Options: Name Type Description Default --input , -i Path Path to the semsim file. _required --output , -o Path Path where converted semsim will be written. _required --subject-prefix , -s text Subject Prefix that will be mapped to the database _required --object-prefix , -b text Object Prefix that will be mapped to the database. _required --output-format , -O choice ( exomiserdb ) Output file format. Available formats: (exomiserdb) _required --help boolean Show this message and exit. False semsim-scramble Scrambles semsim profile multiplying score value by scramble factor Args: input (Path): Path file that points out to the semsim profile output (Path): Path file that points out to the output file score_column (List[str]): Score column(s) that will be scrambled scramble_factor (float): Scramble Magnitude Usage: pheval-utils semsim-scramble [OPTIONS] Options: Name Type Description Default --input , -i Path Path to the semantic similarity profile to be scrambled. _required --output , -o Path Path where the scrambled semsim file will be written. _required --score-column , -c choice ( jaccard_similarity | dice_similarity | phenodigm_score ) Score column that will be scrambled _required --scramble-factor , -s float Scramble Magnitude (noise) that will be applied to semantic similarity score column (e.g. jaccard similarity). 0.5 --help boolean Show this message and exit. False update-phenopackets Update gene symbols and identifiers for phenopackets. Usage: pheval-utils update-phenopackets [OPTIONS] Options: Name Type Description Default --phenopacket-path , -p Path Path to phenopacket. NOTE: This argument is mutually exclusive with arguments: [phenopacket_dir]. None --phenopacket-dir , -P Path Path to phenopacket directory for updating. NOTE: This argument is mutually exclusive with arguments: [phenopacket_path]. None --output-dir , -o Path Path to write phenopacket. _required --gene-identifier , -g choice ( ensembl_id | entrez_id | hgnc_id ) Gene identifier to add to phenopacket ensembl_id --help boolean Show this message and exit. False","title":"Cli"},{"location":"api/pheval/cli/#main","text":"main CLI method for PhEval Args: verbose (int, optional): Verbose flag. quiet (bool, optional): Queit Flag. Usage: main [OPTIONS] COMMAND [ARGS]... Options: Name Type Description Default -v , --verbose integer range ( 0 and above) N/A 0 -q , --quiet text N/A None --help boolean Show this message and exit. False","title":"main"},{"location":"api/pheval/cli/#pheval","text":"pheval Usage: pheval [OPTIONS] COMMAND [ARGS]... Options: Name Type Description Default --help boolean Show this message and exit. False Subcommands run : PhEval Runner Command Line Interface","title":"pheval"},{"location":"api/pheval/cli/#run","text":"PhEval Runner Command Line Interface Args: input_dir (Path): The input directory (relative path: e.g exomiser-13.11) testdata_dir (Path): The input directory (relative path: e.g ./data runner (str): Runner implementation (e.g exomiser-13.11) tmp_dir (Path): The path of the temporary directory (optional) output_dir (Path): The path of the output directory config (Path): The path of the configuration file (optional e.g., config.yaml) version (str): The version of the tool implementation Usage: pheval run [OPTIONS] Options: Name Type Description Default --input-dir , -i Path The input directory (relative path: e.g exomiser-13.11) _required --testdata-dir , -t Path The input directory (relative path: e.g ./data) _required --runner , -r text Runner implementation (e.g exomiser-13.11) _required --tmp-dir , -m Path The path of the temporary directory (optional) None --output-dir , -o Path The path of the output directory _required --config , -c Path The path of the configuration file (optional e.g config.yaml) None --version , -v text Version of the tool implementation. None --help boolean Show this message and exit. False","title":"run"},{"location":"api/pheval/cli/#pheval-utils","text":"pheval_utils Usage: pheval-utils [OPTIONS] COMMAND [ARGS]... Options: Name Type Description Default --help boolean Show this message and exit. False Subcommands benchmark : Benchmark the gene/variant prioritisation performance for a single run. benchmark-comparison : Benchmark the gene/variant prioritisation performance for two runs. create-spiked-vcfs : Spikes variants into a template VCF file for a directory of phenopackets. scramble-phenopackets : Generate noisy phenopackets from existing ones. semsim-convert : convert semsim profile to an exomiser database file semsim-scramble : Scrambles semsim profile multiplying score value by scramble factor update-phenopackets : Update gene symbols and identifiers for phenopackets.","title":"pheval-utils"},{"location":"api/pheval/cli/#benchmark","text":"Benchmark the gene/variant prioritisation performance for a single run. Usage: pheval-utils benchmark [OPTIONS] Options: Name Type Description Default --directory , -d Path General results directory to be benchmarked, assumes contains subdirectories of pheval_gene_results/pheval_variant_results and the tool specific results directory. _required --phenopacket-dir , -p Path Full path to directory containing input phenopackets. _required --output-prefix , -o text Output file prefix. _required --score-order , -so choice ( ascending | descending ) Ordering of results for ranking. descending --threshold , -t float Score threshold. 0.0 --gene-analysis / --no-gene-analysis boolean Specify analysis for gene prioritisation False --variant-analysis / --no-variant-analysis boolean Specify analysis for variant prioritisation False --plot-type , -p choice ( bar_stacked | bar_cumulative | bar_non_cumulative ) Bar chart type to output. bar_stacked --help boolean Show this message and exit. False","title":"benchmark"},{"location":"api/pheval/cli/#benchmark-comparison","text":"Benchmark the gene/variant prioritisation performance for two runs. Usage: pheval-utils benchmark-comparison [OPTIONS] Options: Name Type Description Default --run-data , -r Path Path to .txt file containing testdata directory and corresponding results directory separated by tab.Each run contained to a new line with the input testdata listed first and on the same line separated by a tabthe results directory. _required --output-prefix , -o text Output file prefix. _required --score-order , -so choice ( ascending | descending ) Ordering of results for ranking. descending --threshold , -t float Score threshold. 0.0 --gene-analysis / --no-gene-analysis boolean Specify analysis for gene prioritisation False --variant-analysis / --no-variant-analysis boolean Specify analysis for variant prioritisation False --plot-type , -p choice ( bar_stacked | bar_cumulative | bar_non_cumulative ) Bar chart type to output. bar_stacked --help boolean Show this message and exit. False","title":"benchmark-comparison"},{"location":"api/pheval/cli/#create-spiked-vcfs","text":"Spikes variants into a template VCF file for a directory of phenopackets. Usage: pheval-utils create-spiked-vcfs [OPTIONS] Options: Name Type Description Default --phenopacket-path , -p Path Path to phenopacket. NOTE: This argument is mutually exclusive with arguments: [phenopacket_dir]. None --phenopacket-dir , -P Path Path to phenopacket directory for updating. NOTE: This argument is mutually exclusive with arguments: [phenopacket_path]. None --template-vcf-path , -t Path Template VCF file NOTE: This argument is mutually exclusive with arguments: [vcf_dir]. None --vcf-dir , -v Path Directory containing template VCF files NOTE: This argument is mutually exclusive with arguments: [template_vcf]. None --output-dir , -O Path Path for creation of output directory vcf --help boolean Show this message and exit. False","title":"create-spiked-vcfs"},{"location":"api/pheval/cli/#scramble-phenopackets","text":"Generate noisy phenopackets from existing ones. Usage: pheval-utils scramble-phenopackets [OPTIONS] Options: Name Type Description Default --phenopacket-path , -p Path Path to phenopacket. NOTE: This argument is mutually exclusive with arguments: [phenopacket_dir]. None --phenopacket-dir , -P Path Path to phenopackets directory. NOTE: This argument is mutually exclusive with arguments: [phenopacket_path]. None --scramble-factor , -s float Scramble factor for randomising phenopacket phenotypic profiles. 0.5 --output-dir , -O Path Path for creation of output directory noisy_phenopackets --help boolean Show this message and exit. False","title":"scramble-phenopackets"},{"location":"api/pheval/cli/#semsim-convert","text":"convert semsim profile to an exomiser database file Usage: pheval-utils semsim-convert [OPTIONS] Options: Name Type Description Default --input , -i Path Path to the semsim file. _required --output , -o Path Path where converted semsim will be written. _required --subject-prefix , -s text Subject Prefix that will be mapped to the database _required --object-prefix , -b text Object Prefix that will be mapped to the database. _required --output-format , -O choice ( exomiserdb ) Output file format. Available formats: (exomiserdb) _required --help boolean Show this message and exit. False","title":"semsim-convert"},{"location":"api/pheval/cli/#semsim-scramble","text":"Scrambles semsim profile multiplying score value by scramble factor Args: input (Path): Path file that points out to the semsim profile output (Path): Path file that points out to the output file score_column (List[str]): Score column(s) that will be scrambled scramble_factor (float): Scramble Magnitude Usage: pheval-utils semsim-scramble [OPTIONS] Options: Name Type Description Default --input , -i Path Path to the semantic similarity profile to be scrambled. _required --output , -o Path Path where the scrambled semsim file will be written. _required --score-column , -c choice ( jaccard_similarity | dice_similarity | phenodigm_score ) Score column that will be scrambled _required --scramble-factor , -s float Scramble Magnitude (noise) that will be applied to semantic similarity score column (e.g. jaccard similarity). 0.5 --help boolean Show this message and exit. False","title":"semsim-scramble"},{"location":"api/pheval/cli/#update-phenopackets","text":"Update gene symbols and identifiers for phenopackets. Usage: pheval-utils update-phenopackets [OPTIONS] Options: Name Type Description Default --phenopacket-path , -p Path Path to phenopacket. NOTE: This argument is mutually exclusive with arguments: [phenopacket_dir]. None --phenopacket-dir , -P Path Path to phenopacket directory for updating. NOTE: This argument is mutually exclusive with arguments: [phenopacket_path]. None --output-dir , -o Path Path to write phenopacket. _required --gene-identifier , -g choice ( ensembl_id | entrez_id | hgnc_id ) Gene identifier to add to phenopacket ensembl_id --help boolean Show this message and exit. False","title":"update-phenopackets"},{"location":"api/pheval/config_parser/","text":"InputDirConfig dataclass Class for defining the fields within the input directory config. Parameters: Name Type Description Default tool str Name of the tool implementation (e.g. exomiser/phen2gene) required tool_version str Version of the tool implementation required phenotype_only bool Whether the tool is run with HPO terms only (True) or with variant data (False) required tool_specific_configuration_options Any Tool specific configurations required Source code in src/pheval/config_parser.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @serde @dataclass class InputDirConfig : \"\"\" Class for defining the fields within the input directory config. Args: tool (str): Name of the tool implementation (e.g. exomiser/phen2gene) tool_version (str): Version of the tool implementation phenotype_only (bool): Whether the tool is run with HPO terms only (True) or with variant data (False) tool_specific_configuration_options (Any): Tool specific configurations \"\"\" tool : str tool_version : str phenotype_only : bool tool_specific_configuration_options : Any parse_input_dir_config ( input_dir ) Reads the config file. Source code in src/pheval/config_parser.py 31 32 33 34 35 36 def parse_input_dir_config ( input_dir : Path ) -> InputDirConfig : \"\"\"Reads the config file.\"\"\" with open ( Path ( input_dir ) . joinpath ( \"config.yaml\" ), \"r\" ) as config_file : config = yaml . safe_load ( config_file ) config_file . close () return from_yaml ( InputDirConfig , yaml . dump ( config ))","title":"Config parser"},{"location":"api/pheval/config_parser/#src.pheval.config_parser.InputDirConfig","text":"Class for defining the fields within the input directory config. Parameters: Name Type Description Default tool str Name of the tool implementation (e.g. exomiser/phen2gene) required tool_version str Version of the tool implementation required phenotype_only bool Whether the tool is run with HPO terms only (True) or with variant data (False) required tool_specific_configuration_options Any Tool specific configurations required Source code in src/pheval/config_parser.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @serde @dataclass class InputDirConfig : \"\"\" Class for defining the fields within the input directory config. Args: tool (str): Name of the tool implementation (e.g. exomiser/phen2gene) tool_version (str): Version of the tool implementation phenotype_only (bool): Whether the tool is run with HPO terms only (True) or with variant data (False) tool_specific_configuration_options (Any): Tool specific configurations \"\"\" tool : str tool_version : str phenotype_only : bool tool_specific_configuration_options : Any","title":"InputDirConfig"},{"location":"api/pheval/config_parser/#src.pheval.config_parser.parse_input_dir_config","text":"Reads the config file. Source code in src/pheval/config_parser.py 31 32 33 34 35 36 def parse_input_dir_config ( input_dir : Path ) -> InputDirConfig : \"\"\"Reads the config file.\"\"\" with open ( Path ( input_dir ) . joinpath ( \"config.yaml\" ), \"r\" ) as config_file : config = yaml . safe_load ( config_file ) config_file . close () return from_yaml ( InputDirConfig , yaml . dump ( config ))","title":"parse_input_dir_config()"},{"location":"api/pheval/constants/","text":"","title":"Constants"},{"location":"api/pheval/run_metadata/","text":"BasicOutputRunMetaData dataclass Class for defining variables for the run metadata. Parameters: Name Type Description Default tool str Name of the tool implementation required tool_version str Version of the tool implementation required config Path Path to the config file located in the input directory required run_timestamp int Time taken for run to complete required corpus Path Path to corpus used in pheval run required tool_specific_configuration_options Any Special field that can be overwritten by tool implementations to contain any extra tool specific configurations used in the run None Source code in src/pheval/run_metadata.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 @serde @dataclass class BasicOutputRunMetaData : \"\"\"Class for defining variables for the run metadata. Args: tool (str): Name of the tool implementation tool_version (str): Version of the tool implementation config (Path): Path to the config file located in the input directory run_timestamp (int): Time taken for run to complete corpus (Path): Path to corpus used in pheval run tool_specific_configuration_options (Any): Special field that can be overwritten by tool implementations to contain any extra tool specific configurations used in the run \"\"\" tool : str tool_version : str config : Path run_timestamp : int corpus : Path tool_specific_configuration_options : Any = None","title":"Run metadata"},{"location":"api/pheval/run_metadata/#src.pheval.run_metadata.BasicOutputRunMetaData","text":"Class for defining variables for the run metadata. Parameters: Name Type Description Default tool str Name of the tool implementation required tool_version str Version of the tool implementation required config Path Path to the config file located in the input directory required run_timestamp int Time taken for run to complete required corpus Path Path to corpus used in pheval run required tool_specific_configuration_options Any Special field that can be overwritten by tool implementations to contain any extra tool specific configurations used in the run None Source code in src/pheval/run_metadata.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 @serde @dataclass class BasicOutputRunMetaData : \"\"\"Class for defining variables for the run metadata. Args: tool (str): Name of the tool implementation tool_version (str): Version of the tool implementation config (Path): Path to the config file located in the input directory run_timestamp (int): Time taken for run to complete corpus (Path): Path to corpus used in pheval run tool_specific_configuration_options (Any): Special field that can be overwritten by tool implementations to contain any extra tool specific configurations used in the run \"\"\" tool : str tool_version : str config : Path run_timestamp : int corpus : Path tool_specific_configuration_options : Any = None","title":"BasicOutputRunMetaData"},{"location":"api/pheval/analyse/analysis/","text":"AssessGenePrioritisation Assess gene prioritisation. Source code in src/pheval/analyse/analysis.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 class AssessGenePrioritisation : \"\"\"Assess gene prioritisation.\"\"\" def __init__ ( self , phenopacket_path : Path , results_dir : Path , standardised_gene_results : [ RankedPhEvalGeneResult ], threshold : float , score_order : str , proband_causative_genes : [ ProbandCausativeGene ], ): self . phenopacket_path = phenopacket_path self . results_dir = results_dir self . standardised_gene_results = standardised_gene_results self . threshold = threshold self . score_order = score_order self . proband_causative_genes = proband_causative_genes def _record_gene_prioritisation_match ( self , gene : ProbandCausativeGene , result_entry : RankedPhEvalGeneResult , rank_stats : RankStats , ) -> GenePrioritisationResult : \"\"\"Record the gene prioritisation rank if found within results.\"\"\" rank = result_entry . rank rank_stats . add_rank ( rank ) return GenePrioritisationResult ( self . phenopacket_path , gene . gene_symbol , rank ) def _assess_gene_with_threshold_ascending_order ( self , result_entry : RankedPhEvalGeneResult , gene : ProbandCausativeGene , rank_stats : RankStats , ) -> GenePrioritisationResult : \"\"\"Record the gene prioritisation rank if it meets the ascending order threshold.\"\"\" if float ( self . threshold ) > float ( result_entry . pheval_gene_result . score ): return self . _record_gene_prioritisation_match ( gene , result_entry , rank_stats ) def _assess_gene_with_threshold ( self , result_entry : RankedPhEvalGeneResult , gene : ProbandCausativeGene , rank_stats : RankStats , ) -> GenePrioritisationResult : \"\"\"Record the gene prioritisation rank if it meets the score threshold.\"\"\" if float ( self . threshold ) < float ( result_entry . pheval_gene_result . score ): return self . _record_gene_prioritisation_match ( gene , result_entry , rank_stats ) def _record_matched_gene ( self , gene : ProbandCausativeGene , rank_stats : RankStats , standardised_gene_result : pd . Series ) -> GenePrioritisationResult : \"\"\"Return the gene rank result - dealing with the specification of a threshold.\"\"\" if float ( self . threshold ) == 0.0 : return self . _record_gene_prioritisation_match ( gene , standardised_gene_result , rank_stats ) else : return ( self . _assess_gene_with_threshold ( standardised_gene_result , gene , rank_stats ) if self . score_order != \"ascending\" else self . _assess_gene_with_threshold_ascending_order ( standardised_gene_result , gene , rank_stats ) ) def assess_gene_prioritisation ( self , rank_stats : RankStats , rank_records : defaultdict ) -> None : \"\"\"Assess gene prioritisation.\"\"\" for gene in self . proband_causative_genes : rank_stats . total += 1 gene_match = GenePrioritisationResult ( self . phenopacket_path , gene . gene_symbol ) for standardised_gene_result in self . standardised_gene_results : if ( gene . gene_identifier == standardised_gene_result . pheval_gene_result . gene_identifier or gene . gene_symbol == standardised_gene_result . pheval_gene_result . gene_identifier ): gene_match = self . _record_matched_gene ( gene , rank_stats , standardised_gene_result ) break PrioritisationRankRecorder ( rank_stats . total , self . results_dir , GenePrioritisationResult ( self . phenopacket_path , gene . gene_symbol ) if gene_match is None else gene_match , rank_records , ) . record_rank () assess_gene_prioritisation ( rank_stats , rank_records ) Assess gene prioritisation. Source code in src/pheval/analyse/analysis.py 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 def assess_gene_prioritisation ( self , rank_stats : RankStats , rank_records : defaultdict ) -> None : \"\"\"Assess gene prioritisation.\"\"\" for gene in self . proband_causative_genes : rank_stats . total += 1 gene_match = GenePrioritisationResult ( self . phenopacket_path , gene . gene_symbol ) for standardised_gene_result in self . standardised_gene_results : if ( gene . gene_identifier == standardised_gene_result . pheval_gene_result . gene_identifier or gene . gene_symbol == standardised_gene_result . pheval_gene_result . gene_identifier ): gene_match = self . _record_matched_gene ( gene , rank_stats , standardised_gene_result ) break PrioritisationRankRecorder ( rank_stats . total , self . results_dir , GenePrioritisationResult ( self . phenopacket_path , gene . gene_symbol ) if gene_match is None else gene_match , rank_records , ) . record_rank () AssessVariantPrioritisation Assess variant prioritisation. Source code in src/pheval/analyse/analysis.py 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 class AssessVariantPrioritisation : \"\"\"Assess variant prioritisation.\"\"\" def __init__ ( self , phenopacket_path : Path , results_dir : Path , standardised_variant_results : [ RankedPhEvalVariantResult ], threshold : float , score_order : str , proband_causative_variants : [ GenomicVariant ], ): self . phenopacket_path = phenopacket_path self . results_dir = results_dir self . standardised_variant_results = standardised_variant_results self . threshold = threshold self . score_order = score_order self . proband_causative_variants = proband_causative_variants def _record_variant_prioritisation_match ( self , result_entry : RankedPhEvalVariantResult , rank_stats : RankStats , ) -> VariantPrioritisationResult : \"\"\"Record the variant prioritisation rank if found within results.\"\"\" rank = result_entry . rank rank_stats . add_rank ( rank ) return VariantPrioritisationResult ( self . phenopacket_path , GenomicVariant ( chrom = result_entry . pheval_variant_result . chromosome , pos = result_entry . pheval_variant_result . start , ref = result_entry . pheval_variant_result . ref , alt = result_entry . pheval_variant_result . alt , ), rank , ) def _assess_variant_with_threshold_ascending_order ( self , result_entry : RankedPhEvalVariantResult , rank_stats : RankStats ) -> VariantPrioritisationResult : \"\"\"Record the variant prioritisation rank if it meets the ascending order threshold.\"\"\" if float ( self . threshold ) > float ( result_entry . pheval_variant_result . score ): return self . _record_variant_prioritisation_match ( result_entry , rank_stats ) def _assess_variant_with_threshold ( self , result_entry : pd . Series , rank_stats : RankStats ) -> VariantPrioritisationResult : \"\"\"Record the variant prioritisation rank if it meets the score threshold.\"\"\" if float ( self . threshold ) < float ( result_entry . pheval_variant_result . score ): return self . _record_variant_prioritisation_match ( result_entry , rank_stats ) def _record_matched_variant ( self , rank_stats : RankStats , standardised_variant_result : pd . Series ) -> VariantPrioritisationResult : \"\"\"Return the variant rank result - dealing with the specification of a threshold.\"\"\" if float ( self . threshold ) == 0.0 : return self . _record_variant_prioritisation_match ( standardised_variant_result , rank_stats ) else : return ( self . _assess_variant_with_threshold ( standardised_variant_result , rank_stats ) if self . score_order != \"ascending\" else self . _assess_variant_with_threshold_ascending_order ( standardised_variant_result , rank_stats ) ) def assess_variant_prioritisation ( self , rank_stats : RankStats , rank_records : defaultdict ) -> None : \"\"\"Assess variant prioritisation.\"\"\" for variant in self . proband_causative_variants : rank_stats . total += 1 variant_match = VariantPrioritisationResult ( self . phenopacket_path , variant ) for result in self . standardised_variant_results : result_variant = GenomicVariant ( chrom = result . pheval_variant_result . chromosome , pos = result . pheval_variant_result . start , ref = result . pheval_variant_result . ref , alt = result . pheval_variant_result . alt , ) if variant == result_variant : variant_match = self . _record_matched_variant ( rank_stats , result ) break PrioritisationRankRecorder ( rank_stats . total , self . results_dir , VariantPrioritisationResult ( self . phenopacket_path , variant ) if variant_match is None else variant_match , rank_records , ) . record_rank () assess_variant_prioritisation ( rank_stats , rank_records ) Assess variant prioritisation. Source code in src/pheval/analyse/analysis.py 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 def assess_variant_prioritisation ( self , rank_stats : RankStats , rank_records : defaultdict ) -> None : \"\"\"Assess variant prioritisation.\"\"\" for variant in self . proband_causative_variants : rank_stats . total += 1 variant_match = VariantPrioritisationResult ( self . phenopacket_path , variant ) for result in self . standardised_variant_results : result_variant = GenomicVariant ( chrom = result . pheval_variant_result . chromosome , pos = result . pheval_variant_result . start , ref = result . pheval_variant_result . ref , alt = result . pheval_variant_result . alt , ) if variant == result_variant : variant_match = self . _record_matched_variant ( rank_stats , result ) break PrioritisationRankRecorder ( rank_stats . total , self . results_dir , VariantPrioritisationResult ( self . phenopacket_path , variant ) if variant_match is None else variant_match , rank_records , ) . record_rank () GenePrioritisationResult dataclass Store rank data for causative genes. Source code in src/pheval/analyse/analysis.py 80 81 82 83 84 85 86 @dataclass class GenePrioritisationResult : \"\"\"Store rank data for causative genes.\"\"\" phenopacket_path : Path gene : str rank : int = 0 PrioritisationRankRecorder dataclass Compare the ranks of different runs. Source code in src/pheval/analyse/analysis.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 @dataclass class PrioritisationRankRecorder : \"\"\"Compare the ranks of different runs.\"\"\" index : int directory : Path prioritisation_result : VariantPrioritisationResult or GenePrioritisationResult run_comparison : defaultdict def _record_gene_rank ( self ) -> None : \"\"\"Record gene prioritisation rank.\"\"\" self . run_comparison [ self . index ][ \"Gene\" ] = self . prioritisation_result . gene def _record_variant_rank ( self ) -> None : \"\"\"Record variant prioritisation rank.\"\"\" variant = self . prioritisation_result . variant self . run_comparison [ self . index ][ \"Variant\" ] = \"_\" . join ( [ variant . chrom , str ( variant . pos ), variant . ref , variant . alt ] ) def record_rank ( self ) -> None : \"\"\"Records the rank for different runs.\"\"\" self . run_comparison [ self . index ][ \"Phenopacket\" ] = self . prioritisation_result . phenopacket_path . name self . _record_gene_rank () if type ( self . prioritisation_result ) is GenePrioritisationResult else self . _record_variant_rank () self . run_comparison [ self . index ][ self . directory ] = self . prioritisation_result . rank record_rank () Records the rank for different runs. Source code in src/pheval/analyse/analysis.py 118 119 120 121 122 123 124 125 126 def record_rank ( self ) -> None : \"\"\"Records the rank for different runs.\"\"\" self . run_comparison [ self . index ][ \"Phenopacket\" ] = self . prioritisation_result . phenopacket_path . name self . _record_gene_rank () if type ( self . prioritisation_result ) is GenePrioritisationResult else self . _record_variant_rank () self . run_comparison [ self . index ][ self . directory ] = self . prioritisation_result . rank TrackInputOutputDirectories dataclass Track the input testdata for a corresponding pheval output directory Source code in src/pheval/analyse/analysis.py 129 130 131 132 133 134 @dataclass class TrackInputOutputDirectories : \"\"\"Track the input testdata for a corresponding pheval output directory\"\"\" phenopacket_dir : Path results_dir : Path VariantPrioritisationResult dataclass Store rank data for causative variants. Source code in src/pheval/analyse/analysis.py 89 90 91 92 93 94 95 @dataclass class VariantPrioritisationResult : \"\"\"Store rank data for causative variants.\"\"\" phenopacket_path : Path variant : GenomicVariant rank : int = 0 benchmark ( directory , phenopacket_dir , score_order , output_prefix , threshold , gene_analysis , variant_analysis , plot_type ) Benchmark the gene/variant prioritisation performance for a single run. Source code in src/pheval/analyse/analysis.py 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 @click . command () @click . option ( \"--directory\" , \"-d\" , required = True , metavar = \"PATH\" , help = \"General results directory to be benchmarked, assumes contains subdirectories of pheval_gene_results/\" \"pheval_variant_results and the tool specific results directory. \" , type = Path , ) @click . option ( \"--phenopacket-dir\" , \"-p\" , required = True , metavar = \"PATH\" , help = \"Full path to directory containing input phenopackets.\" , type = Path , ) @click . option ( \"--output-prefix\" , \"-o\" , metavar = \"<str>\" , required = True , help = \" Output file prefix. \" , ) @click . option ( \"--score-order\" , \"-so\" , required = True , help = \"Ordering of results for ranking.\" , type = click . Choice ([ \"ascending\" , \"descending\" ]), default = \"descending\" , show_default = True , ) @click . option ( \"--threshold\" , \"-t\" , metavar = \"<float>\" , default = float ( 0.0 ), required = False , help = \"Score threshold.\" , type = float , ) @click . option ( \"--gene-analysis/--no-gene-analysis\" , default = False , required = False , type = bool , show_default = True , help = \"Specify analysis for gene prioritisation\" , ) @click . option ( \"--variant-analysis/--no-variant-analysis\" , default = False , required = False , type = bool , show_default = True , help = \"Specify analysis for variant prioritisation\" , ) @click . option ( \"--plot-type\" , \"-p\" , default = \"bar_stacked\" , show_default = True , type = click . Choice ([ \"bar_stacked\" , \"bar_cumulative\" , \"bar_non_cumulative\" ]), help = \"Bar chart type to output.\" , ) def benchmark ( directory : Path , phenopacket_dir : Path , score_order : str , output_prefix : str , threshold : float , gene_analysis : bool , variant_analysis : bool , plot_type : str , ): \"\"\"Benchmark the gene/variant prioritisation performance for a single run.\"\"\" if not gene_analysis and not variant_analysis : raise InputError ( \"Need to specify gene analysis and/or variant analysis.\" ) benchmark_directory ( TrackInputOutputDirectories ( results_dir = directory , phenopacket_dir = phenopacket_dir ), score_order , output_prefix , threshold , gene_analysis , variant_analysis , plot_type , ) benchmark_comparison ( run_data , score_order , output_prefix , threshold , gene_analysis , variant_analysis , plot_type ) Benchmark the gene/variant prioritisation performance for two runs. Source code in src/pheval/analyse/analysis.py 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 @click . command () @click . option ( \"--run-data\" , \"-r\" , required = True , metavar = \"PATH\" , help = \"Path to .txt file containing testdata directory and corresponding results directory separated by tab.\" \"Each run contained to a new line with the input testdata listed first and on the same line separated by a tab\" \"the results directory.\" , type = Path , ) @click . option ( \"--output-prefix\" , \"-o\" , metavar = \"<str>\" , required = True , help = \" Output file prefix. \" , ) @click . option ( \"--score-order\" , \"-so\" , required = True , help = \"Ordering of results for ranking.\" , type = click . Choice ([ \"ascending\" , \"descending\" ]), default = \"descending\" , show_default = True , ) @click . option ( \"--threshold\" , \"-t\" , metavar = \"<float>\" , default = float ( 0.0 ), required = False , help = \"Score threshold.\" , type = float , ) @click . option ( \"--gene-analysis/--no-gene-analysis\" , default = False , required = False , type = bool , show_default = True , help = \"Specify analysis for gene prioritisation\" , ) @click . option ( \"--variant-analysis/--no-variant-analysis\" , default = False , required = False , type = bool , show_default = True , help = \"Specify analysis for variant prioritisation\" , ) @click . option ( \"--plot-type\" , \"-p\" , default = \"bar_stacked\" , show_default = True , type = click . Choice ([ \"bar_stacked\" , \"bar_cumulative\" , \"bar_non_cumulative\" ]), help = \"Bar chart type to output.\" , ) def benchmark_comparison ( run_data : Path , score_order : str , output_prefix : str , threshold : float , gene_analysis : bool , variant_analysis : bool , plot_type : str , ): \"\"\"Benchmark the gene/variant prioritisation performance for two runs.\"\"\" if not gene_analysis and not variant_analysis : raise InputError ( \"Need to specify gene analysis and/or variant analysis.\" ) benchmark_runs ( _parse_run_data_text_file ( run_data ), score_order , output_prefix , threshold , gene_analysis , variant_analysis , plot_type , ) benchmark_directory ( results_dir_and_input , score_order , output_prefix , threshold , gene_analysis , variant_analysis , plot_type ) Benchmark prioritisation performance for a single directory. Source code in src/pheval/analyse/analysis.py 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 def benchmark_directory ( results_dir_and_input : TrackInputOutputDirectories , score_order : str , output_prefix : str , threshold : float , gene_analysis : bool , variant_analysis : bool , plot_type : str , ) -> None : \"\"\"Benchmark prioritisation performance for a single directory.\"\"\" gene_stats_writer = ( RankStatsWriter ( Path ( output_prefix + \"-gene_summary.tsv\" )) if gene_analysis else None ) variants_stats_writer = ( RankStatsWriter ( Path ( output_prefix + \"-variant_summary.tsv\" )) if variant_analysis else None ) gene_rank_comparison , variant_rank_comparison = defaultdict ( dict ), defaultdict ( dict ) prioritisation_data = _assess_prioritisation_for_results_directory ( results_dir_and_input , score_order , threshold , gene_rank_comparison , variant_rank_comparison , gene_stats_writer , variants_stats_writer , gene_analysis , variant_analysis , ) generate_benchmark_gene_output ( prioritisation_data , plot_type ) if gene_analysis else None generate_benchmark_variant_output ( prioritisation_data , plot_type ) if variant_analysis else None gene_stats_writer . close () if gene_analysis else None variants_stats_writer . close () if variant_analysis else None benchmark_runs ( results_directories , score_order , output_prefix , threshold , gene_analysis , variant_analysis , plot_type ) Benchmark several result directories. Source code in src/pheval/analyse/analysis.py 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 def benchmark_runs ( results_directories : [ TrackInputOutputDirectories ], score_order : str , output_prefix : str , threshold : float , gene_analysis : bool , variant_analysis : bool , plot_type : str , ) -> None : \"\"\"Benchmark several result directories.\"\"\" gene_stats_writer = ( RankStatsWriter ( Path ( output_prefix + \"-gene_summary.tsv\" )) if gene_analysis else None ) variants_stats_writer = ( RankStatsWriter ( Path ( output_prefix + \"-variant_summary.tsv\" )) if variant_analysis else None ) prioritisation_stats_for_runs = [] for results_dir_and_input in results_directories : gene_rank_comparison , variant_rank_comparison = defaultdict ( dict ), defaultdict ( dict ) prioritisation_stats = _assess_prioritisation_for_results_directory ( results_dir_and_input , score_order , threshold , gene_rank_comparison , variant_rank_comparison , gene_stats_writer , variants_stats_writer , gene_analysis , variant_analysis , ) prioritisation_stats_for_runs . append ( prioritisation_stats ) generate_benchmark_comparison_gene_output ( prioritisation_stats_for_runs , plot_type ) if gene_analysis else None generate_benchmark_comparison_variant_output ( prioritisation_stats_for_runs , plot_type ) if variant_analysis else None gene_stats_writer . close () if gene_analysis else None variants_stats_writer . close () if variant_analysis else None parse_pheval_gene_result ( pheval_gene_result ) Parse PhEval gene result into RankedPhEvalGeneResult dataclass. Source code in src/pheval/analyse/analysis.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 def parse_pheval_gene_result ( pheval_gene_result : pd . DataFrame ) -> [ RankedPhEvalGeneResult ]: \"\"\"Parse PhEval gene result into RankedPhEvalGeneResult dataclass.\"\"\" ranked_gene_results = [] for _index , result in pheval_gene_result . iterrows (): ranked_gene_results . append ( RankedPhEvalGeneResult ( pheval_gene_result = PhEvalGeneResult ( gene_symbol = result [ \"gene_symbol\" ], gene_identifier = result [ \"gene_identifier\" ], score = result [ \"score\" ], ), rank = result [ \"rank\" ], ) ) return ranked_gene_results parse_pheval_variant_result ( pheval_variant_result ) Parse PhEval variant result into RankedPhEvalVariantResult dataclass. Source code in src/pheval/analyse/analysis.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def parse_pheval_variant_result ( pheval_variant_result : pd . DataFrame ) -> [ RankedPhEvalVariantResult ]: \"\"\"Parse PhEval variant result into RankedPhEvalVariantResult dataclass.\"\"\" ranked_variant_results = [] for _index , result in pheval_variant_result . iterrows (): ranked_variant_results . append ( RankedPhEvalVariantResult ( pheval_variant_result = PhEvalVariantResult ( chromosome = result [ \"chromosome\" ], start = result [ \"start\" ], end = result [ \"end\" ], ref = result [ \"ref\" ], alt = result [ \"alt\" ], score = result [ \"score\" ], ), rank = result [ \"rank\" ], ) ) return ranked_variant_results","title":"Analysis"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.AssessGenePrioritisation","text":"Assess gene prioritisation. Source code in src/pheval/analyse/analysis.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 class AssessGenePrioritisation : \"\"\"Assess gene prioritisation.\"\"\" def __init__ ( self , phenopacket_path : Path , results_dir : Path , standardised_gene_results : [ RankedPhEvalGeneResult ], threshold : float , score_order : str , proband_causative_genes : [ ProbandCausativeGene ], ): self . phenopacket_path = phenopacket_path self . results_dir = results_dir self . standardised_gene_results = standardised_gene_results self . threshold = threshold self . score_order = score_order self . proband_causative_genes = proband_causative_genes def _record_gene_prioritisation_match ( self , gene : ProbandCausativeGene , result_entry : RankedPhEvalGeneResult , rank_stats : RankStats , ) -> GenePrioritisationResult : \"\"\"Record the gene prioritisation rank if found within results.\"\"\" rank = result_entry . rank rank_stats . add_rank ( rank ) return GenePrioritisationResult ( self . phenopacket_path , gene . gene_symbol , rank ) def _assess_gene_with_threshold_ascending_order ( self , result_entry : RankedPhEvalGeneResult , gene : ProbandCausativeGene , rank_stats : RankStats , ) -> GenePrioritisationResult : \"\"\"Record the gene prioritisation rank if it meets the ascending order threshold.\"\"\" if float ( self . threshold ) > float ( result_entry . pheval_gene_result . score ): return self . _record_gene_prioritisation_match ( gene , result_entry , rank_stats ) def _assess_gene_with_threshold ( self , result_entry : RankedPhEvalGeneResult , gene : ProbandCausativeGene , rank_stats : RankStats , ) -> GenePrioritisationResult : \"\"\"Record the gene prioritisation rank if it meets the score threshold.\"\"\" if float ( self . threshold ) < float ( result_entry . pheval_gene_result . score ): return self . _record_gene_prioritisation_match ( gene , result_entry , rank_stats ) def _record_matched_gene ( self , gene : ProbandCausativeGene , rank_stats : RankStats , standardised_gene_result : pd . Series ) -> GenePrioritisationResult : \"\"\"Return the gene rank result - dealing with the specification of a threshold.\"\"\" if float ( self . threshold ) == 0.0 : return self . _record_gene_prioritisation_match ( gene , standardised_gene_result , rank_stats ) else : return ( self . _assess_gene_with_threshold ( standardised_gene_result , gene , rank_stats ) if self . score_order != \"ascending\" else self . _assess_gene_with_threshold_ascending_order ( standardised_gene_result , gene , rank_stats ) ) def assess_gene_prioritisation ( self , rank_stats : RankStats , rank_records : defaultdict ) -> None : \"\"\"Assess gene prioritisation.\"\"\" for gene in self . proband_causative_genes : rank_stats . total += 1 gene_match = GenePrioritisationResult ( self . phenopacket_path , gene . gene_symbol ) for standardised_gene_result in self . standardised_gene_results : if ( gene . gene_identifier == standardised_gene_result . pheval_gene_result . gene_identifier or gene . gene_symbol == standardised_gene_result . pheval_gene_result . gene_identifier ): gene_match = self . _record_matched_gene ( gene , rank_stats , standardised_gene_result ) break PrioritisationRankRecorder ( rank_stats . total , self . results_dir , GenePrioritisationResult ( self . phenopacket_path , gene . gene_symbol ) if gene_match is None else gene_match , rank_records , ) . record_rank ()","title":"AssessGenePrioritisation"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.AssessGenePrioritisation.assess_gene_prioritisation","text":"Assess gene prioritisation. Source code in src/pheval/analyse/analysis.py 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 def assess_gene_prioritisation ( self , rank_stats : RankStats , rank_records : defaultdict ) -> None : \"\"\"Assess gene prioritisation.\"\"\" for gene in self . proband_causative_genes : rank_stats . total += 1 gene_match = GenePrioritisationResult ( self . phenopacket_path , gene . gene_symbol ) for standardised_gene_result in self . standardised_gene_results : if ( gene . gene_identifier == standardised_gene_result . pheval_gene_result . gene_identifier or gene . gene_symbol == standardised_gene_result . pheval_gene_result . gene_identifier ): gene_match = self . _record_matched_gene ( gene , rank_stats , standardised_gene_result ) break PrioritisationRankRecorder ( rank_stats . total , self . results_dir , GenePrioritisationResult ( self . phenopacket_path , gene . gene_symbol ) if gene_match is None else gene_match , rank_records , ) . record_rank ()","title":"assess_gene_prioritisation()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.AssessVariantPrioritisation","text":"Assess variant prioritisation. Source code in src/pheval/analyse/analysis.py 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 class AssessVariantPrioritisation : \"\"\"Assess variant prioritisation.\"\"\" def __init__ ( self , phenopacket_path : Path , results_dir : Path , standardised_variant_results : [ RankedPhEvalVariantResult ], threshold : float , score_order : str , proband_causative_variants : [ GenomicVariant ], ): self . phenopacket_path = phenopacket_path self . results_dir = results_dir self . standardised_variant_results = standardised_variant_results self . threshold = threshold self . score_order = score_order self . proband_causative_variants = proband_causative_variants def _record_variant_prioritisation_match ( self , result_entry : RankedPhEvalVariantResult , rank_stats : RankStats , ) -> VariantPrioritisationResult : \"\"\"Record the variant prioritisation rank if found within results.\"\"\" rank = result_entry . rank rank_stats . add_rank ( rank ) return VariantPrioritisationResult ( self . phenopacket_path , GenomicVariant ( chrom = result_entry . pheval_variant_result . chromosome , pos = result_entry . pheval_variant_result . start , ref = result_entry . pheval_variant_result . ref , alt = result_entry . pheval_variant_result . alt , ), rank , ) def _assess_variant_with_threshold_ascending_order ( self , result_entry : RankedPhEvalVariantResult , rank_stats : RankStats ) -> VariantPrioritisationResult : \"\"\"Record the variant prioritisation rank if it meets the ascending order threshold.\"\"\" if float ( self . threshold ) > float ( result_entry . pheval_variant_result . score ): return self . _record_variant_prioritisation_match ( result_entry , rank_stats ) def _assess_variant_with_threshold ( self , result_entry : pd . Series , rank_stats : RankStats ) -> VariantPrioritisationResult : \"\"\"Record the variant prioritisation rank if it meets the score threshold.\"\"\" if float ( self . threshold ) < float ( result_entry . pheval_variant_result . score ): return self . _record_variant_prioritisation_match ( result_entry , rank_stats ) def _record_matched_variant ( self , rank_stats : RankStats , standardised_variant_result : pd . Series ) -> VariantPrioritisationResult : \"\"\"Return the variant rank result - dealing with the specification of a threshold.\"\"\" if float ( self . threshold ) == 0.0 : return self . _record_variant_prioritisation_match ( standardised_variant_result , rank_stats ) else : return ( self . _assess_variant_with_threshold ( standardised_variant_result , rank_stats ) if self . score_order != \"ascending\" else self . _assess_variant_with_threshold_ascending_order ( standardised_variant_result , rank_stats ) ) def assess_variant_prioritisation ( self , rank_stats : RankStats , rank_records : defaultdict ) -> None : \"\"\"Assess variant prioritisation.\"\"\" for variant in self . proband_causative_variants : rank_stats . total += 1 variant_match = VariantPrioritisationResult ( self . phenopacket_path , variant ) for result in self . standardised_variant_results : result_variant = GenomicVariant ( chrom = result . pheval_variant_result . chromosome , pos = result . pheval_variant_result . start , ref = result . pheval_variant_result . ref , alt = result . pheval_variant_result . alt , ) if variant == result_variant : variant_match = self . _record_matched_variant ( rank_stats , result ) break PrioritisationRankRecorder ( rank_stats . total , self . results_dir , VariantPrioritisationResult ( self . phenopacket_path , variant ) if variant_match is None else variant_match , rank_records , ) . record_rank ()","title":"AssessVariantPrioritisation"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.AssessVariantPrioritisation.assess_variant_prioritisation","text":"Assess variant prioritisation. Source code in src/pheval/analyse/analysis.py 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 def assess_variant_prioritisation ( self , rank_stats : RankStats , rank_records : defaultdict ) -> None : \"\"\"Assess variant prioritisation.\"\"\" for variant in self . proband_causative_variants : rank_stats . total += 1 variant_match = VariantPrioritisationResult ( self . phenopacket_path , variant ) for result in self . standardised_variant_results : result_variant = GenomicVariant ( chrom = result . pheval_variant_result . chromosome , pos = result . pheval_variant_result . start , ref = result . pheval_variant_result . ref , alt = result . pheval_variant_result . alt , ) if variant == result_variant : variant_match = self . _record_matched_variant ( rank_stats , result ) break PrioritisationRankRecorder ( rank_stats . total , self . results_dir , VariantPrioritisationResult ( self . phenopacket_path , variant ) if variant_match is None else variant_match , rank_records , ) . record_rank ()","title":"assess_variant_prioritisation()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.GenePrioritisationResult","text":"Store rank data for causative genes. Source code in src/pheval/analyse/analysis.py 80 81 82 83 84 85 86 @dataclass class GenePrioritisationResult : \"\"\"Store rank data for causative genes.\"\"\" phenopacket_path : Path gene : str rank : int = 0","title":"GenePrioritisationResult"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.PrioritisationRankRecorder","text":"Compare the ranks of different runs. Source code in src/pheval/analyse/analysis.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 @dataclass class PrioritisationRankRecorder : \"\"\"Compare the ranks of different runs.\"\"\" index : int directory : Path prioritisation_result : VariantPrioritisationResult or GenePrioritisationResult run_comparison : defaultdict def _record_gene_rank ( self ) -> None : \"\"\"Record gene prioritisation rank.\"\"\" self . run_comparison [ self . index ][ \"Gene\" ] = self . prioritisation_result . gene def _record_variant_rank ( self ) -> None : \"\"\"Record variant prioritisation rank.\"\"\" variant = self . prioritisation_result . variant self . run_comparison [ self . index ][ \"Variant\" ] = \"_\" . join ( [ variant . chrom , str ( variant . pos ), variant . ref , variant . alt ] ) def record_rank ( self ) -> None : \"\"\"Records the rank for different runs.\"\"\" self . run_comparison [ self . index ][ \"Phenopacket\" ] = self . prioritisation_result . phenopacket_path . name self . _record_gene_rank () if type ( self . prioritisation_result ) is GenePrioritisationResult else self . _record_variant_rank () self . run_comparison [ self . index ][ self . directory ] = self . prioritisation_result . rank","title":"PrioritisationRankRecorder"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.PrioritisationRankRecorder.record_rank","text":"Records the rank for different runs. Source code in src/pheval/analyse/analysis.py 118 119 120 121 122 123 124 125 126 def record_rank ( self ) -> None : \"\"\"Records the rank for different runs.\"\"\" self . run_comparison [ self . index ][ \"Phenopacket\" ] = self . prioritisation_result . phenopacket_path . name self . _record_gene_rank () if type ( self . prioritisation_result ) is GenePrioritisationResult else self . _record_variant_rank () self . run_comparison [ self . index ][ self . directory ] = self . prioritisation_result . rank","title":"record_rank()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.TrackInputOutputDirectories","text":"Track the input testdata for a corresponding pheval output directory Source code in src/pheval/analyse/analysis.py 129 130 131 132 133 134 @dataclass class TrackInputOutputDirectories : \"\"\"Track the input testdata for a corresponding pheval output directory\"\"\" phenopacket_dir : Path results_dir : Path","title":"TrackInputOutputDirectories"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.VariantPrioritisationResult","text":"Store rank data for causative variants. Source code in src/pheval/analyse/analysis.py 89 90 91 92 93 94 95 @dataclass class VariantPrioritisationResult : \"\"\"Store rank data for causative variants.\"\"\" phenopacket_path : Path variant : GenomicVariant rank : int = 0","title":"VariantPrioritisationResult"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.benchmark","text":"Benchmark the gene/variant prioritisation performance for a single run. Source code in src/pheval/analyse/analysis.py 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 @click . command () @click . option ( \"--directory\" , \"-d\" , required = True , metavar = \"PATH\" , help = \"General results directory to be benchmarked, assumes contains subdirectories of pheval_gene_results/\" \"pheval_variant_results and the tool specific results directory. \" , type = Path , ) @click . option ( \"--phenopacket-dir\" , \"-p\" , required = True , metavar = \"PATH\" , help = \"Full path to directory containing input phenopackets.\" , type = Path , ) @click . option ( \"--output-prefix\" , \"-o\" , metavar = \"<str>\" , required = True , help = \" Output file prefix. \" , ) @click . option ( \"--score-order\" , \"-so\" , required = True , help = \"Ordering of results for ranking.\" , type = click . Choice ([ \"ascending\" , \"descending\" ]), default = \"descending\" , show_default = True , ) @click . option ( \"--threshold\" , \"-t\" , metavar = \"<float>\" , default = float ( 0.0 ), required = False , help = \"Score threshold.\" , type = float , ) @click . option ( \"--gene-analysis/--no-gene-analysis\" , default = False , required = False , type = bool , show_default = True , help = \"Specify analysis for gene prioritisation\" , ) @click . option ( \"--variant-analysis/--no-variant-analysis\" , default = False , required = False , type = bool , show_default = True , help = \"Specify analysis for variant prioritisation\" , ) @click . option ( \"--plot-type\" , \"-p\" , default = \"bar_stacked\" , show_default = True , type = click . Choice ([ \"bar_stacked\" , \"bar_cumulative\" , \"bar_non_cumulative\" ]), help = \"Bar chart type to output.\" , ) def benchmark ( directory : Path , phenopacket_dir : Path , score_order : str , output_prefix : str , threshold : float , gene_analysis : bool , variant_analysis : bool , plot_type : str , ): \"\"\"Benchmark the gene/variant prioritisation performance for a single run.\"\"\" if not gene_analysis and not variant_analysis : raise InputError ( \"Need to specify gene analysis and/or variant analysis.\" ) benchmark_directory ( TrackInputOutputDirectories ( results_dir = directory , phenopacket_dir = phenopacket_dir ), score_order , output_prefix , threshold , gene_analysis , variant_analysis , plot_type , )","title":"benchmark()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.benchmark_comparison","text":"Benchmark the gene/variant prioritisation performance for two runs. Source code in src/pheval/analyse/analysis.py 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 @click . command () @click . option ( \"--run-data\" , \"-r\" , required = True , metavar = \"PATH\" , help = \"Path to .txt file containing testdata directory and corresponding results directory separated by tab.\" \"Each run contained to a new line with the input testdata listed first and on the same line separated by a tab\" \"the results directory.\" , type = Path , ) @click . option ( \"--output-prefix\" , \"-o\" , metavar = \"<str>\" , required = True , help = \" Output file prefix. \" , ) @click . option ( \"--score-order\" , \"-so\" , required = True , help = \"Ordering of results for ranking.\" , type = click . Choice ([ \"ascending\" , \"descending\" ]), default = \"descending\" , show_default = True , ) @click . option ( \"--threshold\" , \"-t\" , metavar = \"<float>\" , default = float ( 0.0 ), required = False , help = \"Score threshold.\" , type = float , ) @click . option ( \"--gene-analysis/--no-gene-analysis\" , default = False , required = False , type = bool , show_default = True , help = \"Specify analysis for gene prioritisation\" , ) @click . option ( \"--variant-analysis/--no-variant-analysis\" , default = False , required = False , type = bool , show_default = True , help = \"Specify analysis for variant prioritisation\" , ) @click . option ( \"--plot-type\" , \"-p\" , default = \"bar_stacked\" , show_default = True , type = click . Choice ([ \"bar_stacked\" , \"bar_cumulative\" , \"bar_non_cumulative\" ]), help = \"Bar chart type to output.\" , ) def benchmark_comparison ( run_data : Path , score_order : str , output_prefix : str , threshold : float , gene_analysis : bool , variant_analysis : bool , plot_type : str , ): \"\"\"Benchmark the gene/variant prioritisation performance for two runs.\"\"\" if not gene_analysis and not variant_analysis : raise InputError ( \"Need to specify gene analysis and/or variant analysis.\" ) benchmark_runs ( _parse_run_data_text_file ( run_data ), score_order , output_prefix , threshold , gene_analysis , variant_analysis , plot_type , )","title":"benchmark_comparison()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.benchmark_directory","text":"Benchmark prioritisation performance for a single directory. Source code in src/pheval/analyse/analysis.py 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 def benchmark_directory ( results_dir_and_input : TrackInputOutputDirectories , score_order : str , output_prefix : str , threshold : float , gene_analysis : bool , variant_analysis : bool , plot_type : str , ) -> None : \"\"\"Benchmark prioritisation performance for a single directory.\"\"\" gene_stats_writer = ( RankStatsWriter ( Path ( output_prefix + \"-gene_summary.tsv\" )) if gene_analysis else None ) variants_stats_writer = ( RankStatsWriter ( Path ( output_prefix + \"-variant_summary.tsv\" )) if variant_analysis else None ) gene_rank_comparison , variant_rank_comparison = defaultdict ( dict ), defaultdict ( dict ) prioritisation_data = _assess_prioritisation_for_results_directory ( results_dir_and_input , score_order , threshold , gene_rank_comparison , variant_rank_comparison , gene_stats_writer , variants_stats_writer , gene_analysis , variant_analysis , ) generate_benchmark_gene_output ( prioritisation_data , plot_type ) if gene_analysis else None generate_benchmark_variant_output ( prioritisation_data , plot_type ) if variant_analysis else None gene_stats_writer . close () if gene_analysis else None variants_stats_writer . close () if variant_analysis else None","title":"benchmark_directory()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.benchmark_runs","text":"Benchmark several result directories. Source code in src/pheval/analyse/analysis.py 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 def benchmark_runs ( results_directories : [ TrackInputOutputDirectories ], score_order : str , output_prefix : str , threshold : float , gene_analysis : bool , variant_analysis : bool , plot_type : str , ) -> None : \"\"\"Benchmark several result directories.\"\"\" gene_stats_writer = ( RankStatsWriter ( Path ( output_prefix + \"-gene_summary.tsv\" )) if gene_analysis else None ) variants_stats_writer = ( RankStatsWriter ( Path ( output_prefix + \"-variant_summary.tsv\" )) if variant_analysis else None ) prioritisation_stats_for_runs = [] for results_dir_and_input in results_directories : gene_rank_comparison , variant_rank_comparison = defaultdict ( dict ), defaultdict ( dict ) prioritisation_stats = _assess_prioritisation_for_results_directory ( results_dir_and_input , score_order , threshold , gene_rank_comparison , variant_rank_comparison , gene_stats_writer , variants_stats_writer , gene_analysis , variant_analysis , ) prioritisation_stats_for_runs . append ( prioritisation_stats ) generate_benchmark_comparison_gene_output ( prioritisation_stats_for_runs , plot_type ) if gene_analysis else None generate_benchmark_comparison_variant_output ( prioritisation_stats_for_runs , plot_type ) if variant_analysis else None gene_stats_writer . close () if gene_analysis else None variants_stats_writer . close () if variant_analysis else None","title":"benchmark_runs()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.parse_pheval_gene_result","text":"Parse PhEval gene result into RankedPhEvalGeneResult dataclass. Source code in src/pheval/analyse/analysis.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 def parse_pheval_gene_result ( pheval_gene_result : pd . DataFrame ) -> [ RankedPhEvalGeneResult ]: \"\"\"Parse PhEval gene result into RankedPhEvalGeneResult dataclass.\"\"\" ranked_gene_results = [] for _index , result in pheval_gene_result . iterrows (): ranked_gene_results . append ( RankedPhEvalGeneResult ( pheval_gene_result = PhEvalGeneResult ( gene_symbol = result [ \"gene_symbol\" ], gene_identifier = result [ \"gene_identifier\" ], score = result [ \"score\" ], ), rank = result [ \"rank\" ], ) ) return ranked_gene_results","title":"parse_pheval_gene_result()"},{"location":"api/pheval/analyse/analysis/#src.pheval.analyse.analysis.parse_pheval_variant_result","text":"Parse PhEval variant result into RankedPhEvalVariantResult dataclass. Source code in src/pheval/analyse/analysis.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def parse_pheval_variant_result ( pheval_variant_result : pd . DataFrame ) -> [ RankedPhEvalVariantResult ]: \"\"\"Parse PhEval variant result into RankedPhEvalVariantResult dataclass.\"\"\" ranked_variant_results = [] for _index , result in pheval_variant_result . iterrows (): ranked_variant_results . append ( RankedPhEvalVariantResult ( pheval_variant_result = PhEvalVariantResult ( chromosome = result [ \"chromosome\" ], start = result [ \"start\" ], end = result [ \"end\" ], ref = result [ \"ref\" ], alt = result [ \"alt\" ], score = result [ \"score\" ], ), rank = result [ \"rank\" ], ) ) return ranked_variant_results","title":"parse_pheval_variant_result()"},{"location":"api/pheval/analyse/generate_plots/","text":"PlotGenerator Source code in src/pheval/analyse/generate_plots.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 class PlotGenerator : def __init__ ( self , gene_analysis : bool ): self . gene_analysis = gene_analysis self . stats , self . mrr = [], [] matplotlib . rcParams [ \"axes.spines.right\" ] = False matplotlib . rcParams [ \"axes.spines.top\" ] = False def _retrieve_prioritisation_data ( self , prioritisation_result : TrackPrioritisation ): \"\"\"Return either gene prioritisation or variant prioritisation stats.\"\"\" return ( prioritisation_result . gene_prioritisation if self . gene_analysis else prioritisation_result . variant_prioritisation ) def _generate_stacked_bar_plot_data ( self , prioritisation_result : TrackPrioritisation ) -> None : \"\"\"Generate data in correct format for dataframe creation for stacked bar plot.\"\"\" result = self . _retrieve_prioritisation_data ( prioritisation_result ) rank_stats = result . rank_stats self . stats . append ( { \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trim_corpus_results_directory_suffix ( result . results_dir . name ) } \" , \"Top\" : result . rank_stats . percentage_top (), \"2-3\" : rank_stats . percentage_difference ( rank_stats . percentage_top3 (), rank_stats . percentage_top () ), \"4-5\" : rank_stats . percentage_difference ( rank_stats . percentage_top5 (), rank_stats . percentage_top3 () ), \"6-10\" : rank_stats . percentage_difference ( rank_stats . percentage_top10 (), rank_stats . percentage_top5 () ), \">10\" : rank_stats . percentage_difference ( rank_stats . percentage_found (), rank_stats . percentage_top10 () ), \"FO/NP\" : rank_stats . percentage_difference ( 100 , rank_stats . percentage_found ()), } ) def _generate_stats_mrr_bar_plot_data ( self , prioritisation_result : TrackPrioritisation ) -> None : \"\"\"Generate data in correct format for dataframe creation for MRR bar plot.\"\"\" result = self . _retrieve_prioritisation_data ( prioritisation_result ) self . mrr . extend ( [ { \"Rank\" : \"MRR\" , \"Percentage\" : result . rank_stats . mean_reciprocal_rank (), \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trim_corpus_results_directory_suffix ( result . results_dir . name ) } \" , } ] ) def generate_stacked_bar_gene ( self , prioritisation_data : [ TrackPrioritisation ]) -> None : \"\"\"Generate stacked bar plot and MRR bar plot for gene prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_stacked_bar_plot_data ( prioritisation_result ) self . _generate_stats_mrr_bar_plot_data ( prioritisation_result ) gene_prioritisation_stats_df = pd . DataFrame ( self . stats ) gene_prioritisation_stats_df . set_index ( \"Run\" ) . plot ( kind = \"bar\" , stacked = True , colormap = \"tab10\" , ylabel = \"Disease-causing genes (%)\" , figsize = ( 10 , 8 ), # rot=45, ) . legend ( loc = \"center left\" , bbox_to_anchor = ( 1.0 , 0.5 )) plt . savefig ( \"gene_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) gene_mrr_df = pd . DataFrame ( self . mrr ) gene_mrr_df . set_index ( \"Run\" ) . plot ( kind = \"bar\" , colormap = \"tab10\" , ylabel = \"Gene prioritisation mean reciprocal rank\" , legend = False , ) plt . savefig ( \"gene_mrr.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) def generate_stacked_bar_variant ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate stacked bar plot and MRR bar plot for variant prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_stacked_bar_plot_data ( prioritisation_result ) self . _generate_stats_mrr_bar_plot_data ( prioritisation_result ) variant_prioritisation_stats_df = pd . DataFrame ( self . stats ) variant_prioritisation_stats_df . set_index ( \"Run\" ) . plot ( kind = \"bar\" , stacked = True , colormap = \"tab10\" , ylabel = \"Disease-causing variants (%)\" ) . legend ( loc = \"center left\" , bbox_to_anchor = ( 1.0 , 0.5 )) plt . savefig ( \"variant_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) gene_mrr_df = pd . DataFrame ( self . mrr ) gene_mrr_df . set_index ( \"Run\" ) . plot ( kind = \"bar\" , colormap = \"tab10\" , ylabel = \"Variant prioritisation mean reciprocal rank\" , legend = False , ) plt . savefig ( \"variant_mrr.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) def _generate_cumulative_bar_plot_data ( self , prioritisation_result : TrackPrioritisation ): \"\"\"Generate data in correct format for dataframe creation for cumulative bar plot.\"\"\" result = self . _retrieve_prioritisation_data ( prioritisation_result ) rank_stats = result . rank_stats trimmed_corpus_results_dir = trim_corpus_results_directory_suffix ( result . results_dir . name ) self . stats . extend ( [ { \"Rank\" : \"Top\" , \"Percentage\" : rank_stats . percentage_top () / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"Top3\" , \"Percentage\" : rank_stats . percentage_top3 () / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"Top5\" , \"Percentage\" : rank_stats . percentage_top5 () / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"Top10\" , \"Percentage\" : rank_stats . percentage_top10 () / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"Found\" , \"Percentage\" : rank_stats . percentage_found () / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"FO/NP\" , \"Percentage\" : rank_stats . percentage_difference ( 100 , rank_stats . percentage_found () ) / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"MRR\" , \"Percentage\" : rank_stats . mean_reciprocal_rank (), \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, ] ) def generate_cumulative_bar_gene ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate cumulative bar plot for gene prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_cumulative_bar_plot_data ( prioritisation_result ) gene_prioritisation_df = pd . DataFrame ( self . stats ) sns . catplot ( data = gene_prioritisation_df , kind = \"bar\" , x = \"Rank\" , y = \"Percentage\" , hue = \"Run\" ) . set ( xlabel = \"Rank\" , ylabel = \"Disease-causing genes (%)\" ) plt . savefig ( \"gene_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) def generate_cumulative_bar_variant ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate cumulative bar plot for variant prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_cumulative_bar_plot_data ( prioritisation_result ) variant_prioritisation_df = pd . DataFrame ( self . stats ) sns . catplot ( data = variant_prioritisation_df , kind = \"bar\" , x = \"Rank\" , y = \"Percentage\" , hue = \"Run\" ) . set ( xlabel = \"Rank\" , ylabel = \"Disease-causing variants (%)\" ) plt . savefig ( \"variant_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) def _generate_non_cumulative_bar_plot_data ( self , prioritisation_result : TrackPrioritisation ) -> [ dict ]: \"\"\"Generate data in correct format for dataframe creation for non-cumulative bar plot.\"\"\" result = self . _retrieve_prioritisation_data ( prioritisation_result ) rank_stats = result . rank_stats trimmed_corpus_results_dir = trim_corpus_results_directory_suffix ( result . results_dir . name ) self . stats . extend ( [ { \"Rank\" : \"Top\" , \"Percentage\" : rank_stats . percentage_top () / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"2-3\" , \"Percentage\" : rank_stats . percentage_difference ( rank_stats . percentage_top3 (), rank_stats . percentage_top () ) / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"4-5\" , \"Percentage\" : rank_stats . percentage_difference ( rank_stats . percentage_top5 (), rank_stats . percentage_top3 () ) / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"6-10\" , \"Percentage\" : rank_stats . percentage_difference ( rank_stats . percentage_top10 (), rank_stats . percentage_top5 () ) / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \">10\" , \"Percentage\" : rank_stats . percentage_difference ( rank_stats . percentage_found (), rank_stats . percentage_top10 () ) / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"FO/NP\" , \"Percentage\" : rank_stats . percentage_difference ( 100 , rank_stats . percentage_found () ) / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"MRR\" , \"Percentage\" : rank_stats . mean_reciprocal_rank (), \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, ] ) def generate_non_cumulative_bar_gene ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate non-cumulative bar plot for gene prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_non_cumulative_bar_plot_data ( prioritisation_result ) gene_prioritisation_df = pd . DataFrame ( self . stats ) sns . catplot ( data = gene_prioritisation_df , kind = \"bar\" , x = \"Rank\" , y = \"Percentage\" , hue = \"Run\" ) . set ( xlabel = \"Rank\" , ylabel = \"Disease-causing genes (%)\" ) plt . savefig ( \"gene_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) def generate_non_cumulative_bar_variant ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate non-cumulative bar plot for variant prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_non_cumulative_bar_plot_data ( prioritisation_result ) variant_prioritisation_df = pd . DataFrame ( self . stats ) sns . catplot ( data = variant_prioritisation_df , kind = \"bar\" , x = \"Rank\" , y = \"Percentage\" , hue = \"Run\" ) . set ( xlabel = \"Rank\" , ylabel = \"Disease-causing variants (%)\" ) plt . savefig ( \"variant_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) generate_cumulative_bar_gene ( prioritisation_data ) Generate cumulative bar plot for gene prioritisation stats. Source code in src/pheval/analyse/generate_plots.py 190 191 192 193 194 195 196 197 198 def generate_cumulative_bar_gene ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate cumulative bar plot for gene prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_cumulative_bar_plot_data ( prioritisation_result ) gene_prioritisation_df = pd . DataFrame ( self . stats ) sns . catplot ( data = gene_prioritisation_df , kind = \"bar\" , x = \"Rank\" , y = \"Percentage\" , hue = \"Run\" ) . set ( xlabel = \"Rank\" , ylabel = \"Disease-causing genes (%)\" ) plt . savefig ( \"gene_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) generate_cumulative_bar_variant ( prioritisation_data ) Generate cumulative bar plot for variant prioritisation stats. Source code in src/pheval/analyse/generate_plots.py 200 201 202 203 204 205 206 207 208 def generate_cumulative_bar_variant ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate cumulative bar plot for variant prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_cumulative_bar_plot_data ( prioritisation_result ) variant_prioritisation_df = pd . DataFrame ( self . stats ) sns . catplot ( data = variant_prioritisation_df , kind = \"bar\" , x = \"Rank\" , y = \"Percentage\" , hue = \"Run\" ) . set ( xlabel = \"Rank\" , ylabel = \"Disease-causing variants (%)\" ) plt . savefig ( \"variant_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) generate_non_cumulative_bar_gene ( prioritisation_data ) Generate non-cumulative bar plot for gene prioritisation stats. Source code in src/pheval/analyse/generate_plots.py 272 273 274 275 276 277 278 279 280 def generate_non_cumulative_bar_gene ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate non-cumulative bar plot for gene prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_non_cumulative_bar_plot_data ( prioritisation_result ) gene_prioritisation_df = pd . DataFrame ( self . stats ) sns . catplot ( data = gene_prioritisation_df , kind = \"bar\" , x = \"Rank\" , y = \"Percentage\" , hue = \"Run\" ) . set ( xlabel = \"Rank\" , ylabel = \"Disease-causing genes (%)\" ) plt . savefig ( \"gene_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) generate_non_cumulative_bar_variant ( prioritisation_data ) Generate non-cumulative bar plot for variant prioritisation stats. Source code in src/pheval/analyse/generate_plots.py 282 283 284 285 286 287 288 289 290 def generate_non_cumulative_bar_variant ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate non-cumulative bar plot for variant prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_non_cumulative_bar_plot_data ( prioritisation_result ) variant_prioritisation_df = pd . DataFrame ( self . stats ) sns . catplot ( data = variant_prioritisation_df , kind = \"bar\" , x = \"Rank\" , y = \"Percentage\" , hue = \"Run\" ) . set ( xlabel = \"Rank\" , ylabel = \"Disease-causing variants (%)\" ) plt . savefig ( \"variant_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) generate_stacked_bar_gene ( prioritisation_data ) Generate stacked bar plot and MRR bar plot for gene prioritisation stats. Source code in src/pheval/analyse/generate_plots.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def generate_stacked_bar_gene ( self , prioritisation_data : [ TrackPrioritisation ]) -> None : \"\"\"Generate stacked bar plot and MRR bar plot for gene prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_stacked_bar_plot_data ( prioritisation_result ) self . _generate_stats_mrr_bar_plot_data ( prioritisation_result ) gene_prioritisation_stats_df = pd . DataFrame ( self . stats ) gene_prioritisation_stats_df . set_index ( \"Run\" ) . plot ( kind = \"bar\" , stacked = True , colormap = \"tab10\" , ylabel = \"Disease-causing genes (%)\" , figsize = ( 10 , 8 ), # rot=45, ) . legend ( loc = \"center left\" , bbox_to_anchor = ( 1.0 , 0.5 )) plt . savefig ( \"gene_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) gene_mrr_df = pd . DataFrame ( self . mrr ) gene_mrr_df . set_index ( \"Run\" ) . plot ( kind = \"bar\" , colormap = \"tab10\" , ylabel = \"Gene prioritisation mean reciprocal rank\" , legend = False , ) plt . savefig ( \"gene_mrr.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) generate_stacked_bar_variant ( prioritisation_data ) Generate stacked bar plot and MRR bar plot for variant prioritisation stats. Source code in src/pheval/analyse/generate_plots.py 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 def generate_stacked_bar_variant ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate stacked bar plot and MRR bar plot for variant prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_stacked_bar_plot_data ( prioritisation_result ) self . _generate_stats_mrr_bar_plot_data ( prioritisation_result ) variant_prioritisation_stats_df = pd . DataFrame ( self . stats ) variant_prioritisation_stats_df . set_index ( \"Run\" ) . plot ( kind = \"bar\" , stacked = True , colormap = \"tab10\" , ylabel = \"Disease-causing variants (%)\" ) . legend ( loc = \"center left\" , bbox_to_anchor = ( 1.0 , 0.5 )) plt . savefig ( \"variant_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) gene_mrr_df = pd . DataFrame ( self . mrr ) gene_mrr_df . set_index ( \"Run\" ) . plot ( kind = \"bar\" , colormap = \"tab10\" , ylabel = \"Variant prioritisation mean reciprocal rank\" , legend = False , ) plt . savefig ( \"variant_mrr.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) TrackGenePrioritisation dataclass Track gene prioritisation for a run. Source code in src/pheval/analyse/generate_plots.py 18 19 20 21 22 23 24 @dataclass class TrackGenePrioritisation : \"\"\"Track gene prioritisation for a run.\"\"\" results_dir : Path ranks : dict rank_stats : RankStats TrackPrioritisation dataclass Track prioritisation for a run. Source code in src/pheval/analyse/generate_plots.py 36 37 38 39 40 41 @dataclass class TrackPrioritisation : \"\"\"Track prioritisation for a run.\"\"\" gene_prioritisation : TrackGenePrioritisation variant_prioritisation : TrackVariantPrioritisation TrackVariantPrioritisation dataclass Track variant prioritisation for a run. Source code in src/pheval/analyse/generate_plots.py 27 28 29 30 31 32 33 @dataclass class TrackVariantPrioritisation : \"\"\"Track variant prioritisation for a run.\"\"\" results_dir : Path ranks : dict rank_stats : RankStats generate_gene_plots ( prioritisation_data , plot_type ) Generate summary stats bar plot for gene prioritisation. Source code in src/pheval/analyse/generate_plots.py 293 294 295 296 297 298 299 300 301 def generate_gene_plots ( prioritisation_data : [ TrackPrioritisation ], plot_type : str ) -> None : \"\"\"Generate summary stats bar plot for gene prioritisation.\"\"\" plot_generator = PlotGenerator ( gene_analysis = True ) if plot_type == \"bar_stacked\" : plot_generator . generate_stacked_bar_gene ( prioritisation_data ) elif plot_type == \"bar_cumulative\" : plot_generator . generate_cumulative_bar_gene ( prioritisation_data ) elif plot_type == \"bar_non_cumulative\" : plot_generator . generate_non_cumulative_bar_gene ( prioritisation_data ) generate_variant_plots ( prioritisation_data , plot_type ) Generate summary stats bar plot for variant prioritisation. Source code in src/pheval/analyse/generate_plots.py 304 305 306 307 308 309 310 311 312 def generate_variant_plots ( prioritisation_data : [ TrackPrioritisation ], plot_type : str ) -> None : \"\"\"Generate summary stats bar plot for variant prioritisation.\"\"\" plot_generator = PlotGenerator ( gene_analysis = False ) if plot_type == \"bar_stacked\" : plot_generator . generate_stacked_bar_variant ( prioritisation_data ) elif plot_type == \"bar_cumulative\" : plot_generator . generate_cumulative_bar_variant ( prioritisation_data ) elif plot_type == \"bar_non_cumulative\" : plot_generator . generate_non_cumulative_bar_variant ( prioritisation_data ) trim_corpus_results_directory_suffix ( corpus_results_directory ) Trim the end of the corpus results directory name. Source code in src/pheval/analyse/generate_plots.py 13 14 15 def trim_corpus_results_directory_suffix ( corpus_results_directory : Path ) -> Path : \"\"\"Trim the end of the corpus results directory name.\"\"\" return Path ( str ( corpus_results_directory ) . replace ( PHEVAL_RESULTS_DIRECTORY_SUFFIX , \"\" ))","title":"Generate plots"},{"location":"api/pheval/analyse/generate_plots/#src.pheval.analyse.generate_plots.PlotGenerator","text":"Source code in src/pheval/analyse/generate_plots.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 class PlotGenerator : def __init__ ( self , gene_analysis : bool ): self . gene_analysis = gene_analysis self . stats , self . mrr = [], [] matplotlib . rcParams [ \"axes.spines.right\" ] = False matplotlib . rcParams [ \"axes.spines.top\" ] = False def _retrieve_prioritisation_data ( self , prioritisation_result : TrackPrioritisation ): \"\"\"Return either gene prioritisation or variant prioritisation stats.\"\"\" return ( prioritisation_result . gene_prioritisation if self . gene_analysis else prioritisation_result . variant_prioritisation ) def _generate_stacked_bar_plot_data ( self , prioritisation_result : TrackPrioritisation ) -> None : \"\"\"Generate data in correct format for dataframe creation for stacked bar plot.\"\"\" result = self . _retrieve_prioritisation_data ( prioritisation_result ) rank_stats = result . rank_stats self . stats . append ( { \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trim_corpus_results_directory_suffix ( result . results_dir . name ) } \" , \"Top\" : result . rank_stats . percentage_top (), \"2-3\" : rank_stats . percentage_difference ( rank_stats . percentage_top3 (), rank_stats . percentage_top () ), \"4-5\" : rank_stats . percentage_difference ( rank_stats . percentage_top5 (), rank_stats . percentage_top3 () ), \"6-10\" : rank_stats . percentage_difference ( rank_stats . percentage_top10 (), rank_stats . percentage_top5 () ), \">10\" : rank_stats . percentage_difference ( rank_stats . percentage_found (), rank_stats . percentage_top10 () ), \"FO/NP\" : rank_stats . percentage_difference ( 100 , rank_stats . percentage_found ()), } ) def _generate_stats_mrr_bar_plot_data ( self , prioritisation_result : TrackPrioritisation ) -> None : \"\"\"Generate data in correct format for dataframe creation for MRR bar plot.\"\"\" result = self . _retrieve_prioritisation_data ( prioritisation_result ) self . mrr . extend ( [ { \"Rank\" : \"MRR\" , \"Percentage\" : result . rank_stats . mean_reciprocal_rank (), \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trim_corpus_results_directory_suffix ( result . results_dir . name ) } \" , } ] ) def generate_stacked_bar_gene ( self , prioritisation_data : [ TrackPrioritisation ]) -> None : \"\"\"Generate stacked bar plot and MRR bar plot for gene prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_stacked_bar_plot_data ( prioritisation_result ) self . _generate_stats_mrr_bar_plot_data ( prioritisation_result ) gene_prioritisation_stats_df = pd . DataFrame ( self . stats ) gene_prioritisation_stats_df . set_index ( \"Run\" ) . plot ( kind = \"bar\" , stacked = True , colormap = \"tab10\" , ylabel = \"Disease-causing genes (%)\" , figsize = ( 10 , 8 ), # rot=45, ) . legend ( loc = \"center left\" , bbox_to_anchor = ( 1.0 , 0.5 )) plt . savefig ( \"gene_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) gene_mrr_df = pd . DataFrame ( self . mrr ) gene_mrr_df . set_index ( \"Run\" ) . plot ( kind = \"bar\" , colormap = \"tab10\" , ylabel = \"Gene prioritisation mean reciprocal rank\" , legend = False , ) plt . savefig ( \"gene_mrr.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) def generate_stacked_bar_variant ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate stacked bar plot and MRR bar plot for variant prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_stacked_bar_plot_data ( prioritisation_result ) self . _generate_stats_mrr_bar_plot_data ( prioritisation_result ) variant_prioritisation_stats_df = pd . DataFrame ( self . stats ) variant_prioritisation_stats_df . set_index ( \"Run\" ) . plot ( kind = \"bar\" , stacked = True , colormap = \"tab10\" , ylabel = \"Disease-causing variants (%)\" ) . legend ( loc = \"center left\" , bbox_to_anchor = ( 1.0 , 0.5 )) plt . savefig ( \"variant_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) gene_mrr_df = pd . DataFrame ( self . mrr ) gene_mrr_df . set_index ( \"Run\" ) . plot ( kind = \"bar\" , colormap = \"tab10\" , ylabel = \"Variant prioritisation mean reciprocal rank\" , legend = False , ) plt . savefig ( \"variant_mrr.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) def _generate_cumulative_bar_plot_data ( self , prioritisation_result : TrackPrioritisation ): \"\"\"Generate data in correct format for dataframe creation for cumulative bar plot.\"\"\" result = self . _retrieve_prioritisation_data ( prioritisation_result ) rank_stats = result . rank_stats trimmed_corpus_results_dir = trim_corpus_results_directory_suffix ( result . results_dir . name ) self . stats . extend ( [ { \"Rank\" : \"Top\" , \"Percentage\" : rank_stats . percentage_top () / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"Top3\" , \"Percentage\" : rank_stats . percentage_top3 () / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"Top5\" , \"Percentage\" : rank_stats . percentage_top5 () / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"Top10\" , \"Percentage\" : rank_stats . percentage_top10 () / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"Found\" , \"Percentage\" : rank_stats . percentage_found () / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"FO/NP\" , \"Percentage\" : rank_stats . percentage_difference ( 100 , rank_stats . percentage_found () ) / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"MRR\" , \"Percentage\" : rank_stats . mean_reciprocal_rank (), \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, ] ) def generate_cumulative_bar_gene ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate cumulative bar plot for gene prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_cumulative_bar_plot_data ( prioritisation_result ) gene_prioritisation_df = pd . DataFrame ( self . stats ) sns . catplot ( data = gene_prioritisation_df , kind = \"bar\" , x = \"Rank\" , y = \"Percentage\" , hue = \"Run\" ) . set ( xlabel = \"Rank\" , ylabel = \"Disease-causing genes (%)\" ) plt . savefig ( \"gene_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) def generate_cumulative_bar_variant ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate cumulative bar plot for variant prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_cumulative_bar_plot_data ( prioritisation_result ) variant_prioritisation_df = pd . DataFrame ( self . stats ) sns . catplot ( data = variant_prioritisation_df , kind = \"bar\" , x = \"Rank\" , y = \"Percentage\" , hue = \"Run\" ) . set ( xlabel = \"Rank\" , ylabel = \"Disease-causing variants (%)\" ) plt . savefig ( \"variant_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) def _generate_non_cumulative_bar_plot_data ( self , prioritisation_result : TrackPrioritisation ) -> [ dict ]: \"\"\"Generate data in correct format for dataframe creation for non-cumulative bar plot.\"\"\" result = self . _retrieve_prioritisation_data ( prioritisation_result ) rank_stats = result . rank_stats trimmed_corpus_results_dir = trim_corpus_results_directory_suffix ( result . results_dir . name ) self . stats . extend ( [ { \"Rank\" : \"Top\" , \"Percentage\" : rank_stats . percentage_top () / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"2-3\" , \"Percentage\" : rank_stats . percentage_difference ( rank_stats . percentage_top3 (), rank_stats . percentage_top () ) / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"4-5\" , \"Percentage\" : rank_stats . percentage_difference ( rank_stats . percentage_top5 (), rank_stats . percentage_top3 () ) / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"6-10\" , \"Percentage\" : rank_stats . percentage_difference ( rank_stats . percentage_top10 (), rank_stats . percentage_top5 () ) / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \">10\" , \"Percentage\" : rank_stats . percentage_difference ( rank_stats . percentage_found (), rank_stats . percentage_top10 () ) / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"FO/NP\" , \"Percentage\" : rank_stats . percentage_difference ( 100 , rank_stats . percentage_found () ) / 100 , \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, { \"Rank\" : \"MRR\" , \"Percentage\" : rank_stats . mean_reciprocal_rank (), \"Run\" : f \" { result . results_dir . parents [ 0 ] . name } _\" f \" { trimmed_corpus_results_dir } \" , }, ] ) def generate_non_cumulative_bar_gene ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate non-cumulative bar plot for gene prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_non_cumulative_bar_plot_data ( prioritisation_result ) gene_prioritisation_df = pd . DataFrame ( self . stats ) sns . catplot ( data = gene_prioritisation_df , kind = \"bar\" , x = \"Rank\" , y = \"Percentage\" , hue = \"Run\" ) . set ( xlabel = \"Rank\" , ylabel = \"Disease-causing genes (%)\" ) plt . savefig ( \"gene_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) def generate_non_cumulative_bar_variant ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate non-cumulative bar plot for variant prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_non_cumulative_bar_plot_data ( prioritisation_result ) variant_prioritisation_df = pd . DataFrame ( self . stats ) sns . catplot ( data = variant_prioritisation_df , kind = \"bar\" , x = \"Rank\" , y = \"Percentage\" , hue = \"Run\" ) . set ( xlabel = \"Rank\" , ylabel = \"Disease-causing variants (%)\" ) plt . savefig ( \"variant_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" )","title":"PlotGenerator"},{"location":"api/pheval/analyse/generate_plots/#src.pheval.analyse.generate_plots.PlotGenerator.generate_cumulative_bar_gene","text":"Generate cumulative bar plot for gene prioritisation stats. Source code in src/pheval/analyse/generate_plots.py 190 191 192 193 194 195 196 197 198 def generate_cumulative_bar_gene ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate cumulative bar plot for gene prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_cumulative_bar_plot_data ( prioritisation_result ) gene_prioritisation_df = pd . DataFrame ( self . stats ) sns . catplot ( data = gene_prioritisation_df , kind = \"bar\" , x = \"Rank\" , y = \"Percentage\" , hue = \"Run\" ) . set ( xlabel = \"Rank\" , ylabel = \"Disease-causing genes (%)\" ) plt . savefig ( \"gene_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" )","title":"generate_cumulative_bar_gene()"},{"location":"api/pheval/analyse/generate_plots/#src.pheval.analyse.generate_plots.PlotGenerator.generate_cumulative_bar_variant","text":"Generate cumulative bar plot for variant prioritisation stats. Source code in src/pheval/analyse/generate_plots.py 200 201 202 203 204 205 206 207 208 def generate_cumulative_bar_variant ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate cumulative bar plot for variant prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_cumulative_bar_plot_data ( prioritisation_result ) variant_prioritisation_df = pd . DataFrame ( self . stats ) sns . catplot ( data = variant_prioritisation_df , kind = \"bar\" , x = \"Rank\" , y = \"Percentage\" , hue = \"Run\" ) . set ( xlabel = \"Rank\" , ylabel = \"Disease-causing variants (%)\" ) plt . savefig ( \"variant_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" )","title":"generate_cumulative_bar_variant()"},{"location":"api/pheval/analyse/generate_plots/#src.pheval.analyse.generate_plots.PlotGenerator.generate_non_cumulative_bar_gene","text":"Generate non-cumulative bar plot for gene prioritisation stats. Source code in src/pheval/analyse/generate_plots.py 272 273 274 275 276 277 278 279 280 def generate_non_cumulative_bar_gene ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate non-cumulative bar plot for gene prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_non_cumulative_bar_plot_data ( prioritisation_result ) gene_prioritisation_df = pd . DataFrame ( self . stats ) sns . catplot ( data = gene_prioritisation_df , kind = \"bar\" , x = \"Rank\" , y = \"Percentage\" , hue = \"Run\" ) . set ( xlabel = \"Rank\" , ylabel = \"Disease-causing genes (%)\" ) plt . savefig ( \"gene_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" )","title":"generate_non_cumulative_bar_gene()"},{"location":"api/pheval/analyse/generate_plots/#src.pheval.analyse.generate_plots.PlotGenerator.generate_non_cumulative_bar_variant","text":"Generate non-cumulative bar plot for variant prioritisation stats. Source code in src/pheval/analyse/generate_plots.py 282 283 284 285 286 287 288 289 290 def generate_non_cumulative_bar_variant ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate non-cumulative bar plot for variant prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_non_cumulative_bar_plot_data ( prioritisation_result ) variant_prioritisation_df = pd . DataFrame ( self . stats ) sns . catplot ( data = variant_prioritisation_df , kind = \"bar\" , x = \"Rank\" , y = \"Percentage\" , hue = \"Run\" ) . set ( xlabel = \"Rank\" , ylabel = \"Disease-causing variants (%)\" ) plt . savefig ( \"variant_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" )","title":"generate_non_cumulative_bar_variant()"},{"location":"api/pheval/analyse/generate_plots/#src.pheval.analyse.generate_plots.PlotGenerator.generate_stacked_bar_gene","text":"Generate stacked bar plot and MRR bar plot for gene prioritisation stats. Source code in src/pheval/analyse/generate_plots.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def generate_stacked_bar_gene ( self , prioritisation_data : [ TrackPrioritisation ]) -> None : \"\"\"Generate stacked bar plot and MRR bar plot for gene prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_stacked_bar_plot_data ( prioritisation_result ) self . _generate_stats_mrr_bar_plot_data ( prioritisation_result ) gene_prioritisation_stats_df = pd . DataFrame ( self . stats ) gene_prioritisation_stats_df . set_index ( \"Run\" ) . plot ( kind = \"bar\" , stacked = True , colormap = \"tab10\" , ylabel = \"Disease-causing genes (%)\" , figsize = ( 10 , 8 ), # rot=45, ) . legend ( loc = \"center left\" , bbox_to_anchor = ( 1.0 , 0.5 )) plt . savefig ( \"gene_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) gene_mrr_df = pd . DataFrame ( self . mrr ) gene_mrr_df . set_index ( \"Run\" ) . plot ( kind = \"bar\" , colormap = \"tab10\" , ylabel = \"Gene prioritisation mean reciprocal rank\" , legend = False , ) plt . savefig ( \"gene_mrr.svg\" , format = \"svg\" , bbox_inches = \"tight\" )","title":"generate_stacked_bar_gene()"},{"location":"api/pheval/analyse/generate_plots/#src.pheval.analyse.generate_plots.PlotGenerator.generate_stacked_bar_variant","text":"Generate stacked bar plot and MRR bar plot for variant prioritisation stats. Source code in src/pheval/analyse/generate_plots.py 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 def generate_stacked_bar_variant ( self , prioritisation_data : [ TrackPrioritisation ]): \"\"\"Generate stacked bar plot and MRR bar plot for variant prioritisation stats.\"\"\" for prioritisation_result in prioritisation_data : self . _generate_stacked_bar_plot_data ( prioritisation_result ) self . _generate_stats_mrr_bar_plot_data ( prioritisation_result ) variant_prioritisation_stats_df = pd . DataFrame ( self . stats ) variant_prioritisation_stats_df . set_index ( \"Run\" ) . plot ( kind = \"bar\" , stacked = True , colormap = \"tab10\" , ylabel = \"Disease-causing variants (%)\" ) . legend ( loc = \"center left\" , bbox_to_anchor = ( 1.0 , 0.5 )) plt . savefig ( \"variant_rank_stats.svg\" , format = \"svg\" , bbox_inches = \"tight\" ) gene_mrr_df = pd . DataFrame ( self . mrr ) gene_mrr_df . set_index ( \"Run\" ) . plot ( kind = \"bar\" , colormap = \"tab10\" , ylabel = \"Variant prioritisation mean reciprocal rank\" , legend = False , ) plt . savefig ( \"variant_mrr.svg\" , format = \"svg\" , bbox_inches = \"tight\" )","title":"generate_stacked_bar_variant()"},{"location":"api/pheval/analyse/generate_plots/#src.pheval.analyse.generate_plots.TrackGenePrioritisation","text":"Track gene prioritisation for a run. Source code in src/pheval/analyse/generate_plots.py 18 19 20 21 22 23 24 @dataclass class TrackGenePrioritisation : \"\"\"Track gene prioritisation for a run.\"\"\" results_dir : Path ranks : dict rank_stats : RankStats","title":"TrackGenePrioritisation"},{"location":"api/pheval/analyse/generate_plots/#src.pheval.analyse.generate_plots.TrackPrioritisation","text":"Track prioritisation for a run. Source code in src/pheval/analyse/generate_plots.py 36 37 38 39 40 41 @dataclass class TrackPrioritisation : \"\"\"Track prioritisation for a run.\"\"\" gene_prioritisation : TrackGenePrioritisation variant_prioritisation : TrackVariantPrioritisation","title":"TrackPrioritisation"},{"location":"api/pheval/analyse/generate_plots/#src.pheval.analyse.generate_plots.TrackVariantPrioritisation","text":"Track variant prioritisation for a run. Source code in src/pheval/analyse/generate_plots.py 27 28 29 30 31 32 33 @dataclass class TrackVariantPrioritisation : \"\"\"Track variant prioritisation for a run.\"\"\" results_dir : Path ranks : dict rank_stats : RankStats","title":"TrackVariantPrioritisation"},{"location":"api/pheval/analyse/generate_plots/#src.pheval.analyse.generate_plots.generate_gene_plots","text":"Generate summary stats bar plot for gene prioritisation. Source code in src/pheval/analyse/generate_plots.py 293 294 295 296 297 298 299 300 301 def generate_gene_plots ( prioritisation_data : [ TrackPrioritisation ], plot_type : str ) -> None : \"\"\"Generate summary stats bar plot for gene prioritisation.\"\"\" plot_generator = PlotGenerator ( gene_analysis = True ) if plot_type == \"bar_stacked\" : plot_generator . generate_stacked_bar_gene ( prioritisation_data ) elif plot_type == \"bar_cumulative\" : plot_generator . generate_cumulative_bar_gene ( prioritisation_data ) elif plot_type == \"bar_non_cumulative\" : plot_generator . generate_non_cumulative_bar_gene ( prioritisation_data )","title":"generate_gene_plots()"},{"location":"api/pheval/analyse/generate_plots/#src.pheval.analyse.generate_plots.generate_variant_plots","text":"Generate summary stats bar plot for variant prioritisation. Source code in src/pheval/analyse/generate_plots.py 304 305 306 307 308 309 310 311 312 def generate_variant_plots ( prioritisation_data : [ TrackPrioritisation ], plot_type : str ) -> None : \"\"\"Generate summary stats bar plot for variant prioritisation.\"\"\" plot_generator = PlotGenerator ( gene_analysis = False ) if plot_type == \"bar_stacked\" : plot_generator . generate_stacked_bar_variant ( prioritisation_data ) elif plot_type == \"bar_cumulative\" : plot_generator . generate_cumulative_bar_variant ( prioritisation_data ) elif plot_type == \"bar_non_cumulative\" : plot_generator . generate_non_cumulative_bar_variant ( prioritisation_data )","title":"generate_variant_plots()"},{"location":"api/pheval/analyse/generate_plots/#src.pheval.analyse.generate_plots.trim_corpus_results_directory_suffix","text":"Trim the end of the corpus results directory name. Source code in src/pheval/analyse/generate_plots.py 13 14 15 def trim_corpus_results_directory_suffix ( corpus_results_directory : Path ) -> Path : \"\"\"Trim the end of the corpus results directory name.\"\"\" return Path ( str ( corpus_results_directory ) . replace ( PHEVAL_RESULTS_DIRECTORY_SUFFIX , \"\" ))","title":"trim_corpus_results_directory_suffix()"},{"location":"api/pheval/analyse/generate_summary_outputs/","text":"RankComparisonGenerator Write the run comparison of rank assignment for prioritisation. Source code in src/pheval/analyse/generate_summary_outputs.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 class RankComparisonGenerator : \"\"\"Write the run comparison of rank assignment for prioritisation.\"\"\" def __init__ ( self , run_comparison : defaultdict ): self . run_comparison = run_comparison def _generate_dataframe ( self ) -> pd . DataFrame : \"\"\"Generate pandas dataframe.\"\"\" return pd . DataFrame . from_dict ( self . run_comparison , orient = \"index\" ) def _calculate_rank_difference ( self ) -> pd . DataFrame : \"\"\"Calculate the rank decrease for runs - taking the first directory as a baseline.\"\"\" comparison_df = self . _generate_dataframe () comparison_df [ \"rank_decrease\" ] = comparison_df . iloc [:, 3 ] - comparison_df . iloc [:, 2 ] return comparison_df def generate_gene_output ( self , prefix : str ) -> None : \"\"\"Generate the output for gene prioritisation ranks.\"\"\" self . _generate_dataframe () . to_csv ( prefix + \"-gene_rank_comparison.tsv\" , sep = \" \\t \" ) def generate_variant_output ( self , prefix : str ) -> None : \"\"\"Generate the output for variant prioritisation ranks.\"\"\" self . _generate_dataframe () . to_csv ( prefix + \"-variant_rank_comparison.tsv\" , sep = \" \\t \" ) def generate_gene_comparison_output ( self , prefix : str ) -> None : \"\"\"Generate the output for gene prioritisation rank comparison.\"\"\" self . _calculate_rank_difference () . to_csv ( prefix + \"-gene_rank_comparison.tsv\" , sep = \" \\t \" ) def generate_variant_comparison_output ( self , prefix : str ) -> None : \"\"\"Generate the output for variant prioritisation rank comparison.\"\"\" self . _calculate_rank_difference () . to_csv ( prefix + \"-variant_rank_comparison.tsv\" , sep = \" \\t \" ) generate_gene_comparison_output ( prefix ) Generate the output for gene prioritisation rank comparison. Source code in src/pheval/analyse/generate_summary_outputs.py 41 42 43 def generate_gene_comparison_output ( self , prefix : str ) -> None : \"\"\"Generate the output for gene prioritisation rank comparison.\"\"\" self . _calculate_rank_difference () . to_csv ( prefix + \"-gene_rank_comparison.tsv\" , sep = \" \\t \" ) generate_gene_output ( prefix ) Generate the output for gene prioritisation ranks. Source code in src/pheval/analyse/generate_summary_outputs.py 33 34 35 def generate_gene_output ( self , prefix : str ) -> None : \"\"\"Generate the output for gene prioritisation ranks.\"\"\" self . _generate_dataframe () . to_csv ( prefix + \"-gene_rank_comparison.tsv\" , sep = \" \\t \" ) generate_variant_comparison_output ( prefix ) Generate the output for variant prioritisation rank comparison. Source code in src/pheval/analyse/generate_summary_outputs.py 45 46 47 def generate_variant_comparison_output ( self , prefix : str ) -> None : \"\"\"Generate the output for variant prioritisation rank comparison.\"\"\" self . _calculate_rank_difference () . to_csv ( prefix + \"-variant_rank_comparison.tsv\" , sep = \" \\t \" ) generate_variant_output ( prefix ) Generate the output for variant prioritisation ranks. Source code in src/pheval/analyse/generate_summary_outputs.py 37 38 39 def generate_variant_output ( self , prefix : str ) -> None : \"\"\"Generate the output for variant prioritisation ranks.\"\"\" self . _generate_dataframe () . to_csv ( prefix + \"-variant_rank_comparison.tsv\" , sep = \" \\t \" ) RankStatsWriter Write the rank stats for each run. Source code in src/pheval/analyse/generate_summary_outputs.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 class RankStatsWriter : \"\"\"Write the rank stats for each run.\"\"\" def __init__ ( self , file : Path ): self . file = open ( file , \"w\" ) self . writer = csv . writer ( self . file , delimiter = \" \\t \" ) self . writer . writerow ( [ \"results_directory_path\" , \"top\" , \"top3\" , \"top5\" , \"top10\" , \"found\" , \"total\" , \"mean_reciprocal_rank\" , \"percentage_top\" , \"percentage_top3\" , \"percentage_top5\" , \"percentage_top10\" , \"percentage_found\" , ] ) def write_row ( self , directory : Path , rank_stats : RankStats ) -> None : \"\"\"Write summary rank stats row for run.\"\"\" try : self . writer . writerow ( [ directory , rank_stats . top , rank_stats . top3 , rank_stats . top5 , rank_stats . top10 , rank_stats . found , rank_stats . total , rank_stats . mean_reciprocal_rank (), rank_stats . percentage_top (), rank_stats . percentage_top3 (), rank_stats . percentage_top5 (), rank_stats . percentage_top10 (), rank_stats . percentage_found (), ] ) except IOError : print ( \"Error writing \" , self . file ) def close ( self ) -> None : \"\"\"Close file.\"\"\" try : self . file . close () except IOError : print ( \"Error closing \" , self . file ) close () Close file. Source code in src/pheval/analyse/generate_summary_outputs.py 97 98 99 100 101 102 def close ( self ) -> None : \"\"\"Close file.\"\"\" try : self . file . close () except IOError : print ( \"Error closing \" , self . file ) write_row ( directory , rank_stats ) Write summary rank stats row for run. Source code in src/pheval/analyse/generate_summary_outputs.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def write_row ( self , directory : Path , rank_stats : RankStats ) -> None : \"\"\"Write summary rank stats row for run.\"\"\" try : self . writer . writerow ( [ directory , rank_stats . top , rank_stats . top3 , rank_stats . top5 , rank_stats . top10 , rank_stats . found , rank_stats . total , rank_stats . mean_reciprocal_rank (), rank_stats . percentage_top (), rank_stats . percentage_top3 (), rank_stats . percentage_top5 (), rank_stats . percentage_top10 (), rank_stats . percentage_found (), ] ) except IOError : print ( \"Error writing \" , self . file ) generate_benchmark_comparison_gene_output ( prioritisation_stats_for_runs , plot_type ) Generate gene prioritisation outputs for benchmarking multiple runs. Source code in src/pheval/analyse/generate_summary_outputs.py 170 171 172 173 174 175 def generate_benchmark_comparison_gene_output ( prioritisation_stats_for_runs : [ TrackPrioritisation ], plot_type : str ) -> None : \"\"\"Generate gene prioritisation outputs for benchmarking multiple runs.\"\"\" generate_gene_rank_comparisons ( list ( itertools . combinations ( prioritisation_stats_for_runs , 2 ))) generate_gene_plots ( prioritisation_stats_for_runs , plot_type ) generate_benchmark_comparison_variant_output ( prioritisation_stats_for_runs , plot_type ) Generate variant prioritisation outputs for benchmarking multiple runs. Source code in src/pheval/analyse/generate_summary_outputs.py 178 179 180 181 182 183 184 185 def generate_benchmark_comparison_variant_output ( prioritisation_stats_for_runs : [ TrackPrioritisation ], plot_type : str ) -> None : \"\"\"Generate variant prioritisation outputs for benchmarking multiple runs.\"\"\" generate_variant_rank_comparisons ( list ( itertools . combinations ( prioritisation_stats_for_runs , 2 )) ) generate_variant_plots ( prioritisation_stats_for_runs , plot_type ) generate_benchmark_gene_output ( prioritisation_data , plot_type ) Generate gene prioritisation outputs for benchmarking single run. Source code in src/pheval/analyse/generate_summary_outputs.py 105 106 107 108 109 110 111 112 def generate_benchmark_gene_output ( prioritisation_data : TrackPrioritisation , plot_type : str ) -> None : \"\"\"Generate gene prioritisation outputs for benchmarking single run.\"\"\" RankComparisonGenerator ( prioritisation_data . gene_prioritisation . ranks ) . generate_gene_output ( f \" { prioritisation_data . gene_prioritisation . results_dir . name } \" ) generate_gene_plots ([ prioritisation_data ], plot_type ) generate_benchmark_variant_output ( prioritisation_data , plot_type ) Generate variant prioritisation outputs for benchmarking single run. Source code in src/pheval/analyse/generate_summary_outputs.py 115 116 117 118 119 120 121 122 def generate_benchmark_variant_output ( prioritisation_data : TrackPrioritisation , plot_type : str ) -> None : \"\"\"Generate variant prioritisation outputs for benchmarking single run.\"\"\" RankComparisonGenerator ( prioritisation_data . variant_prioritisation . ranks ) . generate_variant_output ( f \" { prioritisation_data . gene_prioritisation . results_dir . name } \" ) generate_variant_plots ([ prioritisation_data ], plot_type ) generate_gene_rank_comparisons ( comparison_ranks ) Generate the gene rank comparison of two result directories. Source code in src/pheval/analyse/generate_summary_outputs.py 141 142 143 144 145 146 147 148 149 150 151 152 def generate_gene_rank_comparisons ( comparison_ranks : [ tuple ]) -> None : \"\"\"Generate the gene rank comparison of two result directories.\"\"\" for pair in comparison_ranks : merged_results = merge_results ( deepcopy ( pair [ 0 ] . gene_prioritisation . ranks ), deepcopy ( pair [ 1 ] . gene_prioritisation . ranks ) ) RankComparisonGenerator ( merged_results ) . generate_gene_comparison_output ( f \" { pair [ 0 ] . gene_prioritisation . results_dir . parents [ 0 ] . name } _\" f \" { pair [ 0 ] . gene_prioritisation . results_dir . name } \" f \"_vs_ { pair [ 1 ] . gene_prioritisation . results_dir . parents [ 0 ] . name } _\" f \" { pair [ 1 ] . gene_prioritisation . results_dir . name } \" ) generate_variant_rank_comparisons ( comparison_ranks ) Generate the variant rank comparison of two result directories. Source code in src/pheval/analyse/generate_summary_outputs.py 155 156 157 158 159 160 161 162 163 164 165 166 167 def generate_variant_rank_comparisons ( comparison_ranks : [ tuple ]) -> None : \"\"\"Generate the variant rank comparison of two result directories.\"\"\" for pair in comparison_ranks : merged_results = merge_results ( deepcopy ( pair [ 0 ] . variant_prioritisation . ranks ), deepcopy ( pair [ 1 ] . variant_prioritisation . ranks ), ) RankComparisonGenerator ( merged_results ) . generate_variant_comparison_output ( f \" { pair [ 0 ] . variant_prioritisation . results_dir . parents [ 0 ] . name } _\" f \" { pair [ 0 ] . variant_prioritisation . results_dir . name } \" f \"_vs_ { pair [ 1 ] . variant_prioritisation . results_dir . parents [ 0 ] . name } _\" f \" { pair [ 1 ] . variant_prioritisation . results_dir . name } \" ) merge_results ( result1 , result2 ) Merge two nested dictionaries containing results on commonalities. Source code in src/pheval/analyse/generate_summary_outputs.py 125 126 127 128 129 130 131 132 133 134 135 136 137 138 def merge_results ( result1 : dict , result2 : dict ) -> dict : \"\"\"Merge two nested dictionaries containing results on commonalities.\"\"\" for key , val in result1 . items (): if type ( val ) == dict : if key in result2 and type ( result2 [ key ] == dict ): merge_results ( result1 [ key ], result2 [ key ]) else : if key in result2 : result1 [ key ] = result2 [ key ] for key , val in result2 . items (): if key not in result1 : result1 [ key ] = val return result1","title":"Generate summary outputs"},{"location":"api/pheval/analyse/generate_summary_outputs/#src.pheval.analyse.generate_summary_outputs.RankComparisonGenerator","text":"Write the run comparison of rank assignment for prioritisation. Source code in src/pheval/analyse/generate_summary_outputs.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 class RankComparisonGenerator : \"\"\"Write the run comparison of rank assignment for prioritisation.\"\"\" def __init__ ( self , run_comparison : defaultdict ): self . run_comparison = run_comparison def _generate_dataframe ( self ) -> pd . DataFrame : \"\"\"Generate pandas dataframe.\"\"\" return pd . DataFrame . from_dict ( self . run_comparison , orient = \"index\" ) def _calculate_rank_difference ( self ) -> pd . DataFrame : \"\"\"Calculate the rank decrease for runs - taking the first directory as a baseline.\"\"\" comparison_df = self . _generate_dataframe () comparison_df [ \"rank_decrease\" ] = comparison_df . iloc [:, 3 ] - comparison_df . iloc [:, 2 ] return comparison_df def generate_gene_output ( self , prefix : str ) -> None : \"\"\"Generate the output for gene prioritisation ranks.\"\"\" self . _generate_dataframe () . to_csv ( prefix + \"-gene_rank_comparison.tsv\" , sep = \" \\t \" ) def generate_variant_output ( self , prefix : str ) -> None : \"\"\"Generate the output for variant prioritisation ranks.\"\"\" self . _generate_dataframe () . to_csv ( prefix + \"-variant_rank_comparison.tsv\" , sep = \" \\t \" ) def generate_gene_comparison_output ( self , prefix : str ) -> None : \"\"\"Generate the output for gene prioritisation rank comparison.\"\"\" self . _calculate_rank_difference () . to_csv ( prefix + \"-gene_rank_comparison.tsv\" , sep = \" \\t \" ) def generate_variant_comparison_output ( self , prefix : str ) -> None : \"\"\"Generate the output for variant prioritisation rank comparison.\"\"\" self . _calculate_rank_difference () . to_csv ( prefix + \"-variant_rank_comparison.tsv\" , sep = \" \\t \" )","title":"RankComparisonGenerator"},{"location":"api/pheval/analyse/generate_summary_outputs/#src.pheval.analyse.generate_summary_outputs.RankComparisonGenerator.generate_gene_comparison_output","text":"Generate the output for gene prioritisation rank comparison. Source code in src/pheval/analyse/generate_summary_outputs.py 41 42 43 def generate_gene_comparison_output ( self , prefix : str ) -> None : \"\"\"Generate the output for gene prioritisation rank comparison.\"\"\" self . _calculate_rank_difference () . to_csv ( prefix + \"-gene_rank_comparison.tsv\" , sep = \" \\t \" )","title":"generate_gene_comparison_output()"},{"location":"api/pheval/analyse/generate_summary_outputs/#src.pheval.analyse.generate_summary_outputs.RankComparisonGenerator.generate_gene_output","text":"Generate the output for gene prioritisation ranks. Source code in src/pheval/analyse/generate_summary_outputs.py 33 34 35 def generate_gene_output ( self , prefix : str ) -> None : \"\"\"Generate the output for gene prioritisation ranks.\"\"\" self . _generate_dataframe () . to_csv ( prefix + \"-gene_rank_comparison.tsv\" , sep = \" \\t \" )","title":"generate_gene_output()"},{"location":"api/pheval/analyse/generate_summary_outputs/#src.pheval.analyse.generate_summary_outputs.RankComparisonGenerator.generate_variant_comparison_output","text":"Generate the output for variant prioritisation rank comparison. Source code in src/pheval/analyse/generate_summary_outputs.py 45 46 47 def generate_variant_comparison_output ( self , prefix : str ) -> None : \"\"\"Generate the output for variant prioritisation rank comparison.\"\"\" self . _calculate_rank_difference () . to_csv ( prefix + \"-variant_rank_comparison.tsv\" , sep = \" \\t \" )","title":"generate_variant_comparison_output()"},{"location":"api/pheval/analyse/generate_summary_outputs/#src.pheval.analyse.generate_summary_outputs.RankComparisonGenerator.generate_variant_output","text":"Generate the output for variant prioritisation ranks. Source code in src/pheval/analyse/generate_summary_outputs.py 37 38 39 def generate_variant_output ( self , prefix : str ) -> None : \"\"\"Generate the output for variant prioritisation ranks.\"\"\" self . _generate_dataframe () . to_csv ( prefix + \"-variant_rank_comparison.tsv\" , sep = \" \\t \" )","title":"generate_variant_output()"},{"location":"api/pheval/analyse/generate_summary_outputs/#src.pheval.analyse.generate_summary_outputs.RankStatsWriter","text":"Write the rank stats for each run. Source code in src/pheval/analyse/generate_summary_outputs.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 class RankStatsWriter : \"\"\"Write the rank stats for each run.\"\"\" def __init__ ( self , file : Path ): self . file = open ( file , \"w\" ) self . writer = csv . writer ( self . file , delimiter = \" \\t \" ) self . writer . writerow ( [ \"results_directory_path\" , \"top\" , \"top3\" , \"top5\" , \"top10\" , \"found\" , \"total\" , \"mean_reciprocal_rank\" , \"percentage_top\" , \"percentage_top3\" , \"percentage_top5\" , \"percentage_top10\" , \"percentage_found\" , ] ) def write_row ( self , directory : Path , rank_stats : RankStats ) -> None : \"\"\"Write summary rank stats row for run.\"\"\" try : self . writer . writerow ( [ directory , rank_stats . top , rank_stats . top3 , rank_stats . top5 , rank_stats . top10 , rank_stats . found , rank_stats . total , rank_stats . mean_reciprocal_rank (), rank_stats . percentage_top (), rank_stats . percentage_top3 (), rank_stats . percentage_top5 (), rank_stats . percentage_top10 (), rank_stats . percentage_found (), ] ) except IOError : print ( \"Error writing \" , self . file ) def close ( self ) -> None : \"\"\"Close file.\"\"\" try : self . file . close () except IOError : print ( \"Error closing \" , self . file )","title":"RankStatsWriter"},{"location":"api/pheval/analyse/generate_summary_outputs/#src.pheval.analyse.generate_summary_outputs.RankStatsWriter.close","text":"Close file. Source code in src/pheval/analyse/generate_summary_outputs.py 97 98 99 100 101 102 def close ( self ) -> None : \"\"\"Close file.\"\"\" try : self . file . close () except IOError : print ( \"Error closing \" , self . file )","title":"close()"},{"location":"api/pheval/analyse/generate_summary_outputs/#src.pheval.analyse.generate_summary_outputs.RankStatsWriter.write_row","text":"Write summary rank stats row for run. Source code in src/pheval/analyse/generate_summary_outputs.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def write_row ( self , directory : Path , rank_stats : RankStats ) -> None : \"\"\"Write summary rank stats row for run.\"\"\" try : self . writer . writerow ( [ directory , rank_stats . top , rank_stats . top3 , rank_stats . top5 , rank_stats . top10 , rank_stats . found , rank_stats . total , rank_stats . mean_reciprocal_rank (), rank_stats . percentage_top (), rank_stats . percentage_top3 (), rank_stats . percentage_top5 (), rank_stats . percentage_top10 (), rank_stats . percentage_found (), ] ) except IOError : print ( \"Error writing \" , self . file )","title":"write_row()"},{"location":"api/pheval/analyse/generate_summary_outputs/#src.pheval.analyse.generate_summary_outputs.generate_benchmark_comparison_gene_output","text":"Generate gene prioritisation outputs for benchmarking multiple runs. Source code in src/pheval/analyse/generate_summary_outputs.py 170 171 172 173 174 175 def generate_benchmark_comparison_gene_output ( prioritisation_stats_for_runs : [ TrackPrioritisation ], plot_type : str ) -> None : \"\"\"Generate gene prioritisation outputs for benchmarking multiple runs.\"\"\" generate_gene_rank_comparisons ( list ( itertools . combinations ( prioritisation_stats_for_runs , 2 ))) generate_gene_plots ( prioritisation_stats_for_runs , plot_type )","title":"generate_benchmark_comparison_gene_output()"},{"location":"api/pheval/analyse/generate_summary_outputs/#src.pheval.analyse.generate_summary_outputs.generate_benchmark_comparison_variant_output","text":"Generate variant prioritisation outputs for benchmarking multiple runs. Source code in src/pheval/analyse/generate_summary_outputs.py 178 179 180 181 182 183 184 185 def generate_benchmark_comparison_variant_output ( prioritisation_stats_for_runs : [ TrackPrioritisation ], plot_type : str ) -> None : \"\"\"Generate variant prioritisation outputs for benchmarking multiple runs.\"\"\" generate_variant_rank_comparisons ( list ( itertools . combinations ( prioritisation_stats_for_runs , 2 )) ) generate_variant_plots ( prioritisation_stats_for_runs , plot_type )","title":"generate_benchmark_comparison_variant_output()"},{"location":"api/pheval/analyse/generate_summary_outputs/#src.pheval.analyse.generate_summary_outputs.generate_benchmark_gene_output","text":"Generate gene prioritisation outputs for benchmarking single run. Source code in src/pheval/analyse/generate_summary_outputs.py 105 106 107 108 109 110 111 112 def generate_benchmark_gene_output ( prioritisation_data : TrackPrioritisation , plot_type : str ) -> None : \"\"\"Generate gene prioritisation outputs for benchmarking single run.\"\"\" RankComparisonGenerator ( prioritisation_data . gene_prioritisation . ranks ) . generate_gene_output ( f \" { prioritisation_data . gene_prioritisation . results_dir . name } \" ) generate_gene_plots ([ prioritisation_data ], plot_type )","title":"generate_benchmark_gene_output()"},{"location":"api/pheval/analyse/generate_summary_outputs/#src.pheval.analyse.generate_summary_outputs.generate_benchmark_variant_output","text":"Generate variant prioritisation outputs for benchmarking single run. Source code in src/pheval/analyse/generate_summary_outputs.py 115 116 117 118 119 120 121 122 def generate_benchmark_variant_output ( prioritisation_data : TrackPrioritisation , plot_type : str ) -> None : \"\"\"Generate variant prioritisation outputs for benchmarking single run.\"\"\" RankComparisonGenerator ( prioritisation_data . variant_prioritisation . ranks ) . generate_variant_output ( f \" { prioritisation_data . gene_prioritisation . results_dir . name } \" ) generate_variant_plots ([ prioritisation_data ], plot_type )","title":"generate_benchmark_variant_output()"},{"location":"api/pheval/analyse/generate_summary_outputs/#src.pheval.analyse.generate_summary_outputs.generate_gene_rank_comparisons","text":"Generate the gene rank comparison of two result directories. Source code in src/pheval/analyse/generate_summary_outputs.py 141 142 143 144 145 146 147 148 149 150 151 152 def generate_gene_rank_comparisons ( comparison_ranks : [ tuple ]) -> None : \"\"\"Generate the gene rank comparison of two result directories.\"\"\" for pair in comparison_ranks : merged_results = merge_results ( deepcopy ( pair [ 0 ] . gene_prioritisation . ranks ), deepcopy ( pair [ 1 ] . gene_prioritisation . ranks ) ) RankComparisonGenerator ( merged_results ) . generate_gene_comparison_output ( f \" { pair [ 0 ] . gene_prioritisation . results_dir . parents [ 0 ] . name } _\" f \" { pair [ 0 ] . gene_prioritisation . results_dir . name } \" f \"_vs_ { pair [ 1 ] . gene_prioritisation . results_dir . parents [ 0 ] . name } _\" f \" { pair [ 1 ] . gene_prioritisation . results_dir . name } \" )","title":"generate_gene_rank_comparisons()"},{"location":"api/pheval/analyse/generate_summary_outputs/#src.pheval.analyse.generate_summary_outputs.generate_variant_rank_comparisons","text":"Generate the variant rank comparison of two result directories. Source code in src/pheval/analyse/generate_summary_outputs.py 155 156 157 158 159 160 161 162 163 164 165 166 167 def generate_variant_rank_comparisons ( comparison_ranks : [ tuple ]) -> None : \"\"\"Generate the variant rank comparison of two result directories.\"\"\" for pair in comparison_ranks : merged_results = merge_results ( deepcopy ( pair [ 0 ] . variant_prioritisation . ranks ), deepcopy ( pair [ 1 ] . variant_prioritisation . ranks ), ) RankComparisonGenerator ( merged_results ) . generate_variant_comparison_output ( f \" { pair [ 0 ] . variant_prioritisation . results_dir . parents [ 0 ] . name } _\" f \" { pair [ 0 ] . variant_prioritisation . results_dir . name } \" f \"_vs_ { pair [ 1 ] . variant_prioritisation . results_dir . parents [ 0 ] . name } _\" f \" { pair [ 1 ] . variant_prioritisation . results_dir . name } \" )","title":"generate_variant_rank_comparisons()"},{"location":"api/pheval/analyse/generate_summary_outputs/#src.pheval.analyse.generate_summary_outputs.merge_results","text":"Merge two nested dictionaries containing results on commonalities. Source code in src/pheval/analyse/generate_summary_outputs.py 125 126 127 128 129 130 131 132 133 134 135 136 137 138 def merge_results ( result1 : dict , result2 : dict ) -> dict : \"\"\"Merge two nested dictionaries containing results on commonalities.\"\"\" for key , val in result1 . items (): if type ( val ) == dict : if key in result2 and type ( result2 [ key ] == dict ): merge_results ( result1 [ key ], result2 [ key ]) else : if key in result2 : result1 [ key ] = result2 [ key ] for key , val in result2 . items (): if key not in result1 : result1 [ key ] = val return result1","title":"merge_results()"},{"location":"api/pheval/analyse/rank_stats/","text":"RankStats dataclass Class for keeping track of the rank stats. Source code in src/pheval/analyse/rank_stats.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 @dataclass class RankStats : \"\"\"Class for keeping track of the rank stats.\"\"\" top : int = 0 top3 : int = 0 top5 : int = 0 top10 : int = 0 found : int = 0 total : int = 0 reciprocal_ranks : list = field ( default_factory = list ) def add_rank ( self , rank : int ) -> None : \"\"\"Add rank for phenopacket.\"\"\" self . reciprocal_ranks . append ( 1 / rank ) self . found += 1 if rank == 1 : self . top += 1 if rank != \"\" and rank <= 3 : self . top3 += 1 if rank != \"\" and rank <= 5 : self . top5 += 1 if rank != \"\" and rank <= 10 : self . top10 += 1 def percentage_rank ( self , value : int ) -> float : \"\"\"Return a percentage rank.\"\"\" return 100 * value / self . found def percentage_top ( self ) -> float : \"\"\"Return percentage of top matches.\"\"\" return self . percentage_rank ( self . top ) def percentage_top3 ( self ) -> float : \"\"\"Return percentage of matches in the top3.\"\"\" return self . percentage_rank ( self . top3 ) def percentage_top5 ( self ) -> float : \"\"\"Return percentage of matches in the top5.\"\"\" return self . percentage_rank ( self . top5 ) def percentage_top10 ( self ) -> float : \"\"\"Return percentage of matches in the top10.\"\"\" return self . percentage_rank ( self . top10 ) def percentage_found ( self ) -> float : \"\"\"Return percentage of matches found.\"\"\" return 100 * self . found / self . total @staticmethod def percentage_difference ( percentage_value_1 : float , percentage_value_2 : float ) -> float : \"\"\"Return percentage difference between two percentage values\"\"\" return percentage_value_1 - percentage_value_2 def mean_reciprocal_rank ( self ) -> float : \"\"\"Return the mean reciprocal rank.\"\"\" return mean ( self . reciprocal_ranks ) add_rank ( rank ) Add rank for phenopacket. Source code in src/pheval/analyse/rank_stats.py 17 18 19 20 21 22 23 24 25 26 27 28 def add_rank ( self , rank : int ) -> None : \"\"\"Add rank for phenopacket.\"\"\" self . reciprocal_ranks . append ( 1 / rank ) self . found += 1 if rank == 1 : self . top += 1 if rank != \"\" and rank <= 3 : self . top3 += 1 if rank != \"\" and rank <= 5 : self . top5 += 1 if rank != \"\" and rank <= 10 : self . top10 += 1 mean_reciprocal_rank () Return the mean reciprocal rank. Source code in src/pheval/analyse/rank_stats.py 59 60 61 def mean_reciprocal_rank ( self ) -> float : \"\"\"Return the mean reciprocal rank.\"\"\" return mean ( self . reciprocal_ranks ) percentage_difference ( percentage_value_1 , percentage_value_2 ) staticmethod Return percentage difference between two percentage values Source code in src/pheval/analyse/rank_stats.py 54 55 56 57 @staticmethod def percentage_difference ( percentage_value_1 : float , percentage_value_2 : float ) -> float : \"\"\"Return percentage difference between two percentage values\"\"\" return percentage_value_1 - percentage_value_2 percentage_found () Return percentage of matches found. Source code in src/pheval/analyse/rank_stats.py 50 51 52 def percentage_found ( self ) -> float : \"\"\"Return percentage of matches found.\"\"\" return 100 * self . found / self . total percentage_rank ( value ) Return a percentage rank. Source code in src/pheval/analyse/rank_stats.py 30 31 32 def percentage_rank ( self , value : int ) -> float : \"\"\"Return a percentage rank.\"\"\" return 100 * value / self . found percentage_top () Return percentage of top matches. Source code in src/pheval/analyse/rank_stats.py 34 35 36 def percentage_top ( self ) -> float : \"\"\"Return percentage of top matches.\"\"\" return self . percentage_rank ( self . top ) percentage_top10 () Return percentage of matches in the top10. Source code in src/pheval/analyse/rank_stats.py 46 47 48 def percentage_top10 ( self ) -> float : \"\"\"Return percentage of matches in the top10.\"\"\" return self . percentage_rank ( self . top10 ) percentage_top3 () Return percentage of matches in the top3. Source code in src/pheval/analyse/rank_stats.py 38 39 40 def percentage_top3 ( self ) -> float : \"\"\"Return percentage of matches in the top3.\"\"\" return self . percentage_rank ( self . top3 ) percentage_top5 () Return percentage of matches in the top5. Source code in src/pheval/analyse/rank_stats.py 42 43 44 def percentage_top5 ( self ) -> float : \"\"\"Return percentage of matches in the top5.\"\"\" return self . percentage_rank ( self . top5 )","title":"Rank stats"},{"location":"api/pheval/analyse/rank_stats/#src.pheval.analyse.rank_stats.RankStats","text":"Class for keeping track of the rank stats. Source code in src/pheval/analyse/rank_stats.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 @dataclass class RankStats : \"\"\"Class for keeping track of the rank stats.\"\"\" top : int = 0 top3 : int = 0 top5 : int = 0 top10 : int = 0 found : int = 0 total : int = 0 reciprocal_ranks : list = field ( default_factory = list ) def add_rank ( self , rank : int ) -> None : \"\"\"Add rank for phenopacket.\"\"\" self . reciprocal_ranks . append ( 1 / rank ) self . found += 1 if rank == 1 : self . top += 1 if rank != \"\" and rank <= 3 : self . top3 += 1 if rank != \"\" and rank <= 5 : self . top5 += 1 if rank != \"\" and rank <= 10 : self . top10 += 1 def percentage_rank ( self , value : int ) -> float : \"\"\"Return a percentage rank.\"\"\" return 100 * value / self . found def percentage_top ( self ) -> float : \"\"\"Return percentage of top matches.\"\"\" return self . percentage_rank ( self . top ) def percentage_top3 ( self ) -> float : \"\"\"Return percentage of matches in the top3.\"\"\" return self . percentage_rank ( self . top3 ) def percentage_top5 ( self ) -> float : \"\"\"Return percentage of matches in the top5.\"\"\" return self . percentage_rank ( self . top5 ) def percentage_top10 ( self ) -> float : \"\"\"Return percentage of matches in the top10.\"\"\" return self . percentage_rank ( self . top10 ) def percentage_found ( self ) -> float : \"\"\"Return percentage of matches found.\"\"\" return 100 * self . found / self . total @staticmethod def percentage_difference ( percentage_value_1 : float , percentage_value_2 : float ) -> float : \"\"\"Return percentage difference between two percentage values\"\"\" return percentage_value_1 - percentage_value_2 def mean_reciprocal_rank ( self ) -> float : \"\"\"Return the mean reciprocal rank.\"\"\" return mean ( self . reciprocal_ranks )","title":"RankStats"},{"location":"api/pheval/analyse/rank_stats/#src.pheval.analyse.rank_stats.RankStats.add_rank","text":"Add rank for phenopacket. Source code in src/pheval/analyse/rank_stats.py 17 18 19 20 21 22 23 24 25 26 27 28 def add_rank ( self , rank : int ) -> None : \"\"\"Add rank for phenopacket.\"\"\" self . reciprocal_ranks . append ( 1 / rank ) self . found += 1 if rank == 1 : self . top += 1 if rank != \"\" and rank <= 3 : self . top3 += 1 if rank != \"\" and rank <= 5 : self . top5 += 1 if rank != \"\" and rank <= 10 : self . top10 += 1","title":"add_rank()"},{"location":"api/pheval/analyse/rank_stats/#src.pheval.analyse.rank_stats.RankStats.mean_reciprocal_rank","text":"Return the mean reciprocal rank. Source code in src/pheval/analyse/rank_stats.py 59 60 61 def mean_reciprocal_rank ( self ) -> float : \"\"\"Return the mean reciprocal rank.\"\"\" return mean ( self . reciprocal_ranks )","title":"mean_reciprocal_rank()"},{"location":"api/pheval/analyse/rank_stats/#src.pheval.analyse.rank_stats.RankStats.percentage_difference","text":"Return percentage difference between two percentage values Source code in src/pheval/analyse/rank_stats.py 54 55 56 57 @staticmethod def percentage_difference ( percentage_value_1 : float , percentage_value_2 : float ) -> float : \"\"\"Return percentage difference between two percentage values\"\"\" return percentage_value_1 - percentage_value_2","title":"percentage_difference()"},{"location":"api/pheval/analyse/rank_stats/#src.pheval.analyse.rank_stats.RankStats.percentage_found","text":"Return percentage of matches found. Source code in src/pheval/analyse/rank_stats.py 50 51 52 def percentage_found ( self ) -> float : \"\"\"Return percentage of matches found.\"\"\" return 100 * self . found / self . total","title":"percentage_found()"},{"location":"api/pheval/analyse/rank_stats/#src.pheval.analyse.rank_stats.RankStats.percentage_rank","text":"Return a percentage rank. Source code in src/pheval/analyse/rank_stats.py 30 31 32 def percentage_rank ( self , value : int ) -> float : \"\"\"Return a percentage rank.\"\"\" return 100 * value / self . found","title":"percentage_rank()"},{"location":"api/pheval/analyse/rank_stats/#src.pheval.analyse.rank_stats.RankStats.percentage_top","text":"Return percentage of top matches. Source code in src/pheval/analyse/rank_stats.py 34 35 36 def percentage_top ( self ) -> float : \"\"\"Return percentage of top matches.\"\"\" return self . percentage_rank ( self . top )","title":"percentage_top()"},{"location":"api/pheval/analyse/rank_stats/#src.pheval.analyse.rank_stats.RankStats.percentage_top10","text":"Return percentage of matches in the top10. Source code in src/pheval/analyse/rank_stats.py 46 47 48 def percentage_top10 ( self ) -> float : \"\"\"Return percentage of matches in the top10.\"\"\" return self . percentage_rank ( self . top10 )","title":"percentage_top10()"},{"location":"api/pheval/analyse/rank_stats/#src.pheval.analyse.rank_stats.RankStats.percentage_top3","text":"Return percentage of matches in the top3. Source code in src/pheval/analyse/rank_stats.py 38 39 40 def percentage_top3 ( self ) -> float : \"\"\"Return percentage of matches in the top3.\"\"\" return self . percentage_rank ( self . top3 )","title":"percentage_top3()"},{"location":"api/pheval/analyse/rank_stats/#src.pheval.analyse.rank_stats.RankStats.percentage_top5","text":"Return percentage of matches in the top5. Source code in src/pheval/analyse/rank_stats.py 42 43 44 def percentage_top5 ( self ) -> float : \"\"\"Return percentage of matches in the top5.\"\"\" return self . percentage_rank ( self . top5 )","title":"percentage_top5()"},{"location":"api/pheval/post_processing/post_processing/","text":"PhEvalGeneResult dataclass Minimal data required from tool-specific output for gene prioritisation. Source code in src/pheval/post_processing/post_processing.py 14 15 16 17 18 19 20 @dataclass class PhEvalGeneResult : \"\"\"Minimal data required from tool-specific output for gene prioritisation.\"\"\" gene_symbol : str gene_identifier : str score : float PhEvalVariantResult dataclass Minimal data required from tool-specific output for variant prioritisation. Source code in src/pheval/post_processing/post_processing.py 40 41 42 43 44 45 46 47 48 49 @dataclass class PhEvalVariantResult : \"\"\"Minimal data required from tool-specific output for variant prioritisation.\"\"\" chromosome : str start : int end : int ref : str alt : str score : float RankedPhEvalGeneResult dataclass PhEval gene result with corresponding rank. Source code in src/pheval/post_processing/post_processing.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @dataclass class RankedPhEvalGeneResult : \"\"\"PhEval gene result with corresponding rank.\"\"\" pheval_gene_result : PhEvalGeneResult rank : int def as_dict ( self ): \"\"\"Return PhEval gene result as dictionary.\"\"\" return { \"gene_symbol\" : self . pheval_gene_result . gene_symbol , \"gene_identifier\" : self . pheval_gene_result . gene_identifier , \"score\" : self . pheval_gene_result . score , \"rank\" : self . rank , } as_dict () Return PhEval gene result as dictionary. Source code in src/pheval/post_processing/post_processing.py 30 31 32 33 34 35 36 37 def as_dict ( self ): \"\"\"Return PhEval gene result as dictionary.\"\"\" return { \"gene_symbol\" : self . pheval_gene_result . gene_symbol , \"gene_identifier\" : self . pheval_gene_result . gene_identifier , \"score\" : self . pheval_gene_result . score , \"rank\" : self . rank , } RankedPhEvalVariantResult dataclass PhEval variant result with corresponding rank. Source code in src/pheval/post_processing/post_processing.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 @dataclass class RankedPhEvalVariantResult : \"\"\"PhEval variant result with corresponding rank.\"\"\" pheval_variant_result : PhEvalVariantResult rank : int def as_dict ( self ): \"\"\"Return PhEval variant result as dictionary.\"\"\" return { \"chromosome\" : self . pheval_variant_result . chromosome , \"start\" : self . pheval_variant_result . start , \"end\" : self . pheval_variant_result . end , \"ref\" : self . pheval_variant_result . ref , \"alt\" : self . pheval_variant_result . alt , \"score\" : self . pheval_variant_result . score , \"rank\" : self . rank , } as_dict () Return PhEval variant result as dictionary. Source code in src/pheval/post_processing/post_processing.py 59 60 61 62 63 64 65 66 67 68 69 def as_dict ( self ): \"\"\"Return PhEval variant result as dictionary.\"\"\" return { \"chromosome\" : self . pheval_variant_result . chromosome , \"start\" : self . pheval_variant_result . start , \"end\" : self . pheval_variant_result . end , \"ref\" : self . pheval_variant_result . ref , \"alt\" : self . pheval_variant_result . alt , \"score\" : self . pheval_variant_result . score , \"rank\" : self . rank , } ResultSorter Source code in src/pheval/post_processing/post_processing.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 class ResultSorter : def __init__ ( self , pheval_results : [ PhEvalGeneResult ] or [ PhEvalVariantResult ], sort_order : SortOrder ): self . pheval_results = pheval_results self . sort_order = sort_order def _sort_by_decreasing_score ( self ) -> [ PhEvalGeneResult ] or [ PhEvalVariantResult ]: \"\"\"Sort results in descending order.\"\"\" return sorted ( self . pheval_results , key = operator . attrgetter ( \"score\" ), reverse = True ) def _sort_by_increasing_score ( self ) -> [ PhEvalGeneResult ] or [ PhEvalVariantResult ]: \"\"\"Sort results in ascending order.\"\"\" return sorted ( self . pheval_results , key = operator . attrgetter ( \"score\" ), reverse = False ) def sort_pheval_results ( self ) -> [ PhEvalGeneResult ] or [ PhEvalVariantResult ]: \"\"\"Sort results with best score first.\"\"\" return ( self . _sort_by_increasing_score () if self . sort_order == SortOrder . ASCENDING else self . _sort_by_decreasing_score () ) sort_pheval_results () Sort results with best score first. Source code in src/pheval/post_processing/post_processing.py 92 93 94 95 96 97 98 def sort_pheval_results ( self ) -> [ PhEvalGeneResult ] or [ PhEvalVariantResult ]: \"\"\"Sort results with best score first.\"\"\" return ( self . _sort_by_increasing_score () if self . sort_order == SortOrder . ASCENDING else self . _sort_by_decreasing_score () ) ScoreRanker Source code in src/pheval/post_processing/post_processing.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 class ScoreRanker : rank : int = 0 current_score : float = float ( \"inf\" ) count : int = 0 def __init__ ( self , sort_order : SortOrder ): self . sort_order = sort_order def _check_rank_order ( self , round_score : float ) -> None : \"\"\"Check the results are correctly ordered.\"\"\" if self . sort_order == SortOrder . ASCENDING and round_score < self . current_score != float ( \"inf\" ): raise ValueError ( \"Results are not correctly sorted!\" ) elif self . sort_order == SortOrder . DESCENDING and round_score > self . current_score != float ( \"inf\" ): raise ValueError ( \"Results are not correctly sorted!\" ) def rank_scores ( self , round_score : float ) -> int : \"\"\"Add ranks to a result, equal scores are given the same rank e.g., 1,1,3.\"\"\" self . _check_rank_order ( round_score ) self . count += 1 if self . current_score == round_score : return self . rank self . current_score = round_score self . rank = self . count return self . rank rank_scores ( round_score ) Add ranks to a result, equal scores are given the same rank e.g., 1,1,3. Source code in src/pheval/post_processing/post_processing.py 120 121 122 123 124 125 126 127 128 def rank_scores ( self , round_score : float ) -> int : \"\"\"Add ranks to a result, equal scores are given the same rank e.g., 1,1,3.\"\"\" self . _check_rank_order ( round_score ) self . count += 1 if self . current_score == round_score : return self . rank self . current_score = round_score self . rank = self . count return self . rank calculate_end_pos ( variant_start , variant_ref ) Calculate the end position for a variant. Source code in src/pheval/post_processing/post_processing.py 9 10 11 def calculate_end_pos ( variant_start : int , variant_ref : str ) -> int : \"\"\"Calculate the end position for a variant.\"\"\" return variant_start + len ( variant_ref ) - 1 generate_pheval_result ( pheval_result , sort_order_str , output_dir , tool_result_path ) Generate either a PhEval variant or PhEval gene tsv result. Source code in src/pheval/post_processing/post_processing.py 200 201 202 203 204 205 206 207 208 209 210 def generate_pheval_result ( pheval_result : [ PhEvalGeneResult ] or [ PhEvalVariantResult ], sort_order_str : str , output_dir : Path , tool_result_path : Path , ): \"\"\"Generate either a PhEval variant or PhEval gene tsv result.\"\"\" ranked_pheval_result = _create_pheval_result ( pheval_result , sort_order_str ) _write_pheval_variant_result ( ranked_pheval_result , output_dir , tool_result_path ) if all ( isinstance ( result , RankedPhEvalVariantResult ) for result in ranked_pheval_result ) else _write_pheval_gene_result ( ranked_pheval_result , output_dir , tool_result_path )","title":"Post processing"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.PhEvalGeneResult","text":"Minimal data required from tool-specific output for gene prioritisation. Source code in src/pheval/post_processing/post_processing.py 14 15 16 17 18 19 20 @dataclass class PhEvalGeneResult : \"\"\"Minimal data required from tool-specific output for gene prioritisation.\"\"\" gene_symbol : str gene_identifier : str score : float","title":"PhEvalGeneResult"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.PhEvalVariantResult","text":"Minimal data required from tool-specific output for variant prioritisation. Source code in src/pheval/post_processing/post_processing.py 40 41 42 43 44 45 46 47 48 49 @dataclass class PhEvalVariantResult : \"\"\"Minimal data required from tool-specific output for variant prioritisation.\"\"\" chromosome : str start : int end : int ref : str alt : str score : float","title":"PhEvalVariantResult"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.RankedPhEvalGeneResult","text":"PhEval gene result with corresponding rank. Source code in src/pheval/post_processing/post_processing.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @dataclass class RankedPhEvalGeneResult : \"\"\"PhEval gene result with corresponding rank.\"\"\" pheval_gene_result : PhEvalGeneResult rank : int def as_dict ( self ): \"\"\"Return PhEval gene result as dictionary.\"\"\" return { \"gene_symbol\" : self . pheval_gene_result . gene_symbol , \"gene_identifier\" : self . pheval_gene_result . gene_identifier , \"score\" : self . pheval_gene_result . score , \"rank\" : self . rank , }","title":"RankedPhEvalGeneResult"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.RankedPhEvalGeneResult.as_dict","text":"Return PhEval gene result as dictionary. Source code in src/pheval/post_processing/post_processing.py 30 31 32 33 34 35 36 37 def as_dict ( self ): \"\"\"Return PhEval gene result as dictionary.\"\"\" return { \"gene_symbol\" : self . pheval_gene_result . gene_symbol , \"gene_identifier\" : self . pheval_gene_result . gene_identifier , \"score\" : self . pheval_gene_result . score , \"rank\" : self . rank , }","title":"as_dict()"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.RankedPhEvalVariantResult","text":"PhEval variant result with corresponding rank. Source code in src/pheval/post_processing/post_processing.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 @dataclass class RankedPhEvalVariantResult : \"\"\"PhEval variant result with corresponding rank.\"\"\" pheval_variant_result : PhEvalVariantResult rank : int def as_dict ( self ): \"\"\"Return PhEval variant result as dictionary.\"\"\" return { \"chromosome\" : self . pheval_variant_result . chromosome , \"start\" : self . pheval_variant_result . start , \"end\" : self . pheval_variant_result . end , \"ref\" : self . pheval_variant_result . ref , \"alt\" : self . pheval_variant_result . alt , \"score\" : self . pheval_variant_result . score , \"rank\" : self . rank , }","title":"RankedPhEvalVariantResult"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.RankedPhEvalVariantResult.as_dict","text":"Return PhEval variant result as dictionary. Source code in src/pheval/post_processing/post_processing.py 59 60 61 62 63 64 65 66 67 68 69 def as_dict ( self ): \"\"\"Return PhEval variant result as dictionary.\"\"\" return { \"chromosome\" : self . pheval_variant_result . chromosome , \"start\" : self . pheval_variant_result . start , \"end\" : self . pheval_variant_result . end , \"ref\" : self . pheval_variant_result . ref , \"alt\" : self . pheval_variant_result . alt , \"score\" : self . pheval_variant_result . score , \"rank\" : self . rank , }","title":"as_dict()"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.ResultSorter","text":"Source code in src/pheval/post_processing/post_processing.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 class ResultSorter : def __init__ ( self , pheval_results : [ PhEvalGeneResult ] or [ PhEvalVariantResult ], sort_order : SortOrder ): self . pheval_results = pheval_results self . sort_order = sort_order def _sort_by_decreasing_score ( self ) -> [ PhEvalGeneResult ] or [ PhEvalVariantResult ]: \"\"\"Sort results in descending order.\"\"\" return sorted ( self . pheval_results , key = operator . attrgetter ( \"score\" ), reverse = True ) def _sort_by_increasing_score ( self ) -> [ PhEvalGeneResult ] or [ PhEvalVariantResult ]: \"\"\"Sort results in ascending order.\"\"\" return sorted ( self . pheval_results , key = operator . attrgetter ( \"score\" ), reverse = False ) def sort_pheval_results ( self ) -> [ PhEvalGeneResult ] or [ PhEvalVariantResult ]: \"\"\"Sort results with best score first.\"\"\" return ( self . _sort_by_increasing_score () if self . sort_order == SortOrder . ASCENDING else self . _sort_by_decreasing_score () )","title":"ResultSorter"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.ResultSorter.sort_pheval_results","text":"Sort results with best score first. Source code in src/pheval/post_processing/post_processing.py 92 93 94 95 96 97 98 def sort_pheval_results ( self ) -> [ PhEvalGeneResult ] or [ PhEvalVariantResult ]: \"\"\"Sort results with best score first.\"\"\" return ( self . _sort_by_increasing_score () if self . sort_order == SortOrder . ASCENDING else self . _sort_by_decreasing_score () )","title":"sort_pheval_results()"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.ScoreRanker","text":"Source code in src/pheval/post_processing/post_processing.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 class ScoreRanker : rank : int = 0 current_score : float = float ( \"inf\" ) count : int = 0 def __init__ ( self , sort_order : SortOrder ): self . sort_order = sort_order def _check_rank_order ( self , round_score : float ) -> None : \"\"\"Check the results are correctly ordered.\"\"\" if self . sort_order == SortOrder . ASCENDING and round_score < self . current_score != float ( \"inf\" ): raise ValueError ( \"Results are not correctly sorted!\" ) elif self . sort_order == SortOrder . DESCENDING and round_score > self . current_score != float ( \"inf\" ): raise ValueError ( \"Results are not correctly sorted!\" ) def rank_scores ( self , round_score : float ) -> int : \"\"\"Add ranks to a result, equal scores are given the same rank e.g., 1,1,3.\"\"\" self . _check_rank_order ( round_score ) self . count += 1 if self . current_score == round_score : return self . rank self . current_score = round_score self . rank = self . count return self . rank","title":"ScoreRanker"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.ScoreRanker.rank_scores","text":"Add ranks to a result, equal scores are given the same rank e.g., 1,1,3. Source code in src/pheval/post_processing/post_processing.py 120 121 122 123 124 125 126 127 128 def rank_scores ( self , round_score : float ) -> int : \"\"\"Add ranks to a result, equal scores are given the same rank e.g., 1,1,3.\"\"\" self . _check_rank_order ( round_score ) self . count += 1 if self . current_score == round_score : return self . rank self . current_score = round_score self . rank = self . count return self . rank","title":"rank_scores()"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.calculate_end_pos","text":"Calculate the end position for a variant. Source code in src/pheval/post_processing/post_processing.py 9 10 11 def calculate_end_pos ( variant_start : int , variant_ref : str ) -> int : \"\"\"Calculate the end position for a variant.\"\"\" return variant_start + len ( variant_ref ) - 1","title":"calculate_end_pos()"},{"location":"api/pheval/post_processing/post_processing/#src.pheval.post_processing.post_processing.generate_pheval_result","text":"Generate either a PhEval variant or PhEval gene tsv result. Source code in src/pheval/post_processing/post_processing.py 200 201 202 203 204 205 206 207 208 209 210 def generate_pheval_result ( pheval_result : [ PhEvalGeneResult ] or [ PhEvalVariantResult ], sort_order_str : str , output_dir : Path , tool_result_path : Path , ): \"\"\"Generate either a PhEval variant or PhEval gene tsv result.\"\"\" ranked_pheval_result = _create_pheval_result ( pheval_result , sort_order_str ) _write_pheval_variant_result ( ranked_pheval_result , output_dir , tool_result_path ) if all ( isinstance ( result , RankedPhEvalVariantResult ) for result in ranked_pheval_result ) else _write_pheval_gene_result ( ranked_pheval_result , output_dir , tool_result_path )","title":"generate_pheval_result()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/","text":"HpoRandomiser Randomises phenopacket phenotypic features. Source code in src/pheval/prepare/create_noisy_phenopackets.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 class HpoRandomiser : \"\"\"Randomises phenopacket phenotypic features.\"\"\" def __init__ ( self , hpo_ontology , scramble_factor : float ): self . hpo_ontology = hpo_ontology self . phenotypic_abnormalities = set ( hpo_ontology . roots ( predicates = [ \"HP:0000118\" ])) self . scramble_factor = scramble_factor def scramble_factor_proportions ( self , phenotypic_features : list [ PhenotypicFeature ]): \"\"\"Calculate proportion of scrambled hpo terms from scramble factor.\"\"\" if len ( phenotypic_features ) == 1 : return 1 else : return int ( round ( len ( phenotypic_features ) * self . scramble_factor , 0 )) def retrieve_hpo_term ( self , hpo_id : str ) -> PhenotypicFeature : \"\"\"Retrieves term for hpo id.\"\"\" rels = self . hpo_ontology . entity_alias_map ( hpo_id ) hpo_term = \"\" . join ( rels [( list ( rels . keys ())[ 0 ])]) return PhenotypicFeature ( type = OntologyClass ( id = hpo_id , label = hpo_term )) @staticmethod def retain_real_patient_terms ( phenotypic_features : list [ PhenotypicFeature ], number_of_scrambled_terms : int , ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of the maximum number of real patient HPO terms.\"\"\" if len ( phenotypic_features ) > 1 : number_of_real_id = len ( phenotypic_features ) - number_of_scrambled_terms else : number_of_real_id = 1 return random . sample ( phenotypic_features , number_of_real_id ) def convert_patient_terms_to_parent ( self , phenotypic_features : list [ PhenotypicFeature ], retained_phenotypic_features : list [ PhenotypicFeature ], number_of_scrambled_terms : int , ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of the HPO terms that have been converted to a parent term.\"\"\" remaining_hpo = [ i for i in phenotypic_features if i not in retained_phenotypic_features ] if len ( remaining_hpo ) == 0 : number_of_scrambled_terms = 0 hpo_terms_to_be_changed = list ( random . sample ( remaining_hpo , number_of_scrambled_terms )) parent_terms = [] for term in hpo_terms_to_be_changed : try : parent_terms . append ( self . retrieve_hpo_term ( self . hpo_ontology . hierararchical_parents ( term . type . id )[ 0 ] ) ) except IndexError : obsolete_term = self . hpo_ontology . entity_metadata_map ( term . type . id ) updated_term = list ( obsolete_term . values ())[ 0 ][ 0 ] parent_terms . append ( self . retrieve_hpo_term ( self . hpo_ontology . hierararchical_parents ( updated_term )[ 0 ] ) ) return parent_terms def create_random_hpo_terms ( self , number_of_scrambled_terms : int ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of random HPO terms\"\"\" random_ids = list ( random . sample ( sorted ( self . phenotypic_abnormalities ), number_of_scrambled_terms ) ) return [ self . retrieve_hpo_term ( random_id ) for random_id in random_ids ] def randomise_hpo_terms ( self , phenotypic_features : list [ PhenotypicFeature ], ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of randomised HPO terms.\"\"\" number_of_scrambled_terms = self . scramble_factor_proportions ( phenotypic_features ) retained_patient_terms = self . retain_real_patient_terms ( phenotypic_features , number_of_scrambled_terms ) return ( retained_patient_terms + self . convert_patient_terms_to_parent ( phenotypic_features , retained_patient_terms , number_of_scrambled_terms ) + self . create_random_hpo_terms ( number_of_scrambled_terms ) ) convert_patient_terms_to_parent ( phenotypic_features , retained_phenotypic_features , number_of_scrambled_terms ) Returns a list of the HPO terms that have been converted to a parent term. Source code in src/pheval/prepare/create_noisy_phenopackets.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def convert_patient_terms_to_parent ( self , phenotypic_features : list [ PhenotypicFeature ], retained_phenotypic_features : list [ PhenotypicFeature ], number_of_scrambled_terms : int , ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of the HPO terms that have been converted to a parent term.\"\"\" remaining_hpo = [ i for i in phenotypic_features if i not in retained_phenotypic_features ] if len ( remaining_hpo ) == 0 : number_of_scrambled_terms = 0 hpo_terms_to_be_changed = list ( random . sample ( remaining_hpo , number_of_scrambled_terms )) parent_terms = [] for term in hpo_terms_to_be_changed : try : parent_terms . append ( self . retrieve_hpo_term ( self . hpo_ontology . hierararchical_parents ( term . type . id )[ 0 ] ) ) except IndexError : obsolete_term = self . hpo_ontology . entity_metadata_map ( term . type . id ) updated_term = list ( obsolete_term . values ())[ 0 ][ 0 ] parent_terms . append ( self . retrieve_hpo_term ( self . hpo_ontology . hierararchical_parents ( updated_term )[ 0 ] ) ) return parent_terms create_random_hpo_terms ( number_of_scrambled_terms ) Returns a list of random HPO terms Source code in src/pheval/prepare/create_noisy_phenopackets.py 85 86 87 88 89 90 def create_random_hpo_terms ( self , number_of_scrambled_terms : int ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of random HPO terms\"\"\" random_ids = list ( random . sample ( sorted ( self . phenotypic_abnormalities ), number_of_scrambled_terms ) ) return [ self . retrieve_hpo_term ( random_id ) for random_id in random_ids ] randomise_hpo_terms ( phenotypic_features ) Returns a list of randomised HPO terms. Source code in src/pheval/prepare/create_noisy_phenopackets.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 def randomise_hpo_terms ( self , phenotypic_features : list [ PhenotypicFeature ], ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of randomised HPO terms.\"\"\" number_of_scrambled_terms = self . scramble_factor_proportions ( phenotypic_features ) retained_patient_terms = self . retain_real_patient_terms ( phenotypic_features , number_of_scrambled_terms ) return ( retained_patient_terms + self . convert_patient_terms_to_parent ( phenotypic_features , retained_patient_terms , number_of_scrambled_terms ) + self . create_random_hpo_terms ( number_of_scrambled_terms ) ) retain_real_patient_terms ( phenotypic_features , number_of_scrambled_terms ) staticmethod Returns a list of the maximum number of real patient HPO terms. Source code in src/pheval/prepare/create_noisy_phenopackets.py 44 45 46 47 48 49 50 51 52 53 54 @staticmethod def retain_real_patient_terms ( phenotypic_features : list [ PhenotypicFeature ], number_of_scrambled_terms : int , ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of the maximum number of real patient HPO terms.\"\"\" if len ( phenotypic_features ) > 1 : number_of_real_id = len ( phenotypic_features ) - number_of_scrambled_terms else : number_of_real_id = 1 return random . sample ( phenotypic_features , number_of_real_id ) retrieve_hpo_term ( hpo_id ) Retrieves term for hpo id. Source code in src/pheval/prepare/create_noisy_phenopackets.py 38 39 40 41 42 def retrieve_hpo_term ( self , hpo_id : str ) -> PhenotypicFeature : \"\"\"Retrieves term for hpo id.\"\"\" rels = self . hpo_ontology . entity_alias_map ( hpo_id ) hpo_term = \"\" . join ( rels [( list ( rels . keys ())[ 0 ])]) return PhenotypicFeature ( type = OntologyClass ( id = hpo_id , label = hpo_term )) scramble_factor_proportions ( phenotypic_features ) Calculate proportion of scrambled hpo terms from scramble factor. Source code in src/pheval/prepare/create_noisy_phenopackets.py 31 32 33 34 35 36 def scramble_factor_proportions ( self , phenotypic_features : list [ PhenotypicFeature ]): \"\"\"Calculate proportion of scrambled hpo terms from scramble factor.\"\"\" if len ( phenotypic_features ) == 1 : return 1 else : return int ( round ( len ( phenotypic_features ) * self . scramble_factor , 0 )) add_noise_to_phenotypic_profile ( hpo_randomiser , phenopacket ) Randomises the phenotypic profile of a phenopacket. Source code in src/pheval/prepare/create_noisy_phenopackets.py 110 111 112 113 114 115 116 117 118 119 120 def add_noise_to_phenotypic_profile ( hpo_randomiser : HpoRandomiser , phenopacket : Phenopacket or Family , ) -> Phenopacket or Family : \"\"\"Randomises the phenotypic profile of a phenopacket.\"\"\" # phenopacket_util = PhenopacketUtil(phenopacket) # phenotypic_features = phenopacket_util.observed_phenotypic_features() phenotypic_features = PhenopacketUtil ( phenopacket ) . observed_phenotypic_features () random_phenotypes = hpo_randomiser . randomise_hpo_terms ( phenotypic_features ) randomised_phenopacket = PhenopacketRebuilder ( phenopacket ) . add_randomised_hpo ( random_phenotypes ) return randomised_phenopacket create_scrambled_phenopacket ( output_dir , phenopacket_path , scramble_factor ) Creates a scrambled phenopacket. Source code in src/pheval/prepare/create_noisy_phenopackets.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def create_scrambled_phenopacket ( output_dir : Path , phenopacket_path : Path , scramble_factor : float ) -> None : \"\"\"Creates a scrambled phenopacket.\"\"\" try : output_dir . mkdir () except FileExistsError : pass ontology = load_ontology () hpo_randomiser = HpoRandomiser ( ontology , scramble_factor ) phenopacket = phenopacket_reader ( phenopacket_path ) created_noisy_phenopacket = add_noise_to_phenotypic_profile ( hpo_randomiser , phenopacket , ) write_phenopacket ( created_noisy_phenopacket , output_dir . joinpath ( phenopacket_path . name ), ) create_scrambled_phenopackets ( output_dir , phenopacket_dir , scramble_factor ) Creates scrambled phenopackets. Source code in src/pheval/prepare/create_noisy_phenopackets.py 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 def create_scrambled_phenopackets ( output_dir : Path , phenopacket_dir : Path , scramble_factor : float ) -> None : \"\"\"Creates scrambled phenopackets.\"\"\" try : output_dir . mkdir () except FileExistsError : pass ontology = load_ontology () hpo_randomiser = HpoRandomiser ( ontology , scramble_factor ) phenopacket_files = files_with_suffix ( phenopacket_dir , \".json\" ) for phenopacket_path in phenopacket_files : phenopacket = phenopacket_reader ( phenopacket_path ) created_noisy_phenopacket = add_noise_to_phenotypic_profile ( hpo_randomiser , phenopacket ) write_phenopacket ( created_noisy_phenopacket , output_dir . joinpath ( phenopacket_path . name , ), ) load_ontology () Loads human phenotype ontology. Source code in src/pheval/prepare/create_noisy_phenopackets.py 17 18 19 20 def load_ontology (): \"\"\"Loads human phenotype ontology.\"\"\" resource = OntologyResource ( slug = \"hp.obo\" , local = False ) return ProntoImplementation ( resource ) scramble_phenopackets ( output_dir , phenopacket_path , phenopacket_dir , scramble_factor ) Create scrambled phenopackets from either a single phenopacket or directory of phenopackets. Source code in src/pheval/prepare/create_noisy_phenopackets.py 166 167 168 169 170 171 172 173 def scramble_phenopackets ( output_dir : Path , phenopacket_path : Path , phenopacket_dir : Path , scramble_factor : float ) -> None : \"\"\"Create scrambled phenopackets from either a single phenopacket or directory of phenopackets.\"\"\" if phenopacket_path is not None : create_scrambled_phenopacket ( output_dir , phenopacket_path , scramble_factor ) elif phenopacket_dir is not None : create_scrambled_phenopackets ( output_dir , phenopacket_dir , scramble_factor )","title":"Create noisy phenopackets"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.HpoRandomiser","text":"Randomises phenopacket phenotypic features. Source code in src/pheval/prepare/create_noisy_phenopackets.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 class HpoRandomiser : \"\"\"Randomises phenopacket phenotypic features.\"\"\" def __init__ ( self , hpo_ontology , scramble_factor : float ): self . hpo_ontology = hpo_ontology self . phenotypic_abnormalities = set ( hpo_ontology . roots ( predicates = [ \"HP:0000118\" ])) self . scramble_factor = scramble_factor def scramble_factor_proportions ( self , phenotypic_features : list [ PhenotypicFeature ]): \"\"\"Calculate proportion of scrambled hpo terms from scramble factor.\"\"\" if len ( phenotypic_features ) == 1 : return 1 else : return int ( round ( len ( phenotypic_features ) * self . scramble_factor , 0 )) def retrieve_hpo_term ( self , hpo_id : str ) -> PhenotypicFeature : \"\"\"Retrieves term for hpo id.\"\"\" rels = self . hpo_ontology . entity_alias_map ( hpo_id ) hpo_term = \"\" . join ( rels [( list ( rels . keys ())[ 0 ])]) return PhenotypicFeature ( type = OntologyClass ( id = hpo_id , label = hpo_term )) @staticmethod def retain_real_patient_terms ( phenotypic_features : list [ PhenotypicFeature ], number_of_scrambled_terms : int , ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of the maximum number of real patient HPO terms.\"\"\" if len ( phenotypic_features ) > 1 : number_of_real_id = len ( phenotypic_features ) - number_of_scrambled_terms else : number_of_real_id = 1 return random . sample ( phenotypic_features , number_of_real_id ) def convert_patient_terms_to_parent ( self , phenotypic_features : list [ PhenotypicFeature ], retained_phenotypic_features : list [ PhenotypicFeature ], number_of_scrambled_terms : int , ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of the HPO terms that have been converted to a parent term.\"\"\" remaining_hpo = [ i for i in phenotypic_features if i not in retained_phenotypic_features ] if len ( remaining_hpo ) == 0 : number_of_scrambled_terms = 0 hpo_terms_to_be_changed = list ( random . sample ( remaining_hpo , number_of_scrambled_terms )) parent_terms = [] for term in hpo_terms_to_be_changed : try : parent_terms . append ( self . retrieve_hpo_term ( self . hpo_ontology . hierararchical_parents ( term . type . id )[ 0 ] ) ) except IndexError : obsolete_term = self . hpo_ontology . entity_metadata_map ( term . type . id ) updated_term = list ( obsolete_term . values ())[ 0 ][ 0 ] parent_terms . append ( self . retrieve_hpo_term ( self . hpo_ontology . hierararchical_parents ( updated_term )[ 0 ] ) ) return parent_terms def create_random_hpo_terms ( self , number_of_scrambled_terms : int ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of random HPO terms\"\"\" random_ids = list ( random . sample ( sorted ( self . phenotypic_abnormalities ), number_of_scrambled_terms ) ) return [ self . retrieve_hpo_term ( random_id ) for random_id in random_ids ] def randomise_hpo_terms ( self , phenotypic_features : list [ PhenotypicFeature ], ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of randomised HPO terms.\"\"\" number_of_scrambled_terms = self . scramble_factor_proportions ( phenotypic_features ) retained_patient_terms = self . retain_real_patient_terms ( phenotypic_features , number_of_scrambled_terms ) return ( retained_patient_terms + self . convert_patient_terms_to_parent ( phenotypic_features , retained_patient_terms , number_of_scrambled_terms ) + self . create_random_hpo_terms ( number_of_scrambled_terms ) )","title":"HpoRandomiser"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.HpoRandomiser.convert_patient_terms_to_parent","text":"Returns a list of the HPO terms that have been converted to a parent term. Source code in src/pheval/prepare/create_noisy_phenopackets.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def convert_patient_terms_to_parent ( self , phenotypic_features : list [ PhenotypicFeature ], retained_phenotypic_features : list [ PhenotypicFeature ], number_of_scrambled_terms : int , ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of the HPO terms that have been converted to a parent term.\"\"\" remaining_hpo = [ i for i in phenotypic_features if i not in retained_phenotypic_features ] if len ( remaining_hpo ) == 0 : number_of_scrambled_terms = 0 hpo_terms_to_be_changed = list ( random . sample ( remaining_hpo , number_of_scrambled_terms )) parent_terms = [] for term in hpo_terms_to_be_changed : try : parent_terms . append ( self . retrieve_hpo_term ( self . hpo_ontology . hierararchical_parents ( term . type . id )[ 0 ] ) ) except IndexError : obsolete_term = self . hpo_ontology . entity_metadata_map ( term . type . id ) updated_term = list ( obsolete_term . values ())[ 0 ][ 0 ] parent_terms . append ( self . retrieve_hpo_term ( self . hpo_ontology . hierararchical_parents ( updated_term )[ 0 ] ) ) return parent_terms","title":"convert_patient_terms_to_parent()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.HpoRandomiser.create_random_hpo_terms","text":"Returns a list of random HPO terms Source code in src/pheval/prepare/create_noisy_phenopackets.py 85 86 87 88 89 90 def create_random_hpo_terms ( self , number_of_scrambled_terms : int ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of random HPO terms\"\"\" random_ids = list ( random . sample ( sorted ( self . phenotypic_abnormalities ), number_of_scrambled_terms ) ) return [ self . retrieve_hpo_term ( random_id ) for random_id in random_ids ]","title":"create_random_hpo_terms()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.HpoRandomiser.randomise_hpo_terms","text":"Returns a list of randomised HPO terms. Source code in src/pheval/prepare/create_noisy_phenopackets.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 def randomise_hpo_terms ( self , phenotypic_features : list [ PhenotypicFeature ], ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of randomised HPO terms.\"\"\" number_of_scrambled_terms = self . scramble_factor_proportions ( phenotypic_features ) retained_patient_terms = self . retain_real_patient_terms ( phenotypic_features , number_of_scrambled_terms ) return ( retained_patient_terms + self . convert_patient_terms_to_parent ( phenotypic_features , retained_patient_terms , number_of_scrambled_terms ) + self . create_random_hpo_terms ( number_of_scrambled_terms ) )","title":"randomise_hpo_terms()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.HpoRandomiser.retain_real_patient_terms","text":"Returns a list of the maximum number of real patient HPO terms. Source code in src/pheval/prepare/create_noisy_phenopackets.py 44 45 46 47 48 49 50 51 52 53 54 @staticmethod def retain_real_patient_terms ( phenotypic_features : list [ PhenotypicFeature ], number_of_scrambled_terms : int , ) -> list [ PhenotypicFeature ]: \"\"\"Returns a list of the maximum number of real patient HPO terms.\"\"\" if len ( phenotypic_features ) > 1 : number_of_real_id = len ( phenotypic_features ) - number_of_scrambled_terms else : number_of_real_id = 1 return random . sample ( phenotypic_features , number_of_real_id )","title":"retain_real_patient_terms()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.HpoRandomiser.retrieve_hpo_term","text":"Retrieves term for hpo id. Source code in src/pheval/prepare/create_noisy_phenopackets.py 38 39 40 41 42 def retrieve_hpo_term ( self , hpo_id : str ) -> PhenotypicFeature : \"\"\"Retrieves term for hpo id.\"\"\" rels = self . hpo_ontology . entity_alias_map ( hpo_id ) hpo_term = \"\" . join ( rels [( list ( rels . keys ())[ 0 ])]) return PhenotypicFeature ( type = OntologyClass ( id = hpo_id , label = hpo_term ))","title":"retrieve_hpo_term()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.HpoRandomiser.scramble_factor_proportions","text":"Calculate proportion of scrambled hpo terms from scramble factor. Source code in src/pheval/prepare/create_noisy_phenopackets.py 31 32 33 34 35 36 def scramble_factor_proportions ( self , phenotypic_features : list [ PhenotypicFeature ]): \"\"\"Calculate proportion of scrambled hpo terms from scramble factor.\"\"\" if len ( phenotypic_features ) == 1 : return 1 else : return int ( round ( len ( phenotypic_features ) * self . scramble_factor , 0 ))","title":"scramble_factor_proportions()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.add_noise_to_phenotypic_profile","text":"Randomises the phenotypic profile of a phenopacket. Source code in src/pheval/prepare/create_noisy_phenopackets.py 110 111 112 113 114 115 116 117 118 119 120 def add_noise_to_phenotypic_profile ( hpo_randomiser : HpoRandomiser , phenopacket : Phenopacket or Family , ) -> Phenopacket or Family : \"\"\"Randomises the phenotypic profile of a phenopacket.\"\"\" # phenopacket_util = PhenopacketUtil(phenopacket) # phenotypic_features = phenopacket_util.observed_phenotypic_features() phenotypic_features = PhenopacketUtil ( phenopacket ) . observed_phenotypic_features () random_phenotypes = hpo_randomiser . randomise_hpo_terms ( phenotypic_features ) randomised_phenopacket = PhenopacketRebuilder ( phenopacket ) . add_randomised_hpo ( random_phenotypes ) return randomised_phenopacket","title":"add_noise_to_phenotypic_profile()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.create_scrambled_phenopacket","text":"Creates a scrambled phenopacket. Source code in src/pheval/prepare/create_noisy_phenopackets.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def create_scrambled_phenopacket ( output_dir : Path , phenopacket_path : Path , scramble_factor : float ) -> None : \"\"\"Creates a scrambled phenopacket.\"\"\" try : output_dir . mkdir () except FileExistsError : pass ontology = load_ontology () hpo_randomiser = HpoRandomiser ( ontology , scramble_factor ) phenopacket = phenopacket_reader ( phenopacket_path ) created_noisy_phenopacket = add_noise_to_phenotypic_profile ( hpo_randomiser , phenopacket , ) write_phenopacket ( created_noisy_phenopacket , output_dir . joinpath ( phenopacket_path . name ), )","title":"create_scrambled_phenopacket()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.create_scrambled_phenopackets","text":"Creates scrambled phenopackets. Source code in src/pheval/prepare/create_noisy_phenopackets.py 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 def create_scrambled_phenopackets ( output_dir : Path , phenopacket_dir : Path , scramble_factor : float ) -> None : \"\"\"Creates scrambled phenopackets.\"\"\" try : output_dir . mkdir () except FileExistsError : pass ontology = load_ontology () hpo_randomiser = HpoRandomiser ( ontology , scramble_factor ) phenopacket_files = files_with_suffix ( phenopacket_dir , \".json\" ) for phenopacket_path in phenopacket_files : phenopacket = phenopacket_reader ( phenopacket_path ) created_noisy_phenopacket = add_noise_to_phenotypic_profile ( hpo_randomiser , phenopacket ) write_phenopacket ( created_noisy_phenopacket , output_dir . joinpath ( phenopacket_path . name , ), )","title":"create_scrambled_phenopackets()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.load_ontology","text":"Loads human phenotype ontology. Source code in src/pheval/prepare/create_noisy_phenopackets.py 17 18 19 20 def load_ontology (): \"\"\"Loads human phenotype ontology.\"\"\" resource = OntologyResource ( slug = \"hp.obo\" , local = False ) return ProntoImplementation ( resource )","title":"load_ontology()"},{"location":"api/pheval/prepare/create_noisy_phenopackets/#src.pheval.prepare.create_noisy_phenopackets.scramble_phenopackets","text":"Create scrambled phenopackets from either a single phenopacket or directory of phenopackets. Source code in src/pheval/prepare/create_noisy_phenopackets.py 166 167 168 169 170 171 172 173 def scramble_phenopackets ( output_dir : Path , phenopacket_path : Path , phenopacket_dir : Path , scramble_factor : float ) -> None : \"\"\"Create scrambled phenopackets from either a single phenopacket or directory of phenopackets.\"\"\" if phenopacket_path is not None : create_scrambled_phenopacket ( output_dir , phenopacket_path , scramble_factor ) elif phenopacket_dir is not None : create_scrambled_phenopackets ( output_dir , phenopacket_dir , scramble_factor )","title":"scramble_phenopackets()"},{"location":"api/pheval/prepare/create_spiked_vcf/","text":"VcfHeader dataclass Data obtained from VCF header Source code in src/pheval/prepare/create_spiked_vcf.py 79 80 81 82 83 84 85 @dataclass class VcfHeader : \"\"\"Data obtained from VCF header\"\"\" sample_id : str assembly : str chr_status : bool VcfHeaderParser Parses the header of a VCF file. Source code in src/pheval/prepare/create_spiked_vcf.py 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 class VcfHeaderParser : \"\"\"Parses the header of a VCF file.\"\"\" def __init__ ( self , vcf_contents : list [ str ]): self . vcf_contents = vcf_contents def parse_assembly ( self ) -> tuple [ str , bool ]: \"\"\"Parses the genome assembly and format of vcf_records.\"\"\" vcf_assembly = {} chr_status = False for line in self . vcf_contents : if line . startswith ( \"##contig=<ID\" ): tokens = line . split ( \",\" ) chromosome = re . sub ( r \"^.*?ID=\" , \"\" , [ token for token in tokens if \"ID=\" in token ][ 0 ] ) if \"chr\" in chromosome : chr_status = True chromosome = chromosome . replace ( \"chr\" , \"\" ) contig_length = re . sub ( \"[^0-9]+\" , \"\" , [ token for token in tokens if \"length=\" in token ][ 0 ], ) vcf_assembly [ chromosome ] = int ( contig_length ) vcf_assembly = { i : vcf_assembly [ i ] for i in vcf_assembly if i . isdigit ()} assembly = [ k for k , v in genome_assemblies . items () if v == vcf_assembly ][ 0 ] return assembly , chr_status def parse_sample_id ( self ) -> str : \"\"\"Parses the sample ID of the VCF.\"\"\" for line in self . vcf_contents : if line . startswith ( \"#CHROM\" ): return line . split ( \" \\t \" )[ 9 ] . rstrip () def parse_vcf_header ( self ) -> VcfHeader : \"\"\"Parses the header of the VCF.\"\"\" assembly , chr_status = self . parse_assembly () sample_id = self . parse_sample_id () return VcfHeader ( sample_id , assembly , chr_status ) parse_assembly () Parses the genome assembly and format of vcf_records. Source code in src/pheval/prepare/create_spiked_vcf.py 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 def parse_assembly ( self ) -> tuple [ str , bool ]: \"\"\"Parses the genome assembly and format of vcf_records.\"\"\" vcf_assembly = {} chr_status = False for line in self . vcf_contents : if line . startswith ( \"##contig=<ID\" ): tokens = line . split ( \",\" ) chromosome = re . sub ( r \"^.*?ID=\" , \"\" , [ token for token in tokens if \"ID=\" in token ][ 0 ] ) if \"chr\" in chromosome : chr_status = True chromosome = chromosome . replace ( \"chr\" , \"\" ) contig_length = re . sub ( \"[^0-9]+\" , \"\" , [ token for token in tokens if \"length=\" in token ][ 0 ], ) vcf_assembly [ chromosome ] = int ( contig_length ) vcf_assembly = { i : vcf_assembly [ i ] for i in vcf_assembly if i . isdigit ()} assembly = [ k for k , v in genome_assemblies . items () if v == vcf_assembly ][ 0 ] return assembly , chr_status parse_sample_id () Parses the sample ID of the VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 144 145 146 147 148 def parse_sample_id ( self ) -> str : \"\"\"Parses the sample ID of the VCF.\"\"\" for line in self . vcf_contents : if line . startswith ( \"#CHROM\" ): return line . split ( \" \\t \" )[ 9 ] . rstrip () parse_vcf_header () Parses the header of the VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 150 151 152 153 154 def parse_vcf_header ( self ) -> VcfHeader : \"\"\"Parses the header of the VCF.\"\"\" assembly , chr_status = self . parse_assembly () sample_id = self . parse_sample_id () return VcfHeader ( sample_id , assembly , chr_status ) VcfPicker Chooses a VCF file from random for a directory if provided, otherwise selects the single template. Source code in src/pheval/prepare/create_spiked_vcf.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 class VcfPicker : \"\"\"Chooses a VCF file from random for a directory if provided, otherwise selects the single template.\"\"\" def __init__ ( self , template_vcf : Path or None , vcf_dir : Path or None ): self . template_vcf = template_vcf self . vcf_dir = vcf_dir def pick_file_from_dir ( self ) -> Path : \"\"\"Selects a file from a directory at random.\"\"\" return secrets . choice ( all_files ( self . vcf_dir )) def pick_file ( self ) -> Path : \"\"\"Selects a VCF file from random when given a directory, if not, template vcf is assigned.\"\"\" return self . pick_file_from_dir () if self . vcf_dir is not None else self . template_vcf pick_file () Selects a VCF file from random when given a directory, if not, template vcf is assigned. Source code in src/pheval/prepare/create_spiked_vcf.py 99 100 101 def pick_file ( self ) -> Path : \"\"\"Selects a VCF file from random when given a directory, if not, template vcf is assigned.\"\"\" return self . pick_file_from_dir () if self . vcf_dir is not None else self . template_vcf pick_file_from_dir () Selects a file from a directory at random. Source code in src/pheval/prepare/create_spiked_vcf.py 95 96 97 def pick_file_from_dir ( self ) -> Path : \"\"\"Selects a file from a directory at random.\"\"\" return secrets . choice ( all_files ( self . vcf_dir )) VcfSpiker Spikes proband variants into template VCF file contents. Source code in src/pheval/prepare/create_spiked_vcf.py 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 class VcfSpiker : \"\"\"Spikes proband variants into template VCF file contents.\"\"\" def __init__ ( self , vcf_contents : list [ str ], proband_causative_variants : list [ ProbandCausativeVariant ], vcf_header : VcfHeader , ): self . vcf_contents = vcf_contents self . proband_causative_variants = proband_causative_variants self . vcf_header = vcf_header def construct_variant_entry ( self , proband_variant_data : ProbandCausativeVariant ) -> list [ str ]: \"\"\"Constructs variant entries.\"\"\" genotype_codes = { \"hemizygous\" : \"0/1\" , \"homozygous\" : \"1/1\" , \"heterozygous\" : \"0/1\" , \"compound heterozygous\" : \"0/1\" , } if self . vcf_header . chr_status is True and \"chr\" not in proband_variant_data . variant . chrom : proband_variant_data . variant . chrom = \"chr\" + proband_variant_data . variant . chrom return [ proband_variant_data . variant . chrom , str ( proband_variant_data . variant . pos ), \".\" , proband_variant_data . variant . ref , f \"< { proband_variant_data . variant . alt } >\" if proband_variant_data . variant . ref == \"N\" else proband_variant_data . variant . alt , \"100\" , \"PASS\" , proband_variant_data . info if proband_variant_data . info else \".\" , \"GT\" , genotype_codes [ proband_variant_data . genotype . lower ()] + \" \\n \" , ] def construct_vcf_records ( self ): \"\"\"Inserts spiked variant into correct position within VCF.\"\"\" updated_vcf_records = copy ( self . vcf_contents ) for variant in self . proband_causative_variants : variant = self . construct_variant_entry ( variant ) variant_entry_position = [ i for i , val in enumerate ( updated_vcf_records ) if val . split ( \" \\t \" )[ 0 ] == variant [ 0 ] and int ( val . split ( \" \\t \" )[ 1 ]) < int ( variant [ 1 ]) ][ - 1 ] + 1 updated_vcf_records . insert ( variant_entry_position , \" \\t \" . join ( variant )) return updated_vcf_records def construct_header ( self , updated_vcf_records ) -> list [ str ]: \"\"\"Constructs the header of the VCF.\"\"\" updated_vcf_file = [] for line in updated_vcf_records : text = line . replace ( self . vcf_header . sample_id , self . proband_causative_variants [ 0 ] . proband_id , ) updated_vcf_file . append ( text ) return updated_vcf_file def construct_vcf ( self ) -> list [ str ]: \"\"\"Constructs the entire spiked VCF.\"\"\" return self . construct_header ( self . construct_vcf_records ()) construct_header ( updated_vcf_records ) Constructs the header of the VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 226 227 228 229 230 231 232 233 234 235 def construct_header ( self , updated_vcf_records ) -> list [ str ]: \"\"\"Constructs the header of the VCF.\"\"\" updated_vcf_file = [] for line in updated_vcf_records : text = line . replace ( self . vcf_header . sample_id , self . proband_causative_variants [ 0 ] . proband_id , ) updated_vcf_file . append ( text ) return updated_vcf_file construct_variant_entry ( proband_variant_data ) Constructs variant entries. Source code in src/pheval/prepare/create_spiked_vcf.py 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 def construct_variant_entry ( self , proband_variant_data : ProbandCausativeVariant ) -> list [ str ]: \"\"\"Constructs variant entries.\"\"\" genotype_codes = { \"hemizygous\" : \"0/1\" , \"homozygous\" : \"1/1\" , \"heterozygous\" : \"0/1\" , \"compound heterozygous\" : \"0/1\" , } if self . vcf_header . chr_status is True and \"chr\" not in proband_variant_data . variant . chrom : proband_variant_data . variant . chrom = \"chr\" + proband_variant_data . variant . chrom return [ proband_variant_data . variant . chrom , str ( proband_variant_data . variant . pos ), \".\" , proband_variant_data . variant . ref , f \"< { proband_variant_data . variant . alt } >\" if proband_variant_data . variant . ref == \"N\" else proband_variant_data . variant . alt , \"100\" , \"PASS\" , proband_variant_data . info if proband_variant_data . info else \".\" , \"GT\" , genotype_codes [ proband_variant_data . genotype . lower ()] + \" \\n \" , ] construct_vcf () Constructs the entire spiked VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 237 238 239 def construct_vcf ( self ) -> list [ str ]: \"\"\"Constructs the entire spiked VCF.\"\"\" return self . construct_header ( self . construct_vcf_records ()) construct_vcf_records () Inserts spiked variant into correct position within VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 213 214 215 216 217 218 219 220 221 222 223 224 def construct_vcf_records ( self ): \"\"\"Inserts spiked variant into correct position within VCF.\"\"\" updated_vcf_records = copy ( self . vcf_contents ) for variant in self . proband_causative_variants : variant = self . construct_variant_entry ( variant ) variant_entry_position = [ i for i , val in enumerate ( updated_vcf_records ) if val . split ( \" \\t \" )[ 0 ] == variant [ 0 ] and int ( val . split ( \" \\t \" )[ 1 ]) < int ( variant [ 1 ]) ][ - 1 ] + 1 updated_vcf_records . insert ( variant_entry_position , \" \\t \" . join ( variant )) return updated_vcf_records VcfWriter Source code in src/pheval/prepare/create_spiked_vcf.py 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 class VcfWriter : def __init__ ( self , vcf_contents : list [ str ], spiked_vcf_file_path : Path , ): self . vcf_contents = vcf_contents self . spiked_vcf_file_path = spiked_vcf_file_path def write_gzip ( self ) -> None : \"\"\"Writes gzipped vcf file.\"\"\" encoded_contents = [ line . encode () for line in self . vcf_contents ] with gzip . open ( self . spiked_vcf_file_path , \"wb\" ) as f : for line in encoded_contents : f . write ( line ) f . close () def write_uncompressed ( self ) -> None : \"\"\"Writes an uncompressed vcf file.\"\"\" with open ( self . spiked_vcf_file_path , \"w\" ) as file : file . writelines ( self . vcf_contents ) file . close () def write_vcf_file ( self ) -> None : \"\"\"Writes spiked vcf file.\"\"\" self . write_gzip () if is_gzipped ( self . spiked_vcf_file_path ) else self . write_uncompressed () write_gzip () Writes gzipped vcf file. Source code in src/pheval/prepare/create_spiked_vcf.py 251 252 253 254 255 256 257 def write_gzip ( self ) -> None : \"\"\"Writes gzipped vcf file.\"\"\" encoded_contents = [ line . encode () for line in self . vcf_contents ] with gzip . open ( self . spiked_vcf_file_path , \"wb\" ) as f : for line in encoded_contents : f . write ( line ) f . close () write_uncompressed () Writes an uncompressed vcf file. Source code in src/pheval/prepare/create_spiked_vcf.py 259 260 261 262 263 def write_uncompressed ( self ) -> None : \"\"\"Writes an uncompressed vcf file.\"\"\" with open ( self . spiked_vcf_file_path , \"w\" ) as file : file . writelines ( self . vcf_contents ) file . close () write_vcf_file () Writes spiked vcf file. Source code in src/pheval/prepare/create_spiked_vcf.py 265 266 267 def write_vcf_file ( self ) -> None : \"\"\"Writes spiked vcf file.\"\"\" self . write_gzip () if is_gzipped ( self . spiked_vcf_file_path ) else self . write_uncompressed () check_variant_assembly ( proband_causative_variants , vcf_header , phenopacket_path ) Checks the assembly of the variant assembly against the VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 def check_variant_assembly ( proband_causative_variants : list [ ProbandCausativeVariant ], vcf_header : VcfHeader , phenopacket_path : Path , ): \"\"\"Checks the assembly of the variant assembly against the VCF.\"\"\" compatible_genome_assembly = { \"GRCh37\" , \"hg19\" , \"GRCh38\" , \"hg38\" } phenopacket_assembly = list ({ variant . assembly for variant in proband_causative_variants }) if len ( phenopacket_assembly ) > 1 : raise ValueError ( \"Too many genome assemblies!\" ) if phenopacket_assembly [ 0 ] not in compatible_genome_assembly : raise IncompatibleGenomeAssemblyError ( phenopacket_assembly , phenopacket_path ) if phenopacket_assembly [ 0 ] != vcf_header . assembly : raise IncompatibleGenomeAssemblyError ( assembly = phenopacket_assembly , phenopacket = phenopacket_path ) create_spiked_vcf ( output_dir , phenopacket_path , template_vcf_path , vcf_dir ) Creates a spiked vcf for a phenopacket. Source code in src/pheval/prepare/create_spiked_vcf.py 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 def create_spiked_vcf ( output_dir : Path , phenopacket_path : Path , template_vcf_path : Path , vcf_dir : Path ): \"\"\"Creates a spiked vcf for a phenopacket.\"\"\" if template_vcf_path is None and vcf_dir is None : raise InputError ( \"Either a template_vcf or vcf_dir must be specified\" ) vcf_file_path = VcfPicker ( template_vcf_path , vcf_dir ) . pick_file () phenopacket = phenopacket_reader ( phenopacket_path ) spiked_vcf_file_message = generate_spiked_vcf_file ( output_dir , phenopacket , phenopacket_path , vcf_file_path ) updated_phenopacket = PhenopacketRebuilder ( phenopacket ) . add_spiked_vcf_path ( spiked_vcf_file_message ) write_phenopacket ( updated_phenopacket , phenopacket_path ) create_spiked_vcfs ( output_dir , phenopacket_dir , template_vcf_path , vcf_dir ) Creates spiked vcfs for phenopackets. Source code in src/pheval/prepare/create_spiked_vcf.py 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 def create_spiked_vcfs ( output_dir : Path , phenopacket_dir : Path , template_vcf_path : Path , vcf_dir : Path ): \"\"\"Creates spiked vcfs for phenopackets.\"\"\" if template_vcf_path is None and vcf_dir is None : raise InputError ( \"Either a template_vcf or vcf_dir must be specified\" ) for phenopacket_path in files_with_suffix ( phenopacket_dir , \".json\" ): vcf_file_path = VcfPicker ( template_vcf_path , vcf_dir ) . pick_file () phenopacket = phenopacket_reader ( phenopacket_path ) spiked_vcf_file_message = generate_spiked_vcf_file ( output_dir , phenopacket , phenopacket_path , vcf_file_path ) updated_phenopacket = PhenopacketRebuilder ( phenopacket ) . add_spiked_vcf_path ( spiked_vcf_file_message ) write_phenopacket ( updated_phenopacket , phenopacket_path ) generate_spiked_vcf_file ( output_dir , phenopacket , phenopacket_path , chosen_template_vcf ) Writes spiked vcf contents to a new file. Source code in src/pheval/prepare/create_spiked_vcf.py 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 def generate_spiked_vcf_file ( output_dir : Path , phenopacket : Phenopacket or Family , phenopacket_path : Path , chosen_template_vcf : Path , ) -> File : \"\"\"Writes spiked vcf contents to a new file.\"\"\" try : output_dir . mkdir () info_log . info ( f \" Created a directory { output_dir } \" ) except FileExistsError : pass vcf_assembly , spiked_vcf = spike_vcf_contents ( phenopacket , phenopacket_path , chosen_template_vcf ) spiked_vcf_path = ( output_dir . joinpath ( phenopacket_path . name . replace ( \".json\" , \".vcf.gz\" )) if is_gzipped ( chosen_template_vcf ) else output_dir . joinpath ( phenopacket_path . name . replace ( \".json\" , \".vcf\" )) ) VcfWriter ( spiked_vcf , spiked_vcf_path ) . write_vcf_file () return File ( uri = urllib . parse . unquote ( spiked_vcf_path . as_uri ()), file_attributes = { \"fileFormat\" : \"vcf\" , \"genomeAssembly\" : vcf_assembly }, ) read_vcf ( vcf_file ) Reads the contents of a VCF file into memory - handles both uncompressed and gzipped. Source code in src/pheval/prepare/create_spiked_vcf.py 104 105 106 107 108 109 110 111 112 def read_vcf ( vcf_file : Path ) -> list [ str ]: \"\"\"Reads the contents of a VCF file into memory - handles both uncompressed and gzipped.\"\"\" open_fn = gzip . open if is_gzipped ( vcf_file ) else open vcf = open_fn ( vcf_file ) vcf_contents = ( [ line . decode () for line in vcf . readlines ()] if is_gzipped ( vcf_file ) else vcf . readlines () ) vcf . close () return vcf_contents spike_vcf_contents ( phenopacket , phenopacket_path , chosen_template_vcf ) Spikes VCF records with variants. Source code in src/pheval/prepare/create_spiked_vcf.py 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 def spike_vcf_contents ( phenopacket : Phenopacket or Family , phenopacket_path : Path , chosen_template_vcf : Path , ) -> tuple [ str , list [ str ]]: \"\"\"Spikes VCF records with variants.\"\"\" # this is a separate function to a click command as it will fail if annotated with click annotations # and referenced from another click command phenopacket_causative_variants = PhenopacketUtil ( phenopacket ) . causative_variants () vcf_contents = read_vcf ( chosen_template_vcf ) vcf_header = VcfHeaderParser ( vcf_contents ) . parse_vcf_header () check_variant_assembly ( phenopacket_causative_variants , vcf_header , phenopacket_path ) return ( vcf_header . assembly , VcfSpiker ( vcf_contents , phenopacket_causative_variants , vcf_header ) . construct_vcf (), ) spike_vcfs ( output_dir , phenopacket_path , phenopacket_dir , template_vcf_path , vcf_dir ) Create spiked VCF from either a phenopacket or a phenopacket directory. Source code in src/pheval/prepare/create_spiked_vcf.py 353 354 355 356 357 358 359 360 361 362 363 364 def spike_vcfs ( output_dir : Path , phenopacket_path : Path , phenopacket_dir : Path , template_vcf_path : Path , vcf_dir : Path , ): \"\"\"Create spiked VCF from either a phenopacket or a phenopacket directory.\"\"\" if phenopacket_path is not None : create_spiked_vcf ( output_dir , phenopacket_path , template_vcf_path , vcf_dir ) elif phenopacket_dir is not None : create_spiked_vcfs ( output_dir , phenopacket_dir , template_vcf_path , vcf_dir )","title":"Create spiked vcf"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfHeader","text":"Data obtained from VCF header Source code in src/pheval/prepare/create_spiked_vcf.py 79 80 81 82 83 84 85 @dataclass class VcfHeader : \"\"\"Data obtained from VCF header\"\"\" sample_id : str assembly : str chr_status : bool","title":"VcfHeader"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfHeaderParser","text":"Parses the header of a VCF file. Source code in src/pheval/prepare/create_spiked_vcf.py 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 class VcfHeaderParser : \"\"\"Parses the header of a VCF file.\"\"\" def __init__ ( self , vcf_contents : list [ str ]): self . vcf_contents = vcf_contents def parse_assembly ( self ) -> tuple [ str , bool ]: \"\"\"Parses the genome assembly and format of vcf_records.\"\"\" vcf_assembly = {} chr_status = False for line in self . vcf_contents : if line . startswith ( \"##contig=<ID\" ): tokens = line . split ( \",\" ) chromosome = re . sub ( r \"^.*?ID=\" , \"\" , [ token for token in tokens if \"ID=\" in token ][ 0 ] ) if \"chr\" in chromosome : chr_status = True chromosome = chromosome . replace ( \"chr\" , \"\" ) contig_length = re . sub ( \"[^0-9]+\" , \"\" , [ token for token in tokens if \"length=\" in token ][ 0 ], ) vcf_assembly [ chromosome ] = int ( contig_length ) vcf_assembly = { i : vcf_assembly [ i ] for i in vcf_assembly if i . isdigit ()} assembly = [ k for k , v in genome_assemblies . items () if v == vcf_assembly ][ 0 ] return assembly , chr_status def parse_sample_id ( self ) -> str : \"\"\"Parses the sample ID of the VCF.\"\"\" for line in self . vcf_contents : if line . startswith ( \"#CHROM\" ): return line . split ( \" \\t \" )[ 9 ] . rstrip () def parse_vcf_header ( self ) -> VcfHeader : \"\"\"Parses the header of the VCF.\"\"\" assembly , chr_status = self . parse_assembly () sample_id = self . parse_sample_id () return VcfHeader ( sample_id , assembly , chr_status )","title":"VcfHeaderParser"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfHeaderParser.parse_assembly","text":"Parses the genome assembly and format of vcf_records. Source code in src/pheval/prepare/create_spiked_vcf.py 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 def parse_assembly ( self ) -> tuple [ str , bool ]: \"\"\"Parses the genome assembly and format of vcf_records.\"\"\" vcf_assembly = {} chr_status = False for line in self . vcf_contents : if line . startswith ( \"##contig=<ID\" ): tokens = line . split ( \",\" ) chromosome = re . sub ( r \"^.*?ID=\" , \"\" , [ token for token in tokens if \"ID=\" in token ][ 0 ] ) if \"chr\" in chromosome : chr_status = True chromosome = chromosome . replace ( \"chr\" , \"\" ) contig_length = re . sub ( \"[^0-9]+\" , \"\" , [ token for token in tokens if \"length=\" in token ][ 0 ], ) vcf_assembly [ chromosome ] = int ( contig_length ) vcf_assembly = { i : vcf_assembly [ i ] for i in vcf_assembly if i . isdigit ()} assembly = [ k for k , v in genome_assemblies . items () if v == vcf_assembly ][ 0 ] return assembly , chr_status","title":"parse_assembly()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfHeaderParser.parse_sample_id","text":"Parses the sample ID of the VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 144 145 146 147 148 def parse_sample_id ( self ) -> str : \"\"\"Parses the sample ID of the VCF.\"\"\" for line in self . vcf_contents : if line . startswith ( \"#CHROM\" ): return line . split ( \" \\t \" )[ 9 ] . rstrip ()","title":"parse_sample_id()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfHeaderParser.parse_vcf_header","text":"Parses the header of the VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 150 151 152 153 154 def parse_vcf_header ( self ) -> VcfHeader : \"\"\"Parses the header of the VCF.\"\"\" assembly , chr_status = self . parse_assembly () sample_id = self . parse_sample_id () return VcfHeader ( sample_id , assembly , chr_status )","title":"parse_vcf_header()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfPicker","text":"Chooses a VCF file from random for a directory if provided, otherwise selects the single template. Source code in src/pheval/prepare/create_spiked_vcf.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 class VcfPicker : \"\"\"Chooses a VCF file from random for a directory if provided, otherwise selects the single template.\"\"\" def __init__ ( self , template_vcf : Path or None , vcf_dir : Path or None ): self . template_vcf = template_vcf self . vcf_dir = vcf_dir def pick_file_from_dir ( self ) -> Path : \"\"\"Selects a file from a directory at random.\"\"\" return secrets . choice ( all_files ( self . vcf_dir )) def pick_file ( self ) -> Path : \"\"\"Selects a VCF file from random when given a directory, if not, template vcf is assigned.\"\"\" return self . pick_file_from_dir () if self . vcf_dir is not None else self . template_vcf","title":"VcfPicker"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfPicker.pick_file","text":"Selects a VCF file from random when given a directory, if not, template vcf is assigned. Source code in src/pheval/prepare/create_spiked_vcf.py 99 100 101 def pick_file ( self ) -> Path : \"\"\"Selects a VCF file from random when given a directory, if not, template vcf is assigned.\"\"\" return self . pick_file_from_dir () if self . vcf_dir is not None else self . template_vcf","title":"pick_file()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfPicker.pick_file_from_dir","text":"Selects a file from a directory at random. Source code in src/pheval/prepare/create_spiked_vcf.py 95 96 97 def pick_file_from_dir ( self ) -> Path : \"\"\"Selects a file from a directory at random.\"\"\" return secrets . choice ( all_files ( self . vcf_dir ))","title":"pick_file_from_dir()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfSpiker","text":"Spikes proband variants into template VCF file contents. Source code in src/pheval/prepare/create_spiked_vcf.py 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 class VcfSpiker : \"\"\"Spikes proband variants into template VCF file contents.\"\"\" def __init__ ( self , vcf_contents : list [ str ], proband_causative_variants : list [ ProbandCausativeVariant ], vcf_header : VcfHeader , ): self . vcf_contents = vcf_contents self . proband_causative_variants = proband_causative_variants self . vcf_header = vcf_header def construct_variant_entry ( self , proband_variant_data : ProbandCausativeVariant ) -> list [ str ]: \"\"\"Constructs variant entries.\"\"\" genotype_codes = { \"hemizygous\" : \"0/1\" , \"homozygous\" : \"1/1\" , \"heterozygous\" : \"0/1\" , \"compound heterozygous\" : \"0/1\" , } if self . vcf_header . chr_status is True and \"chr\" not in proband_variant_data . variant . chrom : proband_variant_data . variant . chrom = \"chr\" + proband_variant_data . variant . chrom return [ proband_variant_data . variant . chrom , str ( proband_variant_data . variant . pos ), \".\" , proband_variant_data . variant . ref , f \"< { proband_variant_data . variant . alt } >\" if proband_variant_data . variant . ref == \"N\" else proband_variant_data . variant . alt , \"100\" , \"PASS\" , proband_variant_data . info if proband_variant_data . info else \".\" , \"GT\" , genotype_codes [ proband_variant_data . genotype . lower ()] + \" \\n \" , ] def construct_vcf_records ( self ): \"\"\"Inserts spiked variant into correct position within VCF.\"\"\" updated_vcf_records = copy ( self . vcf_contents ) for variant in self . proband_causative_variants : variant = self . construct_variant_entry ( variant ) variant_entry_position = [ i for i , val in enumerate ( updated_vcf_records ) if val . split ( \" \\t \" )[ 0 ] == variant [ 0 ] and int ( val . split ( \" \\t \" )[ 1 ]) < int ( variant [ 1 ]) ][ - 1 ] + 1 updated_vcf_records . insert ( variant_entry_position , \" \\t \" . join ( variant )) return updated_vcf_records def construct_header ( self , updated_vcf_records ) -> list [ str ]: \"\"\"Constructs the header of the VCF.\"\"\" updated_vcf_file = [] for line in updated_vcf_records : text = line . replace ( self . vcf_header . sample_id , self . proband_causative_variants [ 0 ] . proband_id , ) updated_vcf_file . append ( text ) return updated_vcf_file def construct_vcf ( self ) -> list [ str ]: \"\"\"Constructs the entire spiked VCF.\"\"\" return self . construct_header ( self . construct_vcf_records ())","title":"VcfSpiker"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfSpiker.construct_header","text":"Constructs the header of the VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 226 227 228 229 230 231 232 233 234 235 def construct_header ( self , updated_vcf_records ) -> list [ str ]: \"\"\"Constructs the header of the VCF.\"\"\" updated_vcf_file = [] for line in updated_vcf_records : text = line . replace ( self . vcf_header . sample_id , self . proband_causative_variants [ 0 ] . proband_id , ) updated_vcf_file . append ( text ) return updated_vcf_file","title":"construct_header()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfSpiker.construct_variant_entry","text":"Constructs variant entries. Source code in src/pheval/prepare/create_spiked_vcf.py 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 def construct_variant_entry ( self , proband_variant_data : ProbandCausativeVariant ) -> list [ str ]: \"\"\"Constructs variant entries.\"\"\" genotype_codes = { \"hemizygous\" : \"0/1\" , \"homozygous\" : \"1/1\" , \"heterozygous\" : \"0/1\" , \"compound heterozygous\" : \"0/1\" , } if self . vcf_header . chr_status is True and \"chr\" not in proband_variant_data . variant . chrom : proband_variant_data . variant . chrom = \"chr\" + proband_variant_data . variant . chrom return [ proband_variant_data . variant . chrom , str ( proband_variant_data . variant . pos ), \".\" , proband_variant_data . variant . ref , f \"< { proband_variant_data . variant . alt } >\" if proband_variant_data . variant . ref == \"N\" else proband_variant_data . variant . alt , \"100\" , \"PASS\" , proband_variant_data . info if proband_variant_data . info else \".\" , \"GT\" , genotype_codes [ proband_variant_data . genotype . lower ()] + \" \\n \" , ]","title":"construct_variant_entry()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfSpiker.construct_vcf","text":"Constructs the entire spiked VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 237 238 239 def construct_vcf ( self ) -> list [ str ]: \"\"\"Constructs the entire spiked VCF.\"\"\" return self . construct_header ( self . construct_vcf_records ())","title":"construct_vcf()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfSpiker.construct_vcf_records","text":"Inserts spiked variant into correct position within VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 213 214 215 216 217 218 219 220 221 222 223 224 def construct_vcf_records ( self ): \"\"\"Inserts spiked variant into correct position within VCF.\"\"\" updated_vcf_records = copy ( self . vcf_contents ) for variant in self . proband_causative_variants : variant = self . construct_variant_entry ( variant ) variant_entry_position = [ i for i , val in enumerate ( updated_vcf_records ) if val . split ( \" \\t \" )[ 0 ] == variant [ 0 ] and int ( val . split ( \" \\t \" )[ 1 ]) < int ( variant [ 1 ]) ][ - 1 ] + 1 updated_vcf_records . insert ( variant_entry_position , \" \\t \" . join ( variant )) return updated_vcf_records","title":"construct_vcf_records()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfWriter","text":"Source code in src/pheval/prepare/create_spiked_vcf.py 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 class VcfWriter : def __init__ ( self , vcf_contents : list [ str ], spiked_vcf_file_path : Path , ): self . vcf_contents = vcf_contents self . spiked_vcf_file_path = spiked_vcf_file_path def write_gzip ( self ) -> None : \"\"\"Writes gzipped vcf file.\"\"\" encoded_contents = [ line . encode () for line in self . vcf_contents ] with gzip . open ( self . spiked_vcf_file_path , \"wb\" ) as f : for line in encoded_contents : f . write ( line ) f . close () def write_uncompressed ( self ) -> None : \"\"\"Writes an uncompressed vcf file.\"\"\" with open ( self . spiked_vcf_file_path , \"w\" ) as file : file . writelines ( self . vcf_contents ) file . close () def write_vcf_file ( self ) -> None : \"\"\"Writes spiked vcf file.\"\"\" self . write_gzip () if is_gzipped ( self . spiked_vcf_file_path ) else self . write_uncompressed ()","title":"VcfWriter"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfWriter.write_gzip","text":"Writes gzipped vcf file. Source code in src/pheval/prepare/create_spiked_vcf.py 251 252 253 254 255 256 257 def write_gzip ( self ) -> None : \"\"\"Writes gzipped vcf file.\"\"\" encoded_contents = [ line . encode () for line in self . vcf_contents ] with gzip . open ( self . spiked_vcf_file_path , \"wb\" ) as f : for line in encoded_contents : f . write ( line ) f . close ()","title":"write_gzip()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfWriter.write_uncompressed","text":"Writes an uncompressed vcf file. Source code in src/pheval/prepare/create_spiked_vcf.py 259 260 261 262 263 def write_uncompressed ( self ) -> None : \"\"\"Writes an uncompressed vcf file.\"\"\" with open ( self . spiked_vcf_file_path , \"w\" ) as file : file . writelines ( self . vcf_contents ) file . close ()","title":"write_uncompressed()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.VcfWriter.write_vcf_file","text":"Writes spiked vcf file. Source code in src/pheval/prepare/create_spiked_vcf.py 265 266 267 def write_vcf_file ( self ) -> None : \"\"\"Writes spiked vcf file.\"\"\" self . write_gzip () if is_gzipped ( self . spiked_vcf_file_path ) else self . write_uncompressed ()","title":"write_vcf_file()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.check_variant_assembly","text":"Checks the assembly of the variant assembly against the VCF. Source code in src/pheval/prepare/create_spiked_vcf.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 def check_variant_assembly ( proband_causative_variants : list [ ProbandCausativeVariant ], vcf_header : VcfHeader , phenopacket_path : Path , ): \"\"\"Checks the assembly of the variant assembly against the VCF.\"\"\" compatible_genome_assembly = { \"GRCh37\" , \"hg19\" , \"GRCh38\" , \"hg38\" } phenopacket_assembly = list ({ variant . assembly for variant in proband_causative_variants }) if len ( phenopacket_assembly ) > 1 : raise ValueError ( \"Too many genome assemblies!\" ) if phenopacket_assembly [ 0 ] not in compatible_genome_assembly : raise IncompatibleGenomeAssemblyError ( phenopacket_assembly , phenopacket_path ) if phenopacket_assembly [ 0 ] != vcf_header . assembly : raise IncompatibleGenomeAssemblyError ( assembly = phenopacket_assembly , phenopacket = phenopacket_path )","title":"check_variant_assembly()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.create_spiked_vcf","text":"Creates a spiked vcf for a phenopacket. Source code in src/pheval/prepare/create_spiked_vcf.py 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 def create_spiked_vcf ( output_dir : Path , phenopacket_path : Path , template_vcf_path : Path , vcf_dir : Path ): \"\"\"Creates a spiked vcf for a phenopacket.\"\"\" if template_vcf_path is None and vcf_dir is None : raise InputError ( \"Either a template_vcf or vcf_dir must be specified\" ) vcf_file_path = VcfPicker ( template_vcf_path , vcf_dir ) . pick_file () phenopacket = phenopacket_reader ( phenopacket_path ) spiked_vcf_file_message = generate_spiked_vcf_file ( output_dir , phenopacket , phenopacket_path , vcf_file_path ) updated_phenopacket = PhenopacketRebuilder ( phenopacket ) . add_spiked_vcf_path ( spiked_vcf_file_message ) write_phenopacket ( updated_phenopacket , phenopacket_path )","title":"create_spiked_vcf()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.create_spiked_vcfs","text":"Creates spiked vcfs for phenopackets. Source code in src/pheval/prepare/create_spiked_vcf.py 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 def create_spiked_vcfs ( output_dir : Path , phenopacket_dir : Path , template_vcf_path : Path , vcf_dir : Path ): \"\"\"Creates spiked vcfs for phenopackets.\"\"\" if template_vcf_path is None and vcf_dir is None : raise InputError ( \"Either a template_vcf or vcf_dir must be specified\" ) for phenopacket_path in files_with_suffix ( phenopacket_dir , \".json\" ): vcf_file_path = VcfPicker ( template_vcf_path , vcf_dir ) . pick_file () phenopacket = phenopacket_reader ( phenopacket_path ) spiked_vcf_file_message = generate_spiked_vcf_file ( output_dir , phenopacket , phenopacket_path , vcf_file_path ) updated_phenopacket = PhenopacketRebuilder ( phenopacket ) . add_spiked_vcf_path ( spiked_vcf_file_message ) write_phenopacket ( updated_phenopacket , phenopacket_path )","title":"create_spiked_vcfs()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.generate_spiked_vcf_file","text":"Writes spiked vcf contents to a new file. Source code in src/pheval/prepare/create_spiked_vcf.py 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 def generate_spiked_vcf_file ( output_dir : Path , phenopacket : Phenopacket or Family , phenopacket_path : Path , chosen_template_vcf : Path , ) -> File : \"\"\"Writes spiked vcf contents to a new file.\"\"\" try : output_dir . mkdir () info_log . info ( f \" Created a directory { output_dir } \" ) except FileExistsError : pass vcf_assembly , spiked_vcf = spike_vcf_contents ( phenopacket , phenopacket_path , chosen_template_vcf ) spiked_vcf_path = ( output_dir . joinpath ( phenopacket_path . name . replace ( \".json\" , \".vcf.gz\" )) if is_gzipped ( chosen_template_vcf ) else output_dir . joinpath ( phenopacket_path . name . replace ( \".json\" , \".vcf\" )) ) VcfWriter ( spiked_vcf , spiked_vcf_path ) . write_vcf_file () return File ( uri = urllib . parse . unquote ( spiked_vcf_path . as_uri ()), file_attributes = { \"fileFormat\" : \"vcf\" , \"genomeAssembly\" : vcf_assembly }, )","title":"generate_spiked_vcf_file()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.read_vcf","text":"Reads the contents of a VCF file into memory - handles both uncompressed and gzipped. Source code in src/pheval/prepare/create_spiked_vcf.py 104 105 106 107 108 109 110 111 112 def read_vcf ( vcf_file : Path ) -> list [ str ]: \"\"\"Reads the contents of a VCF file into memory - handles both uncompressed and gzipped.\"\"\" open_fn = gzip . open if is_gzipped ( vcf_file ) else open vcf = open_fn ( vcf_file ) vcf_contents = ( [ line . decode () for line in vcf . readlines ()] if is_gzipped ( vcf_file ) else vcf . readlines () ) vcf . close () return vcf_contents","title":"read_vcf()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.spike_vcf_contents","text":"Spikes VCF records with variants. Source code in src/pheval/prepare/create_spiked_vcf.py 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 def spike_vcf_contents ( phenopacket : Phenopacket or Family , phenopacket_path : Path , chosen_template_vcf : Path , ) -> tuple [ str , list [ str ]]: \"\"\"Spikes VCF records with variants.\"\"\" # this is a separate function to a click command as it will fail if annotated with click annotations # and referenced from another click command phenopacket_causative_variants = PhenopacketUtil ( phenopacket ) . causative_variants () vcf_contents = read_vcf ( chosen_template_vcf ) vcf_header = VcfHeaderParser ( vcf_contents ) . parse_vcf_header () check_variant_assembly ( phenopacket_causative_variants , vcf_header , phenopacket_path ) return ( vcf_header . assembly , VcfSpiker ( vcf_contents , phenopacket_causative_variants , vcf_header ) . construct_vcf (), )","title":"spike_vcf_contents()"},{"location":"api/pheval/prepare/create_spiked_vcf/#src.pheval.prepare.create_spiked_vcf.spike_vcfs","text":"Create spiked VCF from either a phenopacket or a phenopacket directory. Source code in src/pheval/prepare/create_spiked_vcf.py 353 354 355 356 357 358 359 360 361 362 363 364 def spike_vcfs ( output_dir : Path , phenopacket_path : Path , phenopacket_dir : Path , template_vcf_path : Path , vcf_dir : Path , ): \"\"\"Create spiked VCF from either a phenopacket or a phenopacket directory.\"\"\" if phenopacket_path is not None : create_spiked_vcf ( output_dir , phenopacket_path , template_vcf_path , vcf_dir ) elif phenopacket_dir is not None : create_spiked_vcfs ( output_dir , phenopacket_dir , template_vcf_path , vcf_dir )","title":"spike_vcfs()"},{"location":"api/pheval/prepare/custom_exceptions/","text":"InputError Bases: Exception Exception raised for missing required inputs. Source code in src/pheval/prepare/custom_exceptions.py 4 5 6 7 8 9 10 11 12 13 class InputError ( Exception ): \"\"\"Exception raised for missing required inputs.\"\"\" def __init__ ( self , file , message = \"Missing required input\" ): self . file : str = file self . message : str = message super () . __init__ ( self . message ) def __str__ ( self ): return f \" { self . message } -> { self . file } \" MutuallyExclusiveOptionError Bases: Option Exception raised for when Source code in src/pheval/prepare/custom_exceptions.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class MutuallyExclusiveOptionError ( Option ): \"\"\"Exception raised for when\"\"\" def __init__ ( self , * args , ** kwargs ): self . mutually_exclusive = set ( kwargs . pop ( \"mutually_exclusive\" , [])) help_ = kwargs . get ( \"help\" , \"\" ) if self . mutually_exclusive : ex_str = \", \" . join ( self . mutually_exclusive ) kwargs [ \"help\" ] = help_ + ( \" NOTE: This argument is mutually exclusive with \" \" arguments: [\" + ex_str + \"].\" ) super ( MutuallyExclusiveOptionError , self ) . __init__ ( * args , ** kwargs ) def handle_parse_result ( self , ctx , opts , args ): if self . mutually_exclusive . intersection ( opts ) and self . name in opts : raise UsageError ( \"Illegal usage: ` {} ` is mutually exclusive with \" \"arguments ` {} `.\" . format ( self . name , \", \" . join ( self . mutually_exclusive )) ) return super ( MutuallyExclusiveOptionError , self ) . handle_parse_result ( ctx , opts , args )","title":"Custom exceptions"},{"location":"api/pheval/prepare/custom_exceptions/#src.pheval.prepare.custom_exceptions.InputError","text":"Bases: Exception Exception raised for missing required inputs. Source code in src/pheval/prepare/custom_exceptions.py 4 5 6 7 8 9 10 11 12 13 class InputError ( Exception ): \"\"\"Exception raised for missing required inputs.\"\"\" def __init__ ( self , file , message = \"Missing required input\" ): self . file : str = file self . message : str = message super () . __init__ ( self . message ) def __str__ ( self ): return f \" { self . message } -> { self . file } \"","title":"InputError"},{"location":"api/pheval/prepare/custom_exceptions/#src.pheval.prepare.custom_exceptions.MutuallyExclusiveOptionError","text":"Bases: Option Exception raised for when Source code in src/pheval/prepare/custom_exceptions.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class MutuallyExclusiveOptionError ( Option ): \"\"\"Exception raised for when\"\"\" def __init__ ( self , * args , ** kwargs ): self . mutually_exclusive = set ( kwargs . pop ( \"mutually_exclusive\" , [])) help_ = kwargs . get ( \"help\" , \"\" ) if self . mutually_exclusive : ex_str = \", \" . join ( self . mutually_exclusive ) kwargs [ \"help\" ] = help_ + ( \" NOTE: This argument is mutually exclusive with \" \" arguments: [\" + ex_str + \"].\" ) super ( MutuallyExclusiveOptionError , self ) . __init__ ( * args , ** kwargs ) def handle_parse_result ( self , ctx , opts , args ): if self . mutually_exclusive . intersection ( opts ) and self . name in opts : raise UsageError ( \"Illegal usage: ` {} ` is mutually exclusive with \" \"arguments ` {} `.\" . format ( self . name , \", \" . join ( self . mutually_exclusive )) ) return super ( MutuallyExclusiveOptionError , self ) . handle_parse_result ( ctx , opts , args )","title":"MutuallyExclusiveOptionError"},{"location":"api/pheval/prepare/update_phenopacket/","text":"create_updated_phenopacket ( gene_identifier , phenopacket_path , output_dir ) Updates the gene context within the interpretations for a phenopacket. Source code in src/pheval/prepare/update_phenopacket.py 28 29 30 31 32 def create_updated_phenopacket ( gene_identifier : str , phenopacket_path : Path , output_dir : Path ): \"\"\"Updates the gene context within the interpretations for a phenopacket.\"\"\" hgnc_data = create_hgnc_dict () updated_phenopacket = update_outdated_gene_context ( phenopacket_path , gene_identifier , hgnc_data ) write_phenopacket ( updated_phenopacket , output_dir . joinpath ( phenopacket_path . name )) create_updated_phenopackets ( gene_identifier , phenopacket_dir , output_dir ) Updates the gene context within the interpretations for phenopackets. Source code in src/pheval/prepare/update_phenopacket.py 35 36 37 38 39 40 41 42 def create_updated_phenopackets ( gene_identifier : str , phenopacket_dir : Path , output_dir : Path ): \"\"\"Updates the gene context within the interpretations for phenopackets.\"\"\" hgnc_data = create_hgnc_dict () for phenopacket_path in all_files ( phenopacket_dir ): updated_phenopacket = update_outdated_gene_context ( phenopacket_path , gene_identifier , hgnc_data ) write_phenopacket ( updated_phenopacket , output_dir . joinpath ( phenopacket_path . name )) update_outdated_gene_context ( phenopacket_path , gene_identifier , hgnc_data ) Updates the gene context of the phenopacket. Source code in src/pheval/prepare/update_phenopacket.py 15 16 17 18 19 20 21 22 23 24 25 def update_outdated_gene_context ( phenopacket_path : Path , gene_identifier : str , hgnc_data : defaultdict ): \"\"\"Updates the gene context of the phenopacket.\"\"\" phenopacket = phenopacket_reader ( phenopacket_path ) interpretations = PhenopacketUtil ( phenopacket ) . interpretations () updated_interpretations = GeneIdentifierUpdater ( hgnc_data = hgnc_data , gene_identifier = gene_identifier ) . update_genomic_interpretations_gene_identifier ( interpretations ) return PhenopacketRebuilder ( phenopacket ) . update_interpretations ( updated_interpretations ) update_phenopackets ( gene_identifier , phenopacket_path , phenopacket_dir , output_dir ) Update the gene identifiers in either a single phenopacket or a directory of phenopackets. Source code in src/pheval/prepare/update_phenopacket.py 45 46 47 48 49 50 51 52 53 def update_phenopackets ( gene_identifier : str , phenopacket_path : Path , phenopacket_dir : Path , output_dir : Path ): \"\"\"Update the gene identifiers in either a single phenopacket or a directory of phenopackets.\"\"\" output_dir . mkdir ( exist_ok = True ) if phenopacket_path is not None : create_updated_phenopacket ( gene_identifier , phenopacket_path , output_dir ) elif phenopacket_dir is not None : create_updated_phenopackets ( gene_identifier , phenopacket_dir , output_dir )","title":"Update phenopacket"},{"location":"api/pheval/prepare/update_phenopacket/#src.pheval.prepare.update_phenopacket.create_updated_phenopacket","text":"Updates the gene context within the interpretations for a phenopacket. Source code in src/pheval/prepare/update_phenopacket.py 28 29 30 31 32 def create_updated_phenopacket ( gene_identifier : str , phenopacket_path : Path , output_dir : Path ): \"\"\"Updates the gene context within the interpretations for a phenopacket.\"\"\" hgnc_data = create_hgnc_dict () updated_phenopacket = update_outdated_gene_context ( phenopacket_path , gene_identifier , hgnc_data ) write_phenopacket ( updated_phenopacket , output_dir . joinpath ( phenopacket_path . name ))","title":"create_updated_phenopacket()"},{"location":"api/pheval/prepare/update_phenopacket/#src.pheval.prepare.update_phenopacket.create_updated_phenopackets","text":"Updates the gene context within the interpretations for phenopackets. Source code in src/pheval/prepare/update_phenopacket.py 35 36 37 38 39 40 41 42 def create_updated_phenopackets ( gene_identifier : str , phenopacket_dir : Path , output_dir : Path ): \"\"\"Updates the gene context within the interpretations for phenopackets.\"\"\" hgnc_data = create_hgnc_dict () for phenopacket_path in all_files ( phenopacket_dir ): updated_phenopacket = update_outdated_gene_context ( phenopacket_path , gene_identifier , hgnc_data ) write_phenopacket ( updated_phenopacket , output_dir . joinpath ( phenopacket_path . name ))","title":"create_updated_phenopackets()"},{"location":"api/pheval/prepare/update_phenopacket/#src.pheval.prepare.update_phenopacket.update_outdated_gene_context","text":"Updates the gene context of the phenopacket. Source code in src/pheval/prepare/update_phenopacket.py 15 16 17 18 19 20 21 22 23 24 25 def update_outdated_gene_context ( phenopacket_path : Path , gene_identifier : str , hgnc_data : defaultdict ): \"\"\"Updates the gene context of the phenopacket.\"\"\" phenopacket = phenopacket_reader ( phenopacket_path ) interpretations = PhenopacketUtil ( phenopacket ) . interpretations () updated_interpretations = GeneIdentifierUpdater ( hgnc_data = hgnc_data , gene_identifier = gene_identifier ) . update_genomic_interpretations_gene_identifier ( interpretations ) return PhenopacketRebuilder ( phenopacket ) . update_interpretations ( updated_interpretations )","title":"update_outdated_gene_context()"},{"location":"api/pheval/prepare/update_phenopacket/#src.pheval.prepare.update_phenopacket.update_phenopackets","text":"Update the gene identifiers in either a single phenopacket or a directory of phenopackets. Source code in src/pheval/prepare/update_phenopacket.py 45 46 47 48 49 50 51 52 53 def update_phenopackets ( gene_identifier : str , phenopacket_path : Path , phenopacket_dir : Path , output_dir : Path ): \"\"\"Update the gene identifiers in either a single phenopacket or a directory of phenopackets.\"\"\" output_dir . mkdir ( exist_ok = True ) if phenopacket_path is not None : create_updated_phenopacket ( gene_identifier , phenopacket_path , output_dir ) elif phenopacket_dir is not None : create_updated_phenopackets ( gene_identifier , phenopacket_dir , output_dir )","title":"update_phenopackets()"},{"location":"api/pheval/runners/runner/","text":"Runners Module DefaultPhEvalRunner Bases: PhEvalRunner DefaultPhEvalRunner Parameters: Name Type Description Default PhEvalRunner PhEvalRunner Abstract PhEvalRunnerClass required Source code in src/pheval/runners/runner.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 class DefaultPhEvalRunner ( PhEvalRunner ): \"\"\"DefaultPhEvalRunner Args: PhEvalRunner (PhEvalRunner): Abstract PhEvalRunnerClass \"\"\" input_dir : Path testdata_dir : Path tmp_dir : Path output_dir : Path config_file : Path version : str def prepare ( self ): print ( \"preparing\" ) def run ( self ): print ( \"running\" ) def post_process ( self ): print ( \"post processing\" ) PhEvalRunner dataclass Bases: ABC PhEvalRunner Class Source code in src/pheval/runners/runner.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 @dataclass class PhEvalRunner ( ABC ): \"\"\"PhEvalRunner Class\"\"\" input_dir : Path testdata_dir : Path tmp_dir : Path output_dir : Path config_file : Path version : str directory_path = None input_dir_config = None _meta_data = None __raw_results_dir = \"raw_results/\" __pheval_gene_results_dir = \"pheval_gene_results/\" __pheval_variant_results_dir = \"pheval_variant_results/\" __tool_input_commands_dir = \"tool_input_commands/\" __run_meta_data_file = \"results.yml\" def __post_init__ ( self ): self . input_dir_config = parse_input_dir_config ( self . input_dir ) def _get_tool ( self ): return self . input_dir_config . tool def _get_phenotype_only ( self ): return self . input_dir_config . phenotype_only @property def tool_input_commands_dir ( self ): return Path ( self . output_dir ) . joinpath ( self . __tool_input_commands_dir ) @tool_input_commands_dir . setter def tool_input_commands_dir ( self , directory_path ): self . directory_path = Path ( directory_path ) @property def raw_results_dir ( self ): return Path ( self . output_dir ) . joinpath ( self . __raw_results_dir ) @raw_results_dir . setter def raw_results_dir ( self , directory_path ): self . directory_path = Path ( directory_path ) @property def pheval_gene_results_dir ( self ): return Path ( self . output_dir ) . joinpath ( self . __pheval_gene_results_dir ) @pheval_gene_results_dir . setter def pheval_gene_results_dir ( self , directory_path ): self . directory_path = Path ( directory_path ) @property def pheval_variant_results_dir ( self ): return Path ( self . output_dir ) . joinpath ( self . __pheval_variant_results_dir ) @pheval_variant_results_dir . setter def pheval_variant_results_dir ( self , directory_path ): self . directory_path = Path ( directory_path ) def build_output_directory_structure ( self ): \"\"\"build output directory structure\"\"\" self . tool_input_commands_dir . mkdir ( exist_ok = True ) self . raw_results_dir . mkdir ( exist_ok = True ) self . pheval_gene_results_dir . mkdir ( exist_ok = True ) if not self . _get_phenotype_only (): self . pheval_variant_results_dir . mkdir ( exist_ok = True ) @property def meta_data ( self ): self . _meta_data = BasicOutputRunMetaData ( tool = self . input_dir_config . tool , tool_version = self . version , config = f \" { Path ( self . input_dir ) . parent . name } / { Path ( self . input_dir ) . name } \" , run_timestamp = datetime . now () . timestamp (), corpus = f \" { Path ( self . testdata_dir ) . parent . name } / { Path ( self . testdata_dir ) . name } \" , ) return self . _meta_data @meta_data . setter def meta_data ( self , meta_data ): self . _meta_data = meta_data @abstractmethod def prepare ( self ) -> str : \"\"\"prepare\"\"\" @abstractmethod def run ( self ): \"\"\"run\"\"\" @abstractmethod def post_process ( self ): \"\"\"post_process\"\"\" def construct_meta_data ( self ): \"\"\"Construct run output meta data\"\"\" return self . meta_data build_output_directory_structure () build output directory structure Source code in src/pheval/runners/runner.py 71 72 73 74 75 76 77 def build_output_directory_structure ( self ): \"\"\"build output directory structure\"\"\" self . tool_input_commands_dir . mkdir ( exist_ok = True ) self . raw_results_dir . mkdir ( exist_ok = True ) self . pheval_gene_results_dir . mkdir ( exist_ok = True ) if not self . _get_phenotype_only (): self . pheval_variant_results_dir . mkdir ( exist_ok = True ) construct_meta_data () Construct run output meta data Source code in src/pheval/runners/runner.py 106 107 108 def construct_meta_data ( self ): \"\"\"Construct run output meta data\"\"\" return self . meta_data post_process () abstractmethod post_process Source code in src/pheval/runners/runner.py 102 103 104 @abstractmethod def post_process ( self ): \"\"\"post_process\"\"\" prepare () abstractmethod prepare Source code in src/pheval/runners/runner.py 94 95 96 @abstractmethod def prepare ( self ) -> str : \"\"\"prepare\"\"\" run () abstractmethod run Source code in src/pheval/runners/runner.py 98 99 100 @abstractmethod def run ( self ): \"\"\"run\"\"\"","title":"Runner"},{"location":"api/pheval/runners/runner/#src.pheval.runners.runner.DefaultPhEvalRunner","text":"Bases: PhEvalRunner DefaultPhEvalRunner Parameters: Name Type Description Default PhEvalRunner PhEvalRunner Abstract PhEvalRunnerClass required Source code in src/pheval/runners/runner.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 class DefaultPhEvalRunner ( PhEvalRunner ): \"\"\"DefaultPhEvalRunner Args: PhEvalRunner (PhEvalRunner): Abstract PhEvalRunnerClass \"\"\" input_dir : Path testdata_dir : Path tmp_dir : Path output_dir : Path config_file : Path version : str def prepare ( self ): print ( \"preparing\" ) def run ( self ): print ( \"running\" ) def post_process ( self ): print ( \"post processing\" )","title":"DefaultPhEvalRunner"},{"location":"api/pheval/runners/runner/#src.pheval.runners.runner.PhEvalRunner","text":"Bases: ABC PhEvalRunner Class Source code in src/pheval/runners/runner.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 @dataclass class PhEvalRunner ( ABC ): \"\"\"PhEvalRunner Class\"\"\" input_dir : Path testdata_dir : Path tmp_dir : Path output_dir : Path config_file : Path version : str directory_path = None input_dir_config = None _meta_data = None __raw_results_dir = \"raw_results/\" __pheval_gene_results_dir = \"pheval_gene_results/\" __pheval_variant_results_dir = \"pheval_variant_results/\" __tool_input_commands_dir = \"tool_input_commands/\" __run_meta_data_file = \"results.yml\" def __post_init__ ( self ): self . input_dir_config = parse_input_dir_config ( self . input_dir ) def _get_tool ( self ): return self . input_dir_config . tool def _get_phenotype_only ( self ): return self . input_dir_config . phenotype_only @property def tool_input_commands_dir ( self ): return Path ( self . output_dir ) . joinpath ( self . __tool_input_commands_dir ) @tool_input_commands_dir . setter def tool_input_commands_dir ( self , directory_path ): self . directory_path = Path ( directory_path ) @property def raw_results_dir ( self ): return Path ( self . output_dir ) . joinpath ( self . __raw_results_dir ) @raw_results_dir . setter def raw_results_dir ( self , directory_path ): self . directory_path = Path ( directory_path ) @property def pheval_gene_results_dir ( self ): return Path ( self . output_dir ) . joinpath ( self . __pheval_gene_results_dir ) @pheval_gene_results_dir . setter def pheval_gene_results_dir ( self , directory_path ): self . directory_path = Path ( directory_path ) @property def pheval_variant_results_dir ( self ): return Path ( self . output_dir ) . joinpath ( self . __pheval_variant_results_dir ) @pheval_variant_results_dir . setter def pheval_variant_results_dir ( self , directory_path ): self . directory_path = Path ( directory_path ) def build_output_directory_structure ( self ): \"\"\"build output directory structure\"\"\" self . tool_input_commands_dir . mkdir ( exist_ok = True ) self . raw_results_dir . mkdir ( exist_ok = True ) self . pheval_gene_results_dir . mkdir ( exist_ok = True ) if not self . _get_phenotype_only (): self . pheval_variant_results_dir . mkdir ( exist_ok = True ) @property def meta_data ( self ): self . _meta_data = BasicOutputRunMetaData ( tool = self . input_dir_config . tool , tool_version = self . version , config = f \" { Path ( self . input_dir ) . parent . name } / { Path ( self . input_dir ) . name } \" , run_timestamp = datetime . now () . timestamp (), corpus = f \" { Path ( self . testdata_dir ) . parent . name } / { Path ( self . testdata_dir ) . name } \" , ) return self . _meta_data @meta_data . setter def meta_data ( self , meta_data ): self . _meta_data = meta_data @abstractmethod def prepare ( self ) -> str : \"\"\"prepare\"\"\" @abstractmethod def run ( self ): \"\"\"run\"\"\" @abstractmethod def post_process ( self ): \"\"\"post_process\"\"\" def construct_meta_data ( self ): \"\"\"Construct run output meta data\"\"\" return self . meta_data","title":"PhEvalRunner"},{"location":"api/pheval/runners/runner/#src.pheval.runners.runner.PhEvalRunner.build_output_directory_structure","text":"build output directory structure Source code in src/pheval/runners/runner.py 71 72 73 74 75 76 77 def build_output_directory_structure ( self ): \"\"\"build output directory structure\"\"\" self . tool_input_commands_dir . mkdir ( exist_ok = True ) self . raw_results_dir . mkdir ( exist_ok = True ) self . pheval_gene_results_dir . mkdir ( exist_ok = True ) if not self . _get_phenotype_only (): self . pheval_variant_results_dir . mkdir ( exist_ok = True )","title":"build_output_directory_structure()"},{"location":"api/pheval/runners/runner/#src.pheval.runners.runner.PhEvalRunner.construct_meta_data","text":"Construct run output meta data Source code in src/pheval/runners/runner.py 106 107 108 def construct_meta_data ( self ): \"\"\"Construct run output meta data\"\"\" return self . meta_data","title":"construct_meta_data()"},{"location":"api/pheval/runners/runner/#src.pheval.runners.runner.PhEvalRunner.post_process","text":"post_process Source code in src/pheval/runners/runner.py 102 103 104 @abstractmethod def post_process ( self ): \"\"\"post_process\"\"\"","title":"post_process()"},{"location":"api/pheval/runners/runner/#src.pheval.runners.runner.PhEvalRunner.prepare","text":"prepare Source code in src/pheval/runners/runner.py 94 95 96 @abstractmethod def prepare ( self ) -> str : \"\"\"prepare\"\"\"","title":"prepare()"},{"location":"api/pheval/runners/runner/#src.pheval.runners.runner.PhEvalRunner.run","text":"run Source code in src/pheval/runners/runner.py 98 99 100 @abstractmethod def run ( self ): \"\"\"run\"\"\"","title":"run()"},{"location":"api/pheval/utils/file_utils/","text":"all_files ( directory ) Obtains all files from a given directory. Source code in src/pheval/utils/file_utils.py 23 24 25 26 27 def all_files ( directory : Path ) -> list [ Path ]: \"\"\"Obtains all files from a given directory.\"\"\" files = [ path for path in directory . iterdir ()] files . sort () return files ensure_columns_exists ( cols , dataframes , err_message = '' ) Ensures the columns exist in dataframes passed as argument (e.g) \" ensure_columns_exists( cols=['column_a', 'column_b, 'column_c'], err_message=\"Custom error message if any column doesn't exist in any dataframe passed as argument\", dataframes=[data_frame1, data_frame2], ) \" Source code in src/pheval/utils/file_utils.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def ensure_columns_exists ( cols : list , dataframes : List [ pd . DataFrame ], err_message : str = \"\" ): \"\"\"Ensures the columns exist in dataframes passed as argument (e.g) \" ensure_columns_exists( cols=['column_a', 'column_b, 'column_c'], err_message=\"Custom error message if any column doesn't exist in any dataframe passed as argument\", dataframes=[data_frame1, data_frame2], ) \" \"\"\" flat_cols = list ( itertools . chain ( cols )) if not dataframes or not flat_cols : return if err_message : err_msg = f \"\"\"columns: { \", \" . join ( flat_cols [: - 1 ]) } and { flat_cols [ - 1 ] } { err_message } \"\"\" else : err_msg = f \"\"\"columns: { \", \" . join ( flat_cols [: - 1 ]) } and { flat_cols [ - 1 ] } \\ - must be present in both left and right files\"\"\" for dataframe in dataframes : if not all ( x in dataframe . columns for x in flat_cols ): raise ValueError ( err_msg ) ensure_file_exists ( * files ) Ensures the existence of files passed as parameter Raises: Type Description FileNotFoundError If any file passed as a parameter doesn't exist a FileNotFound Exception will be raised Source code in src/pheval/utils/file_utils.py 49 50 51 52 53 54 55 56 def ensure_file_exists ( * files : str ): \"\"\"Ensures the existence of files passed as parameter Raises: FileNotFoundError: If any file passed as a parameter doesn't exist a FileNotFound Exception will be raised \"\"\" for file in files : if not path . isfile ( file ): raise FileNotFoundError ( f \"File { file } not found\" ) files_with_suffix ( directory , suffix ) Obtains all files ending in a specified suffix from a given directory. Source code in src/pheval/utils/file_utils.py 16 17 18 19 20 def files_with_suffix ( directory : Path , suffix : str ): \"\"\"Obtains all files ending in a specified suffix from a given directory.\"\"\" files = [ path for path in directory . iterdir () if path . suffix == suffix ] files . sort () return files is_gzipped ( path ) Confirms whether a file is gzipped. Source code in src/pheval/utils/file_utils.py 30 31 32 def is_gzipped ( path : Path ) -> bool : \"\"\"Confirms whether a file is gzipped.\"\"\" return path . name . endswith ( \".gz\" ) obtain_closest_file_name ( file_to_be_queried , file_paths ) Obtains the closest file name when given a template file name and a list of full path of files to be queried. Source code in src/pheval/utils/file_utils.py 40 41 42 43 44 45 46 def obtain_closest_file_name ( file_to_be_queried : Path , file_paths : list [ Path ]) -> Path : \"\"\"Obtains the closest file name when given a template file name and a list of full path of files to be queried.\"\"\" stems = [ Path ( file_path ) . stem for file_path in file_paths ] closest_file_match = difflib . get_close_matches ( str ( Path ( file_to_be_queried ) . stem ), stems , cutoff = 0.1 , n = 1 )[ 0 ] return [ file_path for file_path in file_paths if closest_file_match == str ( file_path . stem )][ 0 ] write_metadata ( output_dir , meta_data ) Write the metadata for a run. Source code in src/pheval/utils/file_utils.py 84 85 86 87 88 def write_metadata ( output_dir : Path , meta_data : BasicOutputRunMetaData ) -> None : \"\"\"Write the metadata for a run.\"\"\" with open ( Path ( output_dir ) . joinpath ( \"results.yml\" ), \"w\" ) as metadata_file : yaml . dump ( to_dict ( meta_data ), metadata_file , sort_keys = False , default_style = \"\" ) metadata_file . close ()","title":"File utils"},{"location":"api/pheval/utils/file_utils/#src.pheval.utils.file_utils.all_files","text":"Obtains all files from a given directory. Source code in src/pheval/utils/file_utils.py 23 24 25 26 27 def all_files ( directory : Path ) -> list [ Path ]: \"\"\"Obtains all files from a given directory.\"\"\" files = [ path for path in directory . iterdir ()] files . sort () return files","title":"all_files()"},{"location":"api/pheval/utils/file_utils/#src.pheval.utils.file_utils.ensure_columns_exists","text":"Ensures the columns exist in dataframes passed as argument (e.g) \" ensure_columns_exists( cols=['column_a', 'column_b, 'column_c'], err_message=\"Custom error message if any column doesn't exist in any dataframe passed as argument\", dataframes=[data_frame1, data_frame2], ) \" Source code in src/pheval/utils/file_utils.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def ensure_columns_exists ( cols : list , dataframes : List [ pd . DataFrame ], err_message : str = \"\" ): \"\"\"Ensures the columns exist in dataframes passed as argument (e.g) \" ensure_columns_exists( cols=['column_a', 'column_b, 'column_c'], err_message=\"Custom error message if any column doesn't exist in any dataframe passed as argument\", dataframes=[data_frame1, data_frame2], ) \" \"\"\" flat_cols = list ( itertools . chain ( cols )) if not dataframes or not flat_cols : return if err_message : err_msg = f \"\"\"columns: { \", \" . join ( flat_cols [: - 1 ]) } and { flat_cols [ - 1 ] } { err_message } \"\"\" else : err_msg = f \"\"\"columns: { \", \" . join ( flat_cols [: - 1 ]) } and { flat_cols [ - 1 ] } \\ - must be present in both left and right files\"\"\" for dataframe in dataframes : if not all ( x in dataframe . columns for x in flat_cols ): raise ValueError ( err_msg )","title":"ensure_columns_exists()"},{"location":"api/pheval/utils/file_utils/#src.pheval.utils.file_utils.ensure_file_exists","text":"Ensures the existence of files passed as parameter Raises: Type Description FileNotFoundError If any file passed as a parameter doesn't exist a FileNotFound Exception will be raised Source code in src/pheval/utils/file_utils.py 49 50 51 52 53 54 55 56 def ensure_file_exists ( * files : str ): \"\"\"Ensures the existence of files passed as parameter Raises: FileNotFoundError: If any file passed as a parameter doesn't exist a FileNotFound Exception will be raised \"\"\" for file in files : if not path . isfile ( file ): raise FileNotFoundError ( f \"File { file } not found\" )","title":"ensure_file_exists()"},{"location":"api/pheval/utils/file_utils/#src.pheval.utils.file_utils.files_with_suffix","text":"Obtains all files ending in a specified suffix from a given directory. Source code in src/pheval/utils/file_utils.py 16 17 18 19 20 def files_with_suffix ( directory : Path , suffix : str ): \"\"\"Obtains all files ending in a specified suffix from a given directory.\"\"\" files = [ path for path in directory . iterdir () if path . suffix == suffix ] files . sort () return files","title":"files_with_suffix()"},{"location":"api/pheval/utils/file_utils/#src.pheval.utils.file_utils.is_gzipped","text":"Confirms whether a file is gzipped. Source code in src/pheval/utils/file_utils.py 30 31 32 def is_gzipped ( path : Path ) -> bool : \"\"\"Confirms whether a file is gzipped.\"\"\" return path . name . endswith ( \".gz\" )","title":"is_gzipped()"},{"location":"api/pheval/utils/file_utils/#src.pheval.utils.file_utils.obtain_closest_file_name","text":"Obtains the closest file name when given a template file name and a list of full path of files to be queried. Source code in src/pheval/utils/file_utils.py 40 41 42 43 44 45 46 def obtain_closest_file_name ( file_to_be_queried : Path , file_paths : list [ Path ]) -> Path : \"\"\"Obtains the closest file name when given a template file name and a list of full path of files to be queried.\"\"\" stems = [ Path ( file_path ) . stem for file_path in file_paths ] closest_file_match = difflib . get_close_matches ( str ( Path ( file_to_be_queried ) . stem ), stems , cutoff = 0.1 , n = 1 )[ 0 ] return [ file_path for file_path in file_paths if closest_file_match == str ( file_path . stem )][ 0 ]","title":"obtain_closest_file_name()"},{"location":"api/pheval/utils/file_utils/#src.pheval.utils.file_utils.write_metadata","text":"Write the metadata for a run. Source code in src/pheval/utils/file_utils.py 84 85 86 87 88 def write_metadata ( output_dir : Path , meta_data : BasicOutputRunMetaData ) -> None : \"\"\"Write the metadata for a run.\"\"\" with open ( Path ( output_dir ) . joinpath ( \"results.yml\" ), \"w\" ) as metadata_file : yaml . dump ( to_dict ( meta_data ), metadata_file , sort_keys = False , default_style = \"\" ) metadata_file . close ()","title":"write_metadata()"},{"location":"api/pheval/utils/phenopacket_utils/","text":"GeneIdentifierUpdater Source code in src/pheval/utils/phenopacket_utils.py 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 class GeneIdentifierUpdater : def __init__ ( self , gene_identifier : str , hgnc_data : dict = None , identifier_map : dict = None ): self . hgnc_data = hgnc_data self . gene_identifier = gene_identifier self . identifier_map = identifier_map def find_identifier ( self , gene_symbol : str ) -> str : \"\"\"Finds the specified gene identifier for a gene symbol.\"\"\" if gene_symbol in self . hgnc_data . keys (): return self . hgnc_data [ gene_symbol ][ self . gene_identifier ] else : for _symbol , data in self . hgnc_data . items (): for prev_symbol in data [ \"previous_symbol\" ]: if prev_symbol == gene_symbol : return data [ self . gene_identifier ] def obtain_gene_symbol_from_identifier ( self , query_gene_identifier : str ) -> str : \"\"\" Obtain gene symbol from a gene identifier. (e.g.) \" obtain_gene_symbol_from_identifier(query_gene_identifier=\"HGNC:5\") \" \"\"\" return self . identifier_map [ query_gene_identifier ] def _find_alternate_ids ( self , gene_symbol : str ) -> list [ str ]: \"\"\"Finds the alternate IDs for a gene symbol.\"\"\" if gene_symbol in self . hgnc_data . keys (): return [ self . hgnc_data [ gene_symbol ][ \"hgnc_id\" ], \"ncbigene:\" + self . hgnc_data [ gene_symbol ][ \"entrez_id\" ], \"ensembl:\" + self . hgnc_data [ gene_symbol ][ \"ensembl_id\" ], \"symbol:\" + gene_symbol , ] else : for symbol , data in self . hgnc_data . items (): for prev_symbol in data [ \"previous_symbol\" ]: if prev_symbol == gene_symbol : return [ data [ \"hgnc_id\" ], \"ncbigene:\" + data [ \"entrez_id\" ], \"ensembl:\" + data [ \"ensembl_id\" ], \"symbol:\" + symbol , ] def update_genomic_interpretations_gene_identifier ( self , interpretations : list [ Interpretation ] ) -> list [ Interpretation ]: \"\"\"Updates the genomic interpretations of a phenopacket.\"\"\" updated_interpretations = copy ( list ( interpretations )) for updated_interpretation in updated_interpretations : for g in updated_interpretation . diagnosis . genomic_interpretations : g . variant_interpretation . variation_descriptor . gene_context . value_id = ( self . find_identifier ( g . variant_interpretation . variation_descriptor . gene_context . symbol ) ) del g . variant_interpretation . variation_descriptor . gene_context . alternate_ids [:] g . variant_interpretation . variation_descriptor . gene_context . alternate_ids . extend ( self . _find_alternate_ids ( g . variant_interpretation . variation_descriptor . gene_context . symbol ) ) return updated_interpretations find_identifier ( gene_symbol ) Finds the specified gene identifier for a gene symbol. Source code in src/pheval/utils/phenopacket_utils.py 299 300 301 302 303 304 305 306 307 def find_identifier ( self , gene_symbol : str ) -> str : \"\"\"Finds the specified gene identifier for a gene symbol.\"\"\" if gene_symbol in self . hgnc_data . keys (): return self . hgnc_data [ gene_symbol ][ self . gene_identifier ] else : for _symbol , data in self . hgnc_data . items (): for prev_symbol in data [ \"previous_symbol\" ]: if prev_symbol == gene_symbol : return data [ self . gene_identifier ] obtain_gene_symbol_from_identifier ( query_gene_identifier ) Obtain gene symbol from a gene identifier. (e.g.) \" obtain_gene_symbol_from_identifier(query_gene_identifier=\"HGNC:5\") \" Source code in src/pheval/utils/phenopacket_utils.py 309 310 311 312 313 314 315 316 def obtain_gene_symbol_from_identifier ( self , query_gene_identifier : str ) -> str : \"\"\" Obtain gene symbol from a gene identifier. (e.g.) \" obtain_gene_symbol_from_identifier(query_gene_identifier=\"HGNC:5\") \" \"\"\" return self . identifier_map [ query_gene_identifier ] update_genomic_interpretations_gene_identifier ( interpretations ) Updates the genomic interpretations of a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 def update_genomic_interpretations_gene_identifier ( self , interpretations : list [ Interpretation ] ) -> list [ Interpretation ]: \"\"\"Updates the genomic interpretations of a phenopacket.\"\"\" updated_interpretations = copy ( list ( interpretations )) for updated_interpretation in updated_interpretations : for g in updated_interpretation . diagnosis . genomic_interpretations : g . variant_interpretation . variation_descriptor . gene_context . value_id = ( self . find_identifier ( g . variant_interpretation . variation_descriptor . gene_context . symbol ) ) del g . variant_interpretation . variation_descriptor . gene_context . alternate_ids [:] g . variant_interpretation . variation_descriptor . gene_context . alternate_ids . extend ( self . _find_alternate_ids ( g . variant_interpretation . variation_descriptor . gene_context . symbol ) ) return updated_interpretations IncompatibleGenomeAssemblyError Bases: Exception Exception raised for incompatible genome assembly. Source code in src/pheval/utils/phenopacket_utils.py 24 25 26 27 28 29 30 31 32 33 34 class IncompatibleGenomeAssemblyError ( Exception ): \"\"\"Exception raised for incompatible genome assembly.\"\"\" def __init__ ( self , assembly , phenopacket , message = \"Incompatible Genome Assembly\" ): self . assembly : str = assembly self . phenopacket : Path = phenopacket self . message : str = message super () . __init__ ( self . message ) def __str__ ( self ): return f \" { self . message } -> { self . assembly } in { self . phenopacket } \" PhenopacketRebuilder Rebuilds a Phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 class PhenopacketRebuilder : \"\"\"Rebuilds a Phenopacket.\"\"\" def __init__ ( self , phenopacket : Phenopacket or Family ): self . phenopacket = phenopacket def update_interpretations ( self , interpretations ) -> Phenopacket or Family : \"\"\"Adds the updated interpretations to a phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) if hasattr ( phenopacket , \"proband\" ): del phenopacket . proband . interpretations [:] phenopacket . proband . interpretations . extend ( interpretations ) else : del phenopacket . interpretations [:] phenopacket . interpretations . extend ( interpretations ) return phenopacket def add_randomised_hpo ( self , randomised_hpo ) -> Phenopacket or Family : \"\"\"Adds randomised phenotypic profile to phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) if hasattr ( phenopacket , \"proband\" ): del phenopacket . proband . phenotypic_features [:] phenopacket . proband . phenotypic_features . extend ( randomised_hpo ) else : del phenopacket . phenotypic_features [:] phenopacket . phenotypic_features . extend ( randomised_hpo ) return phenopacket def add_spiked_vcf_path ( self , spiked_vcf_file_data : File ) -> Phenopacket or Family : \"\"\"Adds spiked vcf path to phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) phenopacket_files = [ file for file in phenopacket . files if file . file_attributes [ \"fileFormat\" ] != \"vcf\" ] phenopacket_files . append ( spiked_vcf_file_data ) del phenopacket . files [:] phenopacket . files . extend ( phenopacket_files ) return phenopacket add_randomised_hpo ( randomised_hpo ) Adds randomised phenotypic profile to phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 257 258 259 260 261 262 263 264 265 266 def add_randomised_hpo ( self , randomised_hpo ) -> Phenopacket or Family : \"\"\"Adds randomised phenotypic profile to phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) if hasattr ( phenopacket , \"proband\" ): del phenopacket . proband . phenotypic_features [:] phenopacket . proband . phenotypic_features . extend ( randomised_hpo ) else : del phenopacket . phenotypic_features [:] phenopacket . phenotypic_features . extend ( randomised_hpo ) return phenopacket add_spiked_vcf_path ( spiked_vcf_file_data ) Adds spiked vcf path to phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 268 269 270 271 272 273 274 275 276 277 def add_spiked_vcf_path ( self , spiked_vcf_file_data : File ) -> Phenopacket or Family : \"\"\"Adds spiked vcf path to phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) phenopacket_files = [ file for file in phenopacket . files if file . file_attributes [ \"fileFormat\" ] != \"vcf\" ] phenopacket_files . append ( spiked_vcf_file_data ) del phenopacket . files [:] phenopacket . files . extend ( phenopacket_files ) return phenopacket update_interpretations ( interpretations ) Adds the updated interpretations to a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 246 247 248 249 250 251 252 253 254 255 def update_interpretations ( self , interpretations ) -> Phenopacket or Family : \"\"\"Adds the updated interpretations to a phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) if hasattr ( phenopacket , \"proband\" ): del phenopacket . proband . interpretations [:] phenopacket . proband . interpretations . extend ( interpretations ) else : del phenopacket . interpretations [:] phenopacket . interpretations . extend ( interpretations ) return phenopacket PhenopacketUtil Retrieves relevant data from a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 class PhenopacketUtil : \"\"\"Retrieves relevant data from a phenopacket.\"\"\" def __init__ ( self , phenopacket_contents : Phenopacket ): self . phenopacket_contents = phenopacket_contents def sample_id ( self ) -> str : \"\"\"Retrieve the sample ID from a phenopacket or proband of a family.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . subject . id else : return self . phenopacket_contents . subject . id def phenotypic_features ( self ) -> list [ PhenotypicFeature ]: \"\"\"Retrieves a list of all HPO terms.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . phenotypic_features else : return self . phenopacket_contents . phenotypic_features def observed_phenotypic_features ( self ) -> list [ PhenotypicFeature ]: \"\"\"Removes any HPO terms labelled as excluded.\"\"\" phenotypic_features = [] all_phenotypic_features = self . phenotypic_features () for p in all_phenotypic_features : if p . excluded : continue phenotypic_features . append ( p ) return phenotypic_features def negated_phenotypic_features ( self ) -> [ PhenotypicFeature ]: \"\"\"Retrieve negated phenotypic features.\"\"\" negated_phenotypic_features = [] all_phenotypic_features = self . phenotypic_features () for p in all_phenotypic_features : if p . excluded : negated_phenotypic_features . append ( p ) return negated_phenotypic_features def interpretations ( self ) -> list [ Interpretation ]: \"\"\"Returns all interpretations of a phenopacket.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . interpretations else : return self . phenopacket_contents . interpretations def causative_variants ( self ) -> list [ ProbandCausativeVariant ]: \"\"\"Returns a list of all causative variants listed in a phenopacket.\"\"\" all_variants = [] interpretation = self . interpretations () for i in interpretation : for g in i . diagnosis . genomic_interpretations : vcf_record = g . variant_interpretation . variation_descriptor . vcf_record genotype = g . variant_interpretation . variation_descriptor . allelic_state variant_data = ProbandCausativeVariant ( self . phenopacket_contents . subject . id , vcf_record . genome_assembly , GenomicVariant ( vcf_record . chrom , vcf_record . pos , vcf_record . ref , vcf_record . alt , ), genotype . label , vcf_record . info , ) all_variants . append ( variant_data ) return all_variants def files ( self ) -> list : \"\"\"Returns all files associated with a phenopacket.\"\"\" return self . phenopacket_contents . files def vcf_file_data ( self , phenopacket_path : Path , vcf_dir : Path ) -> File : \"\"\"Retrieves the genome assembly and vcf name from a phenopacket.\"\"\" compatible_genome_assembly = [ \"GRCh37\" , \"hg19\" , \"GRCh38\" , \"hg38\" ] vcf_data = [ file for file in self . files () if file . file_attributes [ \"fileFormat\" ] == \"vcf\" ][ 0 ] if not Path ( vcf_data . uri ) . name . endswith ( \".vcf\" ) and not Path ( vcf_data . uri ) . name . endswith ( \".vcf.gz\" ): raise IncorrectFileFormatError ( Path ( vcf_data . uri ), \".vcf or .vcf.gz file\" ) if vcf_data . file_attributes [ \"genomeAssembly\" ] not in compatible_genome_assembly : raise IncompatibleGenomeAssemblyError ( vcf_data . file_attributes [ \"genomeAssembly\" ], phenopacket_path ) vcf_data . uri = str ( vcf_dir . joinpath ( Path ( vcf_data . uri ) . name )) return vcf_data @staticmethod def _extract_diagnosed_gene ( genomic_interpretation : GenomicInterpretation , ) -> ProbandCausativeGene : \"\"\"Returns the disease causative gene from the variant descriptor field if not empty, otherwise, returns from the gene descriptor from a phenopacket.\"\"\" if genomic_interpretation . variant_interpretation . ByteSize () != 0 : return ProbandCausativeGene ( genomic_interpretation . variant_interpretation . variation_descriptor . gene_context . symbol , genomic_interpretation . variant_interpretation . variation_descriptor . gene_context . value_id , ) else : return ProbandCausativeGene ( gene_symbol = genomic_interpretation . gene . symbol , gene_identifier = genomic_interpretation . gene . value_id , ) def diagnosed_genes ( self ) -> list [ ProbandCausativeGene ]: \"\"\"Returns a unique list of all causative genes and the corresponding gene identifiers from a phenopacket.\"\"\" pheno_interpretation = self . interpretations () genes = [] for i in pheno_interpretation : for g in i . diagnosis . genomic_interpretations : genes . append ( self . _extract_diagnosed_gene ( g )) genes = list ({ gene . gene_symbol : gene for gene in genes } . values ()) return genes def diagnosed_variants ( self ) -> list [ GenomicVariant ]: \"\"\"Returns a list of all variants from a phenopacket - for use in assess-prioritisation.\"\"\" variants = [] pheno_interpretation = self . interpretations () for i in pheno_interpretation : for g in i . diagnosis . genomic_interpretations : variant = GenomicVariant ( chrom = g . variant_interpretation . variation_descriptor . vcf_record . chrom , pos = g . variant_interpretation . variation_descriptor . vcf_record . pos , ref = g . variant_interpretation . variation_descriptor . vcf_record . ref , alt = g . variant_interpretation . variation_descriptor . vcf_record . alt , ) variants . append ( variant ) return variants causative_variants () Returns a list of all causative variants listed in a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 def causative_variants ( self ) -> list [ ProbandCausativeVariant ]: \"\"\"Returns a list of all causative variants listed in a phenopacket.\"\"\" all_variants = [] interpretation = self . interpretations () for i in interpretation : for g in i . diagnosis . genomic_interpretations : vcf_record = g . variant_interpretation . variation_descriptor . vcf_record genotype = g . variant_interpretation . variation_descriptor . allelic_state variant_data = ProbandCausativeVariant ( self . phenopacket_contents . subject . id , vcf_record . genome_assembly , GenomicVariant ( vcf_record . chrom , vcf_record . pos , vcf_record . ref , vcf_record . alt , ), genotype . label , vcf_record . info , ) all_variants . append ( variant_data ) return all_variants diagnosed_genes () Returns a unique list of all causative genes and the corresponding gene identifiers from a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 214 215 216 217 218 219 220 221 222 def diagnosed_genes ( self ) -> list [ ProbandCausativeGene ]: \"\"\"Returns a unique list of all causative genes and the corresponding gene identifiers from a phenopacket.\"\"\" pheno_interpretation = self . interpretations () genes = [] for i in pheno_interpretation : for g in i . diagnosis . genomic_interpretations : genes . append ( self . _extract_diagnosed_gene ( g )) genes = list ({ gene . gene_symbol : gene for gene in genes } . values ()) return genes diagnosed_variants () Returns a list of all variants from a phenopacket - for use in assess-prioritisation. Source code in src/pheval/utils/phenopacket_utils.py 224 225 226 227 228 229 230 231 232 233 234 235 236 237 def diagnosed_variants ( self ) -> list [ GenomicVariant ]: \"\"\"Returns a list of all variants from a phenopacket - for use in assess-prioritisation.\"\"\" variants = [] pheno_interpretation = self . interpretations () for i in pheno_interpretation : for g in i . diagnosis . genomic_interpretations : variant = GenomicVariant ( chrom = g . variant_interpretation . variation_descriptor . vcf_record . chrom , pos = g . variant_interpretation . variation_descriptor . vcf_record . pos , ref = g . variant_interpretation . variation_descriptor . vcf_record . ref , alt = g . variant_interpretation . variation_descriptor . vcf_record . alt , ) variants . append ( variant ) return variants files () Returns all files associated with a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 177 178 179 def files ( self ) -> list : \"\"\"Returns all files associated with a phenopacket.\"\"\" return self . phenopacket_contents . files interpretations () Returns all interpretations of a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 147 148 149 150 151 152 def interpretations ( self ) -> list [ Interpretation ]: \"\"\"Returns all interpretations of a phenopacket.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . interpretations else : return self . phenopacket_contents . interpretations negated_phenotypic_features () Retrieve negated phenotypic features. Source code in src/pheval/utils/phenopacket_utils.py 138 139 140 141 142 143 144 145 def negated_phenotypic_features ( self ) -> [ PhenotypicFeature ]: \"\"\"Retrieve negated phenotypic features.\"\"\" negated_phenotypic_features = [] all_phenotypic_features = self . phenotypic_features () for p in all_phenotypic_features : if p . excluded : negated_phenotypic_features . append ( p ) return negated_phenotypic_features observed_phenotypic_features () Removes any HPO terms labelled as excluded. Source code in src/pheval/utils/phenopacket_utils.py 128 129 130 131 132 133 134 135 136 def observed_phenotypic_features ( self ) -> list [ PhenotypicFeature ]: \"\"\"Removes any HPO terms labelled as excluded.\"\"\" phenotypic_features = [] all_phenotypic_features = self . phenotypic_features () for p in all_phenotypic_features : if p . excluded : continue phenotypic_features . append ( p ) return phenotypic_features phenotypic_features () Retrieves a list of all HPO terms. Source code in src/pheval/utils/phenopacket_utils.py 121 122 123 124 125 126 def phenotypic_features ( self ) -> list [ PhenotypicFeature ]: \"\"\"Retrieves a list of all HPO terms.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . phenotypic_features else : return self . phenopacket_contents . phenotypic_features sample_id () Retrieve the sample ID from a phenopacket or proband of a family. Source code in src/pheval/utils/phenopacket_utils.py 114 115 116 117 118 119 def sample_id ( self ) -> str : \"\"\"Retrieve the sample ID from a phenopacket or proband of a family.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . subject . id else : return self . phenopacket_contents . subject . id vcf_file_data ( phenopacket_path , vcf_dir ) Retrieves the genome assembly and vcf name from a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 181 182 183 184 185 186 187 188 189 190 191 192 193 194 def vcf_file_data ( self , phenopacket_path : Path , vcf_dir : Path ) -> File : \"\"\"Retrieves the genome assembly and vcf name from a phenopacket.\"\"\" compatible_genome_assembly = [ \"GRCh37\" , \"hg19\" , \"GRCh38\" , \"hg38\" ] vcf_data = [ file for file in self . files () if file . file_attributes [ \"fileFormat\" ] == \"vcf\" ][ 0 ] if not Path ( vcf_data . uri ) . name . endswith ( \".vcf\" ) and not Path ( vcf_data . uri ) . name . endswith ( \".vcf.gz\" ): raise IncorrectFileFormatError ( Path ( vcf_data . uri ), \".vcf or .vcf.gz file\" ) if vcf_data . file_attributes [ \"genomeAssembly\" ] not in compatible_genome_assembly : raise IncompatibleGenomeAssemblyError ( vcf_data . file_attributes [ \"genomeAssembly\" ], phenopacket_path ) vcf_data . uri = str ( vcf_dir . joinpath ( Path ( vcf_data . uri ) . name )) return vcf_data create_hgnc_dict () Creates reference for updating gene symbols and identifiers. Source code in src/pheval/utils/phenopacket_utils.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def create_hgnc_dict () -> defaultdict : \"\"\"Creates reference for updating gene symbols and identifiers.\"\"\" hgnc_df = read_hgnc_data () hgnc_data = defaultdict ( dict ) for _index , row in hgnc_df . iterrows (): previous_names = [] hgnc_data [ row [ \"symbol\" ]][ \"ensembl_id\" ] = row [ \"ensembl_gene_id\" ] hgnc_data [ row [ \"symbol\" ]][ \"hgnc_id\" ] = row [ \"hgnc_id\" ] hgnc_data [ row [ \"symbol\" ]][ \"entrez_id\" ] = row [ \"entrez_id\" ] hgnc_data [ row [ \"symbol\" ]][ \"refseq_accession\" ] = row [ \"refseq_accession\" ] previous = str ( row [ \"prev_symbol\" ]) . split ( \"|\" ) for p in previous : previous_names . append ( p . strip ( '\"' )) hgnc_data [ row [ \"symbol\" ]][ \"previous_symbol\" ] = previous_names return hgnc_data create_json_message ( phenopacket ) Creates json message for writing to file. Source code in src/pheval/utils/phenopacket_utils.py 280 281 282 def create_json_message ( phenopacket : Phenopacket or Family ) -> str : \"\"\"Creates json message for writing to file.\"\"\" return MessageToJson ( phenopacket ) phenopacket_reader ( file ) Reads a phenopacket file, returning its contents. Source code in src/pheval/utils/phenopacket_utils.py 97 98 99 100 101 102 103 104 105 def phenopacket_reader ( file : Path ): \"\"\"Reads a phenopacket file, returning its contents.\"\"\" file = open ( file , \"r\" ) phenopacket = json . load ( file ) file . close () if \"proband\" in phenopacket : return Parse ( json . dumps ( phenopacket ), Family ()) else : return Parse ( json . dumps ( phenopacket ), Phenopacket ()) write_phenopacket ( phenopacket , output_file ) Writes a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 285 286 287 288 289 290 def write_phenopacket ( phenopacket : Phenopacket or Family , output_file : Path ) -> None : \"\"\"Writes a phenopacket.\"\"\" phenopacket_json = create_json_message ( phenopacket ) with open ( output_file , \"w\" ) as outfile : outfile . write ( phenopacket_json ) outfile . close ()","title":"Phenopacket utils"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.GeneIdentifierUpdater","text":"Source code in src/pheval/utils/phenopacket_utils.py 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 class GeneIdentifierUpdater : def __init__ ( self , gene_identifier : str , hgnc_data : dict = None , identifier_map : dict = None ): self . hgnc_data = hgnc_data self . gene_identifier = gene_identifier self . identifier_map = identifier_map def find_identifier ( self , gene_symbol : str ) -> str : \"\"\"Finds the specified gene identifier for a gene symbol.\"\"\" if gene_symbol in self . hgnc_data . keys (): return self . hgnc_data [ gene_symbol ][ self . gene_identifier ] else : for _symbol , data in self . hgnc_data . items (): for prev_symbol in data [ \"previous_symbol\" ]: if prev_symbol == gene_symbol : return data [ self . gene_identifier ] def obtain_gene_symbol_from_identifier ( self , query_gene_identifier : str ) -> str : \"\"\" Obtain gene symbol from a gene identifier. (e.g.) \" obtain_gene_symbol_from_identifier(query_gene_identifier=\"HGNC:5\") \" \"\"\" return self . identifier_map [ query_gene_identifier ] def _find_alternate_ids ( self , gene_symbol : str ) -> list [ str ]: \"\"\"Finds the alternate IDs for a gene symbol.\"\"\" if gene_symbol in self . hgnc_data . keys (): return [ self . hgnc_data [ gene_symbol ][ \"hgnc_id\" ], \"ncbigene:\" + self . hgnc_data [ gene_symbol ][ \"entrez_id\" ], \"ensembl:\" + self . hgnc_data [ gene_symbol ][ \"ensembl_id\" ], \"symbol:\" + gene_symbol , ] else : for symbol , data in self . hgnc_data . items (): for prev_symbol in data [ \"previous_symbol\" ]: if prev_symbol == gene_symbol : return [ data [ \"hgnc_id\" ], \"ncbigene:\" + data [ \"entrez_id\" ], \"ensembl:\" + data [ \"ensembl_id\" ], \"symbol:\" + symbol , ] def update_genomic_interpretations_gene_identifier ( self , interpretations : list [ Interpretation ] ) -> list [ Interpretation ]: \"\"\"Updates the genomic interpretations of a phenopacket.\"\"\" updated_interpretations = copy ( list ( interpretations )) for updated_interpretation in updated_interpretations : for g in updated_interpretation . diagnosis . genomic_interpretations : g . variant_interpretation . variation_descriptor . gene_context . value_id = ( self . find_identifier ( g . variant_interpretation . variation_descriptor . gene_context . symbol ) ) del g . variant_interpretation . variation_descriptor . gene_context . alternate_ids [:] g . variant_interpretation . variation_descriptor . gene_context . alternate_ids . extend ( self . _find_alternate_ids ( g . variant_interpretation . variation_descriptor . gene_context . symbol ) ) return updated_interpretations","title":"GeneIdentifierUpdater"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.GeneIdentifierUpdater.find_identifier","text":"Finds the specified gene identifier for a gene symbol. Source code in src/pheval/utils/phenopacket_utils.py 299 300 301 302 303 304 305 306 307 def find_identifier ( self , gene_symbol : str ) -> str : \"\"\"Finds the specified gene identifier for a gene symbol.\"\"\" if gene_symbol in self . hgnc_data . keys (): return self . hgnc_data [ gene_symbol ][ self . gene_identifier ] else : for _symbol , data in self . hgnc_data . items (): for prev_symbol in data [ \"previous_symbol\" ]: if prev_symbol == gene_symbol : return data [ self . gene_identifier ]","title":"find_identifier()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.GeneIdentifierUpdater.obtain_gene_symbol_from_identifier","text":"Obtain gene symbol from a gene identifier. (e.g.) \" obtain_gene_symbol_from_identifier(query_gene_identifier=\"HGNC:5\") \" Source code in src/pheval/utils/phenopacket_utils.py 309 310 311 312 313 314 315 316 def obtain_gene_symbol_from_identifier ( self , query_gene_identifier : str ) -> str : \"\"\" Obtain gene symbol from a gene identifier. (e.g.) \" obtain_gene_symbol_from_identifier(query_gene_identifier=\"HGNC:5\") \" \"\"\" return self . identifier_map [ query_gene_identifier ]","title":"obtain_gene_symbol_from_identifier()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.GeneIdentifierUpdater.update_genomic_interpretations_gene_identifier","text":"Updates the genomic interpretations of a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 def update_genomic_interpretations_gene_identifier ( self , interpretations : list [ Interpretation ] ) -> list [ Interpretation ]: \"\"\"Updates the genomic interpretations of a phenopacket.\"\"\" updated_interpretations = copy ( list ( interpretations )) for updated_interpretation in updated_interpretations : for g in updated_interpretation . diagnosis . genomic_interpretations : g . variant_interpretation . variation_descriptor . gene_context . value_id = ( self . find_identifier ( g . variant_interpretation . variation_descriptor . gene_context . symbol ) ) del g . variant_interpretation . variation_descriptor . gene_context . alternate_ids [:] g . variant_interpretation . variation_descriptor . gene_context . alternate_ids . extend ( self . _find_alternate_ids ( g . variant_interpretation . variation_descriptor . gene_context . symbol ) ) return updated_interpretations","title":"update_genomic_interpretations_gene_identifier()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.IncompatibleGenomeAssemblyError","text":"Bases: Exception Exception raised for incompatible genome assembly. Source code in src/pheval/utils/phenopacket_utils.py 24 25 26 27 28 29 30 31 32 33 34 class IncompatibleGenomeAssemblyError ( Exception ): \"\"\"Exception raised for incompatible genome assembly.\"\"\" def __init__ ( self , assembly , phenopacket , message = \"Incompatible Genome Assembly\" ): self . assembly : str = assembly self . phenopacket : Path = phenopacket self . message : str = message super () . __init__ ( self . message ) def __str__ ( self ): return f \" { self . message } -> { self . assembly } in { self . phenopacket } \"","title":"IncompatibleGenomeAssemblyError"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketRebuilder","text":"Rebuilds a Phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 class PhenopacketRebuilder : \"\"\"Rebuilds a Phenopacket.\"\"\" def __init__ ( self , phenopacket : Phenopacket or Family ): self . phenopacket = phenopacket def update_interpretations ( self , interpretations ) -> Phenopacket or Family : \"\"\"Adds the updated interpretations to a phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) if hasattr ( phenopacket , \"proband\" ): del phenopacket . proband . interpretations [:] phenopacket . proband . interpretations . extend ( interpretations ) else : del phenopacket . interpretations [:] phenopacket . interpretations . extend ( interpretations ) return phenopacket def add_randomised_hpo ( self , randomised_hpo ) -> Phenopacket or Family : \"\"\"Adds randomised phenotypic profile to phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) if hasattr ( phenopacket , \"proband\" ): del phenopacket . proband . phenotypic_features [:] phenopacket . proband . phenotypic_features . extend ( randomised_hpo ) else : del phenopacket . phenotypic_features [:] phenopacket . phenotypic_features . extend ( randomised_hpo ) return phenopacket def add_spiked_vcf_path ( self , spiked_vcf_file_data : File ) -> Phenopacket or Family : \"\"\"Adds spiked vcf path to phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) phenopacket_files = [ file for file in phenopacket . files if file . file_attributes [ \"fileFormat\" ] != \"vcf\" ] phenopacket_files . append ( spiked_vcf_file_data ) del phenopacket . files [:] phenopacket . files . extend ( phenopacket_files ) return phenopacket","title":"PhenopacketRebuilder"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketRebuilder.add_randomised_hpo","text":"Adds randomised phenotypic profile to phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 257 258 259 260 261 262 263 264 265 266 def add_randomised_hpo ( self , randomised_hpo ) -> Phenopacket or Family : \"\"\"Adds randomised phenotypic profile to phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) if hasattr ( phenopacket , \"proband\" ): del phenopacket . proband . phenotypic_features [:] phenopacket . proband . phenotypic_features . extend ( randomised_hpo ) else : del phenopacket . phenotypic_features [:] phenopacket . phenotypic_features . extend ( randomised_hpo ) return phenopacket","title":"add_randomised_hpo()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketRebuilder.add_spiked_vcf_path","text":"Adds spiked vcf path to phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 268 269 270 271 272 273 274 275 276 277 def add_spiked_vcf_path ( self , spiked_vcf_file_data : File ) -> Phenopacket or Family : \"\"\"Adds spiked vcf path to phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) phenopacket_files = [ file for file in phenopacket . files if file . file_attributes [ \"fileFormat\" ] != \"vcf\" ] phenopacket_files . append ( spiked_vcf_file_data ) del phenopacket . files [:] phenopacket . files . extend ( phenopacket_files ) return phenopacket","title":"add_spiked_vcf_path()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketRebuilder.update_interpretations","text":"Adds the updated interpretations to a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 246 247 248 249 250 251 252 253 254 255 def update_interpretations ( self , interpretations ) -> Phenopacket or Family : \"\"\"Adds the updated interpretations to a phenopacket.\"\"\" phenopacket = copy ( self . phenopacket ) if hasattr ( phenopacket , \"proband\" ): del phenopacket . proband . interpretations [:] phenopacket . proband . interpretations . extend ( interpretations ) else : del phenopacket . interpretations [:] phenopacket . interpretations . extend ( interpretations ) return phenopacket","title":"update_interpretations()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil","text":"Retrieves relevant data from a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 class PhenopacketUtil : \"\"\"Retrieves relevant data from a phenopacket.\"\"\" def __init__ ( self , phenopacket_contents : Phenopacket ): self . phenopacket_contents = phenopacket_contents def sample_id ( self ) -> str : \"\"\"Retrieve the sample ID from a phenopacket or proband of a family.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . subject . id else : return self . phenopacket_contents . subject . id def phenotypic_features ( self ) -> list [ PhenotypicFeature ]: \"\"\"Retrieves a list of all HPO terms.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . phenotypic_features else : return self . phenopacket_contents . phenotypic_features def observed_phenotypic_features ( self ) -> list [ PhenotypicFeature ]: \"\"\"Removes any HPO terms labelled as excluded.\"\"\" phenotypic_features = [] all_phenotypic_features = self . phenotypic_features () for p in all_phenotypic_features : if p . excluded : continue phenotypic_features . append ( p ) return phenotypic_features def negated_phenotypic_features ( self ) -> [ PhenotypicFeature ]: \"\"\"Retrieve negated phenotypic features.\"\"\" negated_phenotypic_features = [] all_phenotypic_features = self . phenotypic_features () for p in all_phenotypic_features : if p . excluded : negated_phenotypic_features . append ( p ) return negated_phenotypic_features def interpretations ( self ) -> list [ Interpretation ]: \"\"\"Returns all interpretations of a phenopacket.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . interpretations else : return self . phenopacket_contents . interpretations def causative_variants ( self ) -> list [ ProbandCausativeVariant ]: \"\"\"Returns a list of all causative variants listed in a phenopacket.\"\"\" all_variants = [] interpretation = self . interpretations () for i in interpretation : for g in i . diagnosis . genomic_interpretations : vcf_record = g . variant_interpretation . variation_descriptor . vcf_record genotype = g . variant_interpretation . variation_descriptor . allelic_state variant_data = ProbandCausativeVariant ( self . phenopacket_contents . subject . id , vcf_record . genome_assembly , GenomicVariant ( vcf_record . chrom , vcf_record . pos , vcf_record . ref , vcf_record . alt , ), genotype . label , vcf_record . info , ) all_variants . append ( variant_data ) return all_variants def files ( self ) -> list : \"\"\"Returns all files associated with a phenopacket.\"\"\" return self . phenopacket_contents . files def vcf_file_data ( self , phenopacket_path : Path , vcf_dir : Path ) -> File : \"\"\"Retrieves the genome assembly and vcf name from a phenopacket.\"\"\" compatible_genome_assembly = [ \"GRCh37\" , \"hg19\" , \"GRCh38\" , \"hg38\" ] vcf_data = [ file for file in self . files () if file . file_attributes [ \"fileFormat\" ] == \"vcf\" ][ 0 ] if not Path ( vcf_data . uri ) . name . endswith ( \".vcf\" ) and not Path ( vcf_data . uri ) . name . endswith ( \".vcf.gz\" ): raise IncorrectFileFormatError ( Path ( vcf_data . uri ), \".vcf or .vcf.gz file\" ) if vcf_data . file_attributes [ \"genomeAssembly\" ] not in compatible_genome_assembly : raise IncompatibleGenomeAssemblyError ( vcf_data . file_attributes [ \"genomeAssembly\" ], phenopacket_path ) vcf_data . uri = str ( vcf_dir . joinpath ( Path ( vcf_data . uri ) . name )) return vcf_data @staticmethod def _extract_diagnosed_gene ( genomic_interpretation : GenomicInterpretation , ) -> ProbandCausativeGene : \"\"\"Returns the disease causative gene from the variant descriptor field if not empty, otherwise, returns from the gene descriptor from a phenopacket.\"\"\" if genomic_interpretation . variant_interpretation . ByteSize () != 0 : return ProbandCausativeGene ( genomic_interpretation . variant_interpretation . variation_descriptor . gene_context . symbol , genomic_interpretation . variant_interpretation . variation_descriptor . gene_context . value_id , ) else : return ProbandCausativeGene ( gene_symbol = genomic_interpretation . gene . symbol , gene_identifier = genomic_interpretation . gene . value_id , ) def diagnosed_genes ( self ) -> list [ ProbandCausativeGene ]: \"\"\"Returns a unique list of all causative genes and the corresponding gene identifiers from a phenopacket.\"\"\" pheno_interpretation = self . interpretations () genes = [] for i in pheno_interpretation : for g in i . diagnosis . genomic_interpretations : genes . append ( self . _extract_diagnosed_gene ( g )) genes = list ({ gene . gene_symbol : gene for gene in genes } . values ()) return genes def diagnosed_variants ( self ) -> list [ GenomicVariant ]: \"\"\"Returns a list of all variants from a phenopacket - for use in assess-prioritisation.\"\"\" variants = [] pheno_interpretation = self . interpretations () for i in pheno_interpretation : for g in i . diagnosis . genomic_interpretations : variant = GenomicVariant ( chrom = g . variant_interpretation . variation_descriptor . vcf_record . chrom , pos = g . variant_interpretation . variation_descriptor . vcf_record . pos , ref = g . variant_interpretation . variation_descriptor . vcf_record . ref , alt = g . variant_interpretation . variation_descriptor . vcf_record . alt , ) variants . append ( variant ) return variants","title":"PhenopacketUtil"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.causative_variants","text":"Returns a list of all causative variants listed in a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 def causative_variants ( self ) -> list [ ProbandCausativeVariant ]: \"\"\"Returns a list of all causative variants listed in a phenopacket.\"\"\" all_variants = [] interpretation = self . interpretations () for i in interpretation : for g in i . diagnosis . genomic_interpretations : vcf_record = g . variant_interpretation . variation_descriptor . vcf_record genotype = g . variant_interpretation . variation_descriptor . allelic_state variant_data = ProbandCausativeVariant ( self . phenopacket_contents . subject . id , vcf_record . genome_assembly , GenomicVariant ( vcf_record . chrom , vcf_record . pos , vcf_record . ref , vcf_record . alt , ), genotype . label , vcf_record . info , ) all_variants . append ( variant_data ) return all_variants","title":"causative_variants()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.diagnosed_genes","text":"Returns a unique list of all causative genes and the corresponding gene identifiers from a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 214 215 216 217 218 219 220 221 222 def diagnosed_genes ( self ) -> list [ ProbandCausativeGene ]: \"\"\"Returns a unique list of all causative genes and the corresponding gene identifiers from a phenopacket.\"\"\" pheno_interpretation = self . interpretations () genes = [] for i in pheno_interpretation : for g in i . diagnosis . genomic_interpretations : genes . append ( self . _extract_diagnosed_gene ( g )) genes = list ({ gene . gene_symbol : gene for gene in genes } . values ()) return genes","title":"diagnosed_genes()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.diagnosed_variants","text":"Returns a list of all variants from a phenopacket - for use in assess-prioritisation. Source code in src/pheval/utils/phenopacket_utils.py 224 225 226 227 228 229 230 231 232 233 234 235 236 237 def diagnosed_variants ( self ) -> list [ GenomicVariant ]: \"\"\"Returns a list of all variants from a phenopacket - for use in assess-prioritisation.\"\"\" variants = [] pheno_interpretation = self . interpretations () for i in pheno_interpretation : for g in i . diagnosis . genomic_interpretations : variant = GenomicVariant ( chrom = g . variant_interpretation . variation_descriptor . vcf_record . chrom , pos = g . variant_interpretation . variation_descriptor . vcf_record . pos , ref = g . variant_interpretation . variation_descriptor . vcf_record . ref , alt = g . variant_interpretation . variation_descriptor . vcf_record . alt , ) variants . append ( variant ) return variants","title":"diagnosed_variants()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.files","text":"Returns all files associated with a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 177 178 179 def files ( self ) -> list : \"\"\"Returns all files associated with a phenopacket.\"\"\" return self . phenopacket_contents . files","title":"files()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.interpretations","text":"Returns all interpretations of a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 147 148 149 150 151 152 def interpretations ( self ) -> list [ Interpretation ]: \"\"\"Returns all interpretations of a phenopacket.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . interpretations else : return self . phenopacket_contents . interpretations","title":"interpretations()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.negated_phenotypic_features","text":"Retrieve negated phenotypic features. Source code in src/pheval/utils/phenopacket_utils.py 138 139 140 141 142 143 144 145 def negated_phenotypic_features ( self ) -> [ PhenotypicFeature ]: \"\"\"Retrieve negated phenotypic features.\"\"\" negated_phenotypic_features = [] all_phenotypic_features = self . phenotypic_features () for p in all_phenotypic_features : if p . excluded : negated_phenotypic_features . append ( p ) return negated_phenotypic_features","title":"negated_phenotypic_features()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.observed_phenotypic_features","text":"Removes any HPO terms labelled as excluded. Source code in src/pheval/utils/phenopacket_utils.py 128 129 130 131 132 133 134 135 136 def observed_phenotypic_features ( self ) -> list [ PhenotypicFeature ]: \"\"\"Removes any HPO terms labelled as excluded.\"\"\" phenotypic_features = [] all_phenotypic_features = self . phenotypic_features () for p in all_phenotypic_features : if p . excluded : continue phenotypic_features . append ( p ) return phenotypic_features","title":"observed_phenotypic_features()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.phenotypic_features","text":"Retrieves a list of all HPO terms. Source code in src/pheval/utils/phenopacket_utils.py 121 122 123 124 125 126 def phenotypic_features ( self ) -> list [ PhenotypicFeature ]: \"\"\"Retrieves a list of all HPO terms.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . phenotypic_features else : return self . phenopacket_contents . phenotypic_features","title":"phenotypic_features()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.sample_id","text":"Retrieve the sample ID from a phenopacket or proband of a family. Source code in src/pheval/utils/phenopacket_utils.py 114 115 116 117 118 119 def sample_id ( self ) -> str : \"\"\"Retrieve the sample ID from a phenopacket or proband of a family.\"\"\" if hasattr ( self . phenopacket_contents , \"proband\" ): return self . phenopacket_contents . proband . subject . id else : return self . phenopacket_contents . subject . id","title":"sample_id()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.PhenopacketUtil.vcf_file_data","text":"Retrieves the genome assembly and vcf name from a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 181 182 183 184 185 186 187 188 189 190 191 192 193 194 def vcf_file_data ( self , phenopacket_path : Path , vcf_dir : Path ) -> File : \"\"\"Retrieves the genome assembly and vcf name from a phenopacket.\"\"\" compatible_genome_assembly = [ \"GRCh37\" , \"hg19\" , \"GRCh38\" , \"hg38\" ] vcf_data = [ file for file in self . files () if file . file_attributes [ \"fileFormat\" ] == \"vcf\" ][ 0 ] if not Path ( vcf_data . uri ) . name . endswith ( \".vcf\" ) and not Path ( vcf_data . uri ) . name . endswith ( \".vcf.gz\" ): raise IncorrectFileFormatError ( Path ( vcf_data . uri ), \".vcf or .vcf.gz file\" ) if vcf_data . file_attributes [ \"genomeAssembly\" ] not in compatible_genome_assembly : raise IncompatibleGenomeAssemblyError ( vcf_data . file_attributes [ \"genomeAssembly\" ], phenopacket_path ) vcf_data . uri = str ( vcf_dir . joinpath ( Path ( vcf_data . uri ) . name )) return vcf_data","title":"vcf_file_data()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.create_hgnc_dict","text":"Creates reference for updating gene symbols and identifiers. Source code in src/pheval/utils/phenopacket_utils.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def create_hgnc_dict () -> defaultdict : \"\"\"Creates reference for updating gene symbols and identifiers.\"\"\" hgnc_df = read_hgnc_data () hgnc_data = defaultdict ( dict ) for _index , row in hgnc_df . iterrows (): previous_names = [] hgnc_data [ row [ \"symbol\" ]][ \"ensembl_id\" ] = row [ \"ensembl_gene_id\" ] hgnc_data [ row [ \"symbol\" ]][ \"hgnc_id\" ] = row [ \"hgnc_id\" ] hgnc_data [ row [ \"symbol\" ]][ \"entrez_id\" ] = row [ \"entrez_id\" ] hgnc_data [ row [ \"symbol\" ]][ \"refseq_accession\" ] = row [ \"refseq_accession\" ] previous = str ( row [ \"prev_symbol\" ]) . split ( \"|\" ) for p in previous : previous_names . append ( p . strip ( '\"' )) hgnc_data [ row [ \"symbol\" ]][ \"previous_symbol\" ] = previous_names return hgnc_data","title":"create_hgnc_dict()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.create_json_message","text":"Creates json message for writing to file. Source code in src/pheval/utils/phenopacket_utils.py 280 281 282 def create_json_message ( phenopacket : Phenopacket or Family ) -> str : \"\"\"Creates json message for writing to file.\"\"\" return MessageToJson ( phenopacket )","title":"create_json_message()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.phenopacket_reader","text":"Reads a phenopacket file, returning its contents. Source code in src/pheval/utils/phenopacket_utils.py 97 98 99 100 101 102 103 104 105 def phenopacket_reader ( file : Path ): \"\"\"Reads a phenopacket file, returning its contents.\"\"\" file = open ( file , \"r\" ) phenopacket = json . load ( file ) file . close () if \"proband\" in phenopacket : return Parse ( json . dumps ( phenopacket ), Family ()) else : return Parse ( json . dumps ( phenopacket ), Phenopacket ())","title":"phenopacket_reader()"},{"location":"api/pheval/utils/phenopacket_utils/#src.pheval.utils.phenopacket_utils.write_phenopacket","text":"Writes a phenopacket. Source code in src/pheval/utils/phenopacket_utils.py 285 286 287 288 289 290 def write_phenopacket ( phenopacket : Phenopacket or Family , output_file : Path ) -> None : \"\"\"Writes a phenopacket.\"\"\" phenopacket_json = create_json_message ( phenopacket ) with open ( output_file , \"w\" ) as outfile : outfile . write ( phenopacket_json ) outfile . close ()","title":"write_phenopacket()"},{"location":"api/pheval/utils/semsim_utils/","text":"Contains all pheval utility methods diff_semsim ( semsim_left , semsim_right , score_column , absolute_diff ) Calculates score difference between two semantic similarity profiles Parameters: Name Type Description Default semsim_left pd . DataFrame first semantic similarity dataframe required semsim_right pd . DataFrame second semantic similarity dataframe required score_column str Score column that will be computed (e.g. jaccard_similarity) required absolute_diff bool Whether the difference is absolute (True) or percentage (False). required Returns: Type Description pd . DataFrame pd.DataFrame: A dataframe with terms and its scores differences Source code in src/pheval/utils/semsim_utils.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 def diff_semsim ( semsim_left : pd . DataFrame , semsim_right : pd . DataFrame , score_column : str , absolute_diff : bool ) -> pd . DataFrame : \"\"\"Calculates score difference between two semantic similarity profiles Args: semsim_left (pd.DataFrame): first semantic similarity dataframe semsim_right (pd.DataFrame): second semantic similarity dataframe score_column (str): Score column that will be computed (e.g. jaccard_similarity) absolute_diff (bool, optional): Whether the difference is absolute (True) or percentage (False). Defaults to True. Returns: pd.DataFrame: A dataframe with terms and its scores differences \"\"\" df = pd . merge ( semsim_left , semsim_right , on = [ \"subject_id\" , \"object_id\" ], how = \"outer\" ) if absolute_diff : df [ \"diff\" ] = df [ f \" { score_column } _x\" ] - df [ f \" { score_column } _y\" ] return df [[ \"subject_id\" , \"object_id\" , \"diff\" ]] df [ \"diff\" ] = df . apply ( lambda row : get_percentage_diff ( row [ f \" { score_column } _x\" ], row [ f \" { score_column } _y\" ]), axis = 1 ) return df [[ \"subject_id\" , \"object_id\" , f \" { score_column } _x\" , f \" { score_column } _y\" , \"diff\" ]] filter_non_0_score ( data , col ) Removes rows that have value equal to 0 based on the given column passed by col parameter Parameters: Name Type Description Default data pd . DataFrame Dirty dataframe required col str Column to be filtered required Returns: Type Description pd . DataFrame pd.DataFrame: Filtered dataframe Source code in src/pheval/utils/semsim_utils.py 13 14 15 16 17 18 19 20 21 22 23 def filter_non_0_score ( data : pd . DataFrame , col : str ) -> pd . DataFrame : \"\"\"Removes rows that have value equal to 0 based on the given column passed by col parameter Args: data (pd.DataFrame): Dirty dataframe col (str): Column to be filtered Returns: pd.DataFrame: Filtered dataframe \"\"\" return data [ data [ col ] != 0 ] get_percentage_diff ( current_number , previous_number ) Gets the percentage difference between two numbers Parameters: Name Type Description Default current_number float second number in comparison required previous_number float first number in comparison required Returns: Name Type Description float float percentage difference between two numbers Source code in src/pheval/utils/semsim_utils.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 def get_percentage_diff ( current_number : float , previous_number : float ) -> float : \"\"\"Gets the percentage difference between two numbers Args: current_number (float): second number in comparison previous_number (float): first number in comparison Returns: float: percentage difference between two numbers \"\"\" try : if current_number == previous_number : return \" {:.2%} \" . format ( 0 ) if current_number > previous_number : number = ( 1 - (( current_number / previous_number ))) * 100 else : number = ( 100 - (( previous_number / current_number ) * 100 )) * - 1 return \" {:.2%} \" . format ( number / 100 ) except ZeroDivisionError : return None parse_semsim ( df , cols ) Parses semantic similarity profiles converting the score column as a numeric value and dropping the null ones Parameters: Name Type Description Default df pd . DataFrame semantic similarity profile dataframe required cols list list of columns that will be selected on semsim data required Returns: Type Description pd . DataFrame pd.Dataframe: parsed semantic similarity dataframe Source code in src/pheval/utils/semsim_utils.py 26 27 28 29 30 31 32 33 34 35 36 37 38 def parse_semsim ( df : pd . DataFrame , cols : list ) -> pd . DataFrame : \"\"\"Parses semantic similarity profiles converting the score column as a numeric value and dropping the null ones Args: df (pd.DataFrame): semantic similarity profile dataframe cols (list): list of columns that will be selected on semsim data Returns: pd.Dataframe: parsed semantic similarity dataframe \"\"\" df [ cols [ - 1 ]] = pd . to_numeric ( df [ cols [ - 1 ]], errors = \"coerce\" ) df . replace ( \"None\" , numpy . nan ) . dropna ( subset = cols [ - 1 ], inplace = True ) return df percentage_diff ( semsim_left , semsim_right , score_column , output ) Compares two semantic similarity profiles Parameters: Name Type Description Default semsim_left Path File path of the first semantic similarity profile required semsim_right Path File path of the second semantic similarity profile required score_column str Score column that will be computed (e.g. jaccard_similarity) required output Path Output path for the difference tsv file required Source code in src/pheval/utils/semsim_utils.py 66 67 68 69 70 71 72 73 74 75 76 def percentage_diff ( semsim_left : Path , semsim_right : Path , score_column : str , output : Path ): \"\"\"Compares two semantic similarity profiles Args: semsim_left (Path): File path of the first semantic similarity profile semsim_right (Path): File path of the second semantic similarity profile score_column (str): Score column that will be computed (e.g. jaccard_similarity) output (Path): Output path for the difference tsv file \"\"\" clean_df = semsim_analysis ( semsim_left , semsim_right , score_column , absolute_diff = False ) clean_df . sort_values ( by = \"diff\" , ascending = False ) . to_csv ( output , sep = \" \\t \" , index = False ) semsim_analysis ( semsim_left , semsim_right , score_column , absolute_diff = True ) semsim_analysis Parameters: Name Type Description Default semsim_left Path File path of the first semantic similarity profile required semsim_right Path File path of the second semantic similarity profile required score_column str Score column that will be computed (e.g. jaccard_similarity) required absolute_diff bool Whether the difference is absolute (True) or percentage (False). True Returns: Type Description pd . DataFrame [pd.DataFrame]: DataFrame with the differences between two semantic similarity profiles Source code in src/pheval/utils/semsim_utils.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def semsim_analysis ( semsim_left : Path , semsim_right : Path , score_column : str , absolute_diff = True ) -> pd . DataFrame : \"\"\"semsim_analysis Args: semsim_left (Path): File path of the first semantic similarity profile semsim_right (Path): File path of the second semantic similarity profile score_column (str): Score column that will be computed (e.g. jaccard_similarity) absolute_diff (bool, optional): Whether the difference is absolute (True) or percentage (False). Defaults to True. Returns: [pd.DataFrame]: DataFrame with the differences between two semantic similarity profiles \"\"\" validate_semsim_file_comparison ( semsim_left , semsim_right ) cols = [ \"subject_id\" , \"object_id\" , score_column ] semsim_left = pd . read_csv ( semsim_left , sep = \" \\t \" ) semsim_right = pd . read_csv ( semsim_right , sep = \" \\t \" ) file_utils . ensure_columns_exists ( cols = cols , err_message = \"must exist in semsim dataframes\" , dataframes = [ semsim_left , semsim_right ], ) semsim_left = parse_semsim ( semsim_left , cols ) semsim_right = parse_semsim ( semsim_right , cols ) diff_df = diff_semsim ( semsim_left , semsim_right , score_column , absolute_diff ) return filter_non_0_score ( diff_df , \"diff\" ) semsim_heatmap_plot ( semsim_left , semsim_right , score_column ) Plots semantic similarity profiles heatmap Parameters: Name Type Description Default semsim_left Path File path of the first semantic similarity profile required semsim_right Path File path of the second semantic similarity profile required score_column str Score column that will be computed (e.g. jaccard_similarity) required Source code in src/pheval/utils/semsim_utils.py 79 80 81 82 83 84 85 86 87 88 89 90 def semsim_heatmap_plot ( semsim_left : Path , semsim_right : Path , score_column : str ): \"\"\"Plots semantic similarity profiles heatmap Args: semsim_left (Path): File path of the first semantic similarity profile semsim_right (Path): File path of the second semantic similarity profile score_column (str): Score column that will be computed (e.g. jaccard_similarity) \"\"\" clean_df = semsim_analysis ( semsim_left , semsim_right , score_column ) df = clean_df . pivot ( index = \"subject_id\" , columns = \"object_id\" , values = \"diff\" ) fig = px . imshow ( df , text_auto = True ) fig . show () validate_semsim_file_comparison ( semsim_left , semsim_right ) Checks if files exist and whether they're different Parameters: Name Type Description Default semsim_left Path File path of the first semantic similarity profile required semsim_right Path File path of the second semantic similarity profile required Raises: Type Description Exception FileNotFoundException Source code in src/pheval/utils/semsim_utils.py 123 124 125 126 127 128 129 130 131 132 133 134 def validate_semsim_file_comparison ( semsim_left : Path , semsim_right : Path ): \"\"\"Checks if files exist and whether they're different Args: semsim_left (Path): File path of the first semantic similarity profile semsim_right (Path): File path of the second semantic similarity profile Raises: Exception: FileNotFoundException \"\"\" if semsim_left == semsim_right : errmsg = \"Semantic similarity profiles are equal. Make sure you have selected different files to analyze\" raise Exception ( errmsg ) file_utils . ensure_file_exists ( semsim_left , semsim_right )","title":"Semsim utils"},{"location":"api/pheval/utils/semsim_utils/#src.pheval.utils.semsim_utils.diff_semsim","text":"Calculates score difference between two semantic similarity profiles Parameters: Name Type Description Default semsim_left pd . DataFrame first semantic similarity dataframe required semsim_right pd . DataFrame second semantic similarity dataframe required score_column str Score column that will be computed (e.g. jaccard_similarity) required absolute_diff bool Whether the difference is absolute (True) or percentage (False). required Returns: Type Description pd . DataFrame pd.DataFrame: A dataframe with terms and its scores differences Source code in src/pheval/utils/semsim_utils.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 def diff_semsim ( semsim_left : pd . DataFrame , semsim_right : pd . DataFrame , score_column : str , absolute_diff : bool ) -> pd . DataFrame : \"\"\"Calculates score difference between two semantic similarity profiles Args: semsim_left (pd.DataFrame): first semantic similarity dataframe semsim_right (pd.DataFrame): second semantic similarity dataframe score_column (str): Score column that will be computed (e.g. jaccard_similarity) absolute_diff (bool, optional): Whether the difference is absolute (True) or percentage (False). Defaults to True. Returns: pd.DataFrame: A dataframe with terms and its scores differences \"\"\" df = pd . merge ( semsim_left , semsim_right , on = [ \"subject_id\" , \"object_id\" ], how = \"outer\" ) if absolute_diff : df [ \"diff\" ] = df [ f \" { score_column } _x\" ] - df [ f \" { score_column } _y\" ] return df [[ \"subject_id\" , \"object_id\" , \"diff\" ]] df [ \"diff\" ] = df . apply ( lambda row : get_percentage_diff ( row [ f \" { score_column } _x\" ], row [ f \" { score_column } _y\" ]), axis = 1 ) return df [[ \"subject_id\" , \"object_id\" , f \" { score_column } _x\" , f \" { score_column } _y\" , \"diff\" ]]","title":"diff_semsim()"},{"location":"api/pheval/utils/semsim_utils/#src.pheval.utils.semsim_utils.filter_non_0_score","text":"Removes rows that have value equal to 0 based on the given column passed by col parameter Parameters: Name Type Description Default data pd . DataFrame Dirty dataframe required col str Column to be filtered required Returns: Type Description pd . DataFrame pd.DataFrame: Filtered dataframe Source code in src/pheval/utils/semsim_utils.py 13 14 15 16 17 18 19 20 21 22 23 def filter_non_0_score ( data : pd . DataFrame , col : str ) -> pd . DataFrame : \"\"\"Removes rows that have value equal to 0 based on the given column passed by col parameter Args: data (pd.DataFrame): Dirty dataframe col (str): Column to be filtered Returns: pd.DataFrame: Filtered dataframe \"\"\" return data [ data [ col ] != 0 ]","title":"filter_non_0_score()"},{"location":"api/pheval/utils/semsim_utils/#src.pheval.utils.semsim_utils.get_percentage_diff","text":"Gets the percentage difference between two numbers Parameters: Name Type Description Default current_number float second number in comparison required previous_number float first number in comparison required Returns: Name Type Description float float percentage difference between two numbers Source code in src/pheval/utils/semsim_utils.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 def get_percentage_diff ( current_number : float , previous_number : float ) -> float : \"\"\"Gets the percentage difference between two numbers Args: current_number (float): second number in comparison previous_number (float): first number in comparison Returns: float: percentage difference between two numbers \"\"\" try : if current_number == previous_number : return \" {:.2%} \" . format ( 0 ) if current_number > previous_number : number = ( 1 - (( current_number / previous_number ))) * 100 else : number = ( 100 - (( previous_number / current_number ) * 100 )) * - 1 return \" {:.2%} \" . format ( number / 100 ) except ZeroDivisionError : return None","title":"get_percentage_diff()"},{"location":"api/pheval/utils/semsim_utils/#src.pheval.utils.semsim_utils.parse_semsim","text":"Parses semantic similarity profiles converting the score column as a numeric value and dropping the null ones Parameters: Name Type Description Default df pd . DataFrame semantic similarity profile dataframe required cols list list of columns that will be selected on semsim data required Returns: Type Description pd . DataFrame pd.Dataframe: parsed semantic similarity dataframe Source code in src/pheval/utils/semsim_utils.py 26 27 28 29 30 31 32 33 34 35 36 37 38 def parse_semsim ( df : pd . DataFrame , cols : list ) -> pd . DataFrame : \"\"\"Parses semantic similarity profiles converting the score column as a numeric value and dropping the null ones Args: df (pd.DataFrame): semantic similarity profile dataframe cols (list): list of columns that will be selected on semsim data Returns: pd.Dataframe: parsed semantic similarity dataframe \"\"\" df [ cols [ - 1 ]] = pd . to_numeric ( df [ cols [ - 1 ]], errors = \"coerce\" ) df . replace ( \"None\" , numpy . nan ) . dropna ( subset = cols [ - 1 ], inplace = True ) return df","title":"parse_semsim()"},{"location":"api/pheval/utils/semsim_utils/#src.pheval.utils.semsim_utils.percentage_diff","text":"Compares two semantic similarity profiles Parameters: Name Type Description Default semsim_left Path File path of the first semantic similarity profile required semsim_right Path File path of the second semantic similarity profile required score_column str Score column that will be computed (e.g. jaccard_similarity) required output Path Output path for the difference tsv file required Source code in src/pheval/utils/semsim_utils.py 66 67 68 69 70 71 72 73 74 75 76 def percentage_diff ( semsim_left : Path , semsim_right : Path , score_column : str , output : Path ): \"\"\"Compares two semantic similarity profiles Args: semsim_left (Path): File path of the first semantic similarity profile semsim_right (Path): File path of the second semantic similarity profile score_column (str): Score column that will be computed (e.g. jaccard_similarity) output (Path): Output path for the difference tsv file \"\"\" clean_df = semsim_analysis ( semsim_left , semsim_right , score_column , absolute_diff = False ) clean_df . sort_values ( by = \"diff\" , ascending = False ) . to_csv ( output , sep = \" \\t \" , index = False )","title":"percentage_diff()"},{"location":"api/pheval/utils/semsim_utils/#src.pheval.utils.semsim_utils.semsim_analysis","text":"semsim_analysis Parameters: Name Type Description Default semsim_left Path File path of the first semantic similarity profile required semsim_right Path File path of the second semantic similarity profile required score_column str Score column that will be computed (e.g. jaccard_similarity) required absolute_diff bool Whether the difference is absolute (True) or percentage (False). True Returns: Type Description pd . DataFrame [pd.DataFrame]: DataFrame with the differences between two semantic similarity profiles Source code in src/pheval/utils/semsim_utils.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def semsim_analysis ( semsim_left : Path , semsim_right : Path , score_column : str , absolute_diff = True ) -> pd . DataFrame : \"\"\"semsim_analysis Args: semsim_left (Path): File path of the first semantic similarity profile semsim_right (Path): File path of the second semantic similarity profile score_column (str): Score column that will be computed (e.g. jaccard_similarity) absolute_diff (bool, optional): Whether the difference is absolute (True) or percentage (False). Defaults to True. Returns: [pd.DataFrame]: DataFrame with the differences between two semantic similarity profiles \"\"\" validate_semsim_file_comparison ( semsim_left , semsim_right ) cols = [ \"subject_id\" , \"object_id\" , score_column ] semsim_left = pd . read_csv ( semsim_left , sep = \" \\t \" ) semsim_right = pd . read_csv ( semsim_right , sep = \" \\t \" ) file_utils . ensure_columns_exists ( cols = cols , err_message = \"must exist in semsim dataframes\" , dataframes = [ semsim_left , semsim_right ], ) semsim_left = parse_semsim ( semsim_left , cols ) semsim_right = parse_semsim ( semsim_right , cols ) diff_df = diff_semsim ( semsim_left , semsim_right , score_column , absolute_diff ) return filter_non_0_score ( diff_df , \"diff\" )","title":"semsim_analysis()"},{"location":"api/pheval/utils/semsim_utils/#src.pheval.utils.semsim_utils.semsim_heatmap_plot","text":"Plots semantic similarity profiles heatmap Parameters: Name Type Description Default semsim_left Path File path of the first semantic similarity profile required semsim_right Path File path of the second semantic similarity profile required score_column str Score column that will be computed (e.g. jaccard_similarity) required Source code in src/pheval/utils/semsim_utils.py 79 80 81 82 83 84 85 86 87 88 89 90 def semsim_heatmap_plot ( semsim_left : Path , semsim_right : Path , score_column : str ): \"\"\"Plots semantic similarity profiles heatmap Args: semsim_left (Path): File path of the first semantic similarity profile semsim_right (Path): File path of the second semantic similarity profile score_column (str): Score column that will be computed (e.g. jaccard_similarity) \"\"\" clean_df = semsim_analysis ( semsim_left , semsim_right , score_column ) df = clean_df . pivot ( index = \"subject_id\" , columns = \"object_id\" , values = \"diff\" ) fig = px . imshow ( df , text_auto = True ) fig . show ()","title":"semsim_heatmap_plot()"},{"location":"api/pheval/utils/semsim_utils/#src.pheval.utils.semsim_utils.validate_semsim_file_comparison","text":"Checks if files exist and whether they're different Parameters: Name Type Description Default semsim_left Path File path of the first semantic similarity profile required semsim_right Path File path of the second semantic similarity profile required Raises: Type Description Exception FileNotFoundException Source code in src/pheval/utils/semsim_utils.py 123 124 125 126 127 128 129 130 131 132 133 134 def validate_semsim_file_comparison ( semsim_left : Path , semsim_right : Path ): \"\"\"Checks if files exist and whether they're different Args: semsim_left (Path): File path of the first semantic similarity profile semsim_right (Path): File path of the second semantic similarity profile Raises: Exception: FileNotFoundException \"\"\" if semsim_left == semsim_right : errmsg = \"Semantic similarity profiles are equal. Make sure you have selected different files to analyze\" raise Exception ( errmsg ) file_utils . ensure_file_exists ( semsim_left , semsim_right )","title":"validate_semsim_file_comparison()"},{"location":"api/pheval/utils/utils/","text":"Contains all pheval utility methods rand ( df , min_num , max_num , scramble_factor ) Numeric scrambling Parameters: Name Type Description Default df pd . DataFrame dataframe records required min_num int min value from this records required max_num int max value from this records required scramble_factor float scramble factor scalar required Returns: Name Type Description float float randomized number Source code in src/pheval/utils/utils.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 def rand ( df : pd . DataFrame , min_num : int , max_num : int , scramble_factor : float ) -> float : \"\"\" Numeric scrambling Args: df (pd.DataFrame): dataframe records min_num (int): min value from this records max_num (int): max value from this records scramble_factor (float): scramble factor scalar Returns: float: randomized number \"\"\" try : return df + ( random . uniform ( min_num , max_num ) * scramble_factor ) except TypeError as err : info_log . error ( df , exc_info = err ) return df semsim2h2 ( input_data , output , subject_prefix , object_prefix ) This function converts the exomiser mapping table to sql format. Parameters: Name Type Description Default input_data pd . DataFrame Semsim dataframe required output Path Path where sql file will be written required subject_prefix str (str): mapping subject prefix (e.g. HP) required object_prefx str mapping object prefix (e.g. MP) required Source code in src/pheval/utils/utils.py 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 def semsim2h2 ( input_data : pd . DataFrame , output : Path , subject_prefix : str , object_prefix : str ) -> None : \"\"\"This function converts the exomiser mapping table to sql format. Args: input_data (pd.DataFrame): Semsim dataframe output (Path): Path where sql file will be written subject_prefix: (str): mapping subject prefix (e.g. HP) object_prefx (str): mapping object prefix (e.g. MP) \"\"\" with open ( output , \"w\" ) as file : insert = f \"\"\" TRUNCATE TABLE EXOMISER. { subject_prefix } _ { object_prefix } _MAPPINGS; INSERT INTO EXOMISER. { subject_prefix } _ { object_prefix } _MAPPINGS (MAPPING_ID, { subject_prefix } _ID, { subject_prefix } _TERM, { object_prefix } _ID, { object_prefix } _TERM, SIMJ, IC, SCORE, LCS_ID, LCS_TERM) VALUES \"\"\" # noqa file . write ( insert ) for idx , data in input_data . iterrows (): values = f \"\"\" ( { idx } , ' { data [ f ' { subject_prefix } _ID' ] } ', ' { data [ f ' { subject_prefix } _TERM' ] } ', ' { data [ f ' { object_prefix } _ID' ] } ', ' { data [ f ' { object_prefix } _TERM' ] } ', { data [ 'SIMJ' ] } , { data [ 'IC' ] } , { data [ 'SCORE' ] } , ' { data [ 'LCS_ID' ] } ', ' { data [ 'LCS_TERM' ] } ')\"\"\" # noqa if idx > ( len ( input_data ) < 1 ): file . write ( \",\" ) file . write ( values ) file . write ( \";\" ) semsim_scramble ( input , output , columns_to_be_scrambled , scramble_factor = 0.5 ) Scrambles semantic similarity profile with a magnitude between 0 and 1 (scramble_factor: 0 means no scrambling and 1 means complete randomisation). It then randomises the above scores with a degree of the scramble_factor and returns a scrambles pandas dataframe. Args: input (Path): scramble_factor (float) scalar scramble factor columns_to_be_scrambled (List[str]): columns that will be scrambled in semsim file (e.g. jaccard_similarity). output (Path) Returns: pd.Dataframe: scrambled dataframe Source code in src/pheval/utils/utils.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def semsim_scramble ( input : Path , output : Path , columns_to_be_scrambled : List [ str ], scramble_factor : float = 0.5 , ) -> pd . DataFrame : \"\"\" Scrambles semantic similarity profile with a magnitude between 0 and 1 (scramble_factor: 0 means no scrambling and 1 means complete randomisation). It then randomises the above scores with a degree of the scramble_factor and returns a scrambles pandas dataframe. Args: input (Path): scramble_factor (float) scalar scramble factor columns_to_be_scrambled (List[str]): columns that will be scrambled in semsim file (e.g. jaccard_similarity). output (Path) Returns: pd.Dataframe: scrambled dataframe \"\"\" semsim = pd . read_csv ( input , sep = \" \\t \" ) dataframe = semsim_scramble_df ( semsim , columns_to_be_scrambled , scramble_factor ) dataframe . to_csv ( output , sep = \" \\t \" , index = False ) semsim_scramble_df ( dataframe , columns_to_be_scrambled , scramble_factor ) scramble_semsim_df Parameters: Name Type Description Default dataframe pd . DataFrame dataframe that contains semsim profile required columns_to_be_scrambled List [ str ] required Returns: Type Description pd . DataFrame pd.Dataframe: scrambled dataframe Source code in src/pheval/utils/utils.py 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 def semsim_scramble_df ( dataframe : pd . DataFrame , columns_to_be_scrambled : List [ str ], scramble_factor : float , ) -> pd . DataFrame : \"\"\"scramble_semsim_df Args: dataframe (pd.DataFrame): dataframe that contains semsim profile scramble_factor (float) scalar scramble factor columns_to_be_scrambled (List[str]): Returns: pd.Dataframe: scrambled dataframe \"\"\" for col in columns_to_be_scrambled : min_num = dataframe [ col ] . min () max_num = dataframe [ col ] . max () dataframe [ col ] = dataframe [ col ] . apply ( rand , args = ( min_num , max_num , scramble_factor )) return dataframe semsimconvert_exomiserdb ( input , output , subject_prefix , object_prefix ) convert semsim profile to an exomiser specie mapping schema Example of a mapping schema: MAPPING_ID;HP_ID;HP_TERM;MP_ID;MP_TERM;SIMJ;IC;SCORE;LCS_ID;LCS_TERM To generate the example above, the parameter subject_prefix needs to be \"HP\" and object_prefix needs to be \"MP\" Parameters: Name Type Description Default input Path Path to the semsim profile required output Path Path where sql file will be written required subject_prefix str (str): mapping subject prefix (e.g. HP) required object_prefx str mapping object prefix (e.g. MP) required Source code in src/pheval/utils/utils.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 def semsimconvert_exomiserdb ( input : Path , output : Path , subject_prefix : str , object_prefix : str ) -> None : \"\"\"convert semsim profile to an exomiser specie mapping schema Example of a mapping schema: MAPPING_ID;HP_ID;HP_TERM;MP_ID;MP_TERM;SIMJ;IC;SCORE;LCS_ID;LCS_TERM To generate the example above, the parameter subject_prefix needs to be \"HP\" and object_prefix needs to be \"MP\" Args: input (Path): Path to the semsim profile output (Path): Path where sql file will be written subject_prefix: (str): mapping subject prefix (e.g. HP) object_prefx (str): mapping object prefix (e.g. MP) \"\"\" input_data = pd . read_csv ( input , sep = \" \\t \" ) input_data = input_data . rename ( columns = { \"subject_id\" : f \" { subject_prefix } _ID\" , \"subject_label\" : f \" { subject_prefix } _TERM\" , \"object_id\" : f \" { object_prefix } _ID\" , \"object_label\" : f \" { object_prefix } _TERM\" , \"jaccard_similarity\" : \"SIMJ\" , \"ancestor_information_content\" : \"IC\" , \"phenodigm_score\" : \"SCORE\" , \"ancestor_id\" : \"LCS_ID\" , \"ancestor_label\" : \"LCS_TERM\" , } )[ [ f \" { subject_prefix } _ID\" , f \" { subject_prefix } _TERM\" , f \" { object_prefix } _ID\" , f \" { object_prefix } _TERM\" , \"SIMJ\" , \"IC\" , \"SCORE\" , \"LCS_ID\" , \"LCS_TERM\" , ] ] input_data . insert ( 0 , \"MAPPING_ID\" , None ) input_data [ \"SCORE\" ] . replace ( \"None\" , \"NULL\" , inplace = True ) input_data . to_csv ( output , index = False , sep = \" \\t \" ) semsim2h2 ( input_data , output , subject_prefix , object_prefix )","title":"Utils"},{"location":"api/pheval/utils/utils/#src.pheval.utils.utils.rand","text":"Numeric scrambling Parameters: Name Type Description Default df pd . DataFrame dataframe records required min_num int min value from this records required max_num int max value from this records required scramble_factor float scramble factor scalar required Returns: Name Type Description float float randomized number Source code in src/pheval/utils/utils.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 def rand ( df : pd . DataFrame , min_num : int , max_num : int , scramble_factor : float ) -> float : \"\"\" Numeric scrambling Args: df (pd.DataFrame): dataframe records min_num (int): min value from this records max_num (int): max value from this records scramble_factor (float): scramble factor scalar Returns: float: randomized number \"\"\" try : return df + ( random . uniform ( min_num , max_num ) * scramble_factor ) except TypeError as err : info_log . error ( df , exc_info = err ) return df","title":"rand()"},{"location":"api/pheval/utils/utils/#src.pheval.utils.utils.semsim2h2","text":"This function converts the exomiser mapping table to sql format. Parameters: Name Type Description Default input_data pd . DataFrame Semsim dataframe required output Path Path where sql file will be written required subject_prefix str (str): mapping subject prefix (e.g. HP) required object_prefx str mapping object prefix (e.g. MP) required Source code in src/pheval/utils/utils.py 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 def semsim2h2 ( input_data : pd . DataFrame , output : Path , subject_prefix : str , object_prefix : str ) -> None : \"\"\"This function converts the exomiser mapping table to sql format. Args: input_data (pd.DataFrame): Semsim dataframe output (Path): Path where sql file will be written subject_prefix: (str): mapping subject prefix (e.g. HP) object_prefx (str): mapping object prefix (e.g. MP) \"\"\" with open ( output , \"w\" ) as file : insert = f \"\"\" TRUNCATE TABLE EXOMISER. { subject_prefix } _ { object_prefix } _MAPPINGS; INSERT INTO EXOMISER. { subject_prefix } _ { object_prefix } _MAPPINGS (MAPPING_ID, { subject_prefix } _ID, { subject_prefix } _TERM, { object_prefix } _ID, { object_prefix } _TERM, SIMJ, IC, SCORE, LCS_ID, LCS_TERM) VALUES \"\"\" # noqa file . write ( insert ) for idx , data in input_data . iterrows (): values = f \"\"\" ( { idx } , ' { data [ f ' { subject_prefix } _ID' ] } ', ' { data [ f ' { subject_prefix } _TERM' ] } ', ' { data [ f ' { object_prefix } _ID' ] } ', ' { data [ f ' { object_prefix } _TERM' ] } ', { data [ 'SIMJ' ] } , { data [ 'IC' ] } , { data [ 'SCORE' ] } , ' { data [ 'LCS_ID' ] } ', ' { data [ 'LCS_TERM' ] } ')\"\"\" # noqa if idx > ( len ( input_data ) < 1 ): file . write ( \",\" ) file . write ( values ) file . write ( \";\" )","title":"semsim2h2()"},{"location":"api/pheval/utils/utils/#src.pheval.utils.utils.semsim_scramble","text":"Scrambles semantic similarity profile with a magnitude between 0 and 1 (scramble_factor: 0 means no scrambling and 1 means complete randomisation). It then randomises the above scores with a degree of the scramble_factor and returns a scrambles pandas dataframe. Args: input (Path): scramble_factor (float) scalar scramble factor columns_to_be_scrambled (List[str]): columns that will be scrambled in semsim file (e.g. jaccard_similarity). output (Path) Returns: pd.Dataframe: scrambled dataframe Source code in src/pheval/utils/utils.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def semsim_scramble ( input : Path , output : Path , columns_to_be_scrambled : List [ str ], scramble_factor : float = 0.5 , ) -> pd . DataFrame : \"\"\" Scrambles semantic similarity profile with a magnitude between 0 and 1 (scramble_factor: 0 means no scrambling and 1 means complete randomisation). It then randomises the above scores with a degree of the scramble_factor and returns a scrambles pandas dataframe. Args: input (Path): scramble_factor (float) scalar scramble factor columns_to_be_scrambled (List[str]): columns that will be scrambled in semsim file (e.g. jaccard_similarity). output (Path) Returns: pd.Dataframe: scrambled dataframe \"\"\" semsim = pd . read_csv ( input , sep = \" \\t \" ) dataframe = semsim_scramble_df ( semsim , columns_to_be_scrambled , scramble_factor ) dataframe . to_csv ( output , sep = \" \\t \" , index = False )","title":"semsim_scramble()"},{"location":"api/pheval/utils/utils/#src.pheval.utils.utils.semsim_scramble_df","text":"scramble_semsim_df Parameters: Name Type Description Default dataframe pd . DataFrame dataframe that contains semsim profile required columns_to_be_scrambled List [ str ] required Returns: Type Description pd . DataFrame pd.Dataframe: scrambled dataframe Source code in src/pheval/utils/utils.py 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 def semsim_scramble_df ( dataframe : pd . DataFrame , columns_to_be_scrambled : List [ str ], scramble_factor : float , ) -> pd . DataFrame : \"\"\"scramble_semsim_df Args: dataframe (pd.DataFrame): dataframe that contains semsim profile scramble_factor (float) scalar scramble factor columns_to_be_scrambled (List[str]): Returns: pd.Dataframe: scrambled dataframe \"\"\" for col in columns_to_be_scrambled : min_num = dataframe [ col ] . min () max_num = dataframe [ col ] . max () dataframe [ col ] = dataframe [ col ] . apply ( rand , args = ( min_num , max_num , scramble_factor )) return dataframe","title":"semsim_scramble_df()"},{"location":"api/pheval/utils/utils/#src.pheval.utils.utils.semsimconvert_exomiserdb","text":"convert semsim profile to an exomiser specie mapping schema Example of a mapping schema: MAPPING_ID;HP_ID;HP_TERM;MP_ID;MP_TERM;SIMJ;IC;SCORE;LCS_ID;LCS_TERM To generate the example above, the parameter subject_prefix needs to be \"HP\" and object_prefix needs to be \"MP\" Parameters: Name Type Description Default input Path Path to the semsim profile required output Path Path where sql file will be written required subject_prefix str (str): mapping subject prefix (e.g. HP) required object_prefx str mapping object prefix (e.g. MP) required Source code in src/pheval/utils/utils.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 def semsimconvert_exomiserdb ( input : Path , output : Path , subject_prefix : str , object_prefix : str ) -> None : \"\"\"convert semsim profile to an exomiser specie mapping schema Example of a mapping schema: MAPPING_ID;HP_ID;HP_TERM;MP_ID;MP_TERM;SIMJ;IC;SCORE;LCS_ID;LCS_TERM To generate the example above, the parameter subject_prefix needs to be \"HP\" and object_prefix needs to be \"MP\" Args: input (Path): Path to the semsim profile output (Path): Path where sql file will be written subject_prefix: (str): mapping subject prefix (e.g. HP) object_prefx (str): mapping object prefix (e.g. MP) \"\"\" input_data = pd . read_csv ( input , sep = \" \\t \" ) input_data = input_data . rename ( columns = { \"subject_id\" : f \" { subject_prefix } _ID\" , \"subject_label\" : f \" { subject_prefix } _TERM\" , \"object_id\" : f \" { object_prefix } _ID\" , \"object_label\" : f \" { object_prefix } _TERM\" , \"jaccard_similarity\" : \"SIMJ\" , \"ancestor_information_content\" : \"IC\" , \"phenodigm_score\" : \"SCORE\" , \"ancestor_id\" : \"LCS_ID\" , \"ancestor_label\" : \"LCS_TERM\" , } )[ [ f \" { subject_prefix } _ID\" , f \" { subject_prefix } _TERM\" , f \" { object_prefix } _ID\" , f \" { object_prefix } _TERM\" , \"SIMJ\" , \"IC\" , \"SCORE\" , \"LCS_ID\" , \"LCS_TERM\" , ] ] input_data . insert ( 0 , \"MAPPING_ID\" , None ) input_data [ \"SCORE\" ] . replace ( \"None\" , \"NULL\" , inplace = True ) input_data . to_csv ( output , index = False , sep = \" \\t \" ) semsim2h2 ( input_data , output , subject_prefix , object_prefix )","title":"semsimconvert_exomiserdb()"}]}